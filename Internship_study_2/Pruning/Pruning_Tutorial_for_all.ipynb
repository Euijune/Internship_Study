{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pruning_Tutorial_for_all.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["참고\n","\n","\n","> https://github.com/ruihangdu/PyTorch-Deep-Compression\n","\n"],"metadata":{"id":"E9q3ycP-QEza"}},{"cell_type":"markdown","source":["라이브러리 임포트"],"metadata":{"id":"4f36IrWyrt74"}},{"cell_type":"code","metadata":{"id":"12j9rTQ1oN8v"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms, datasets\n","from torch.autograd import Variable\n","from torch.nn.parameter import Parameter\n","import numpy as np\n","import os, math, time\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3개의 컨볼루션 층, 1개의 완전 연결 층을 가진 ToyNet 정의 "],"metadata":{"id":"hrGitjCirxKg"}},{"cell_type":"code","metadata":{"id":"z1MrLCXcs1tK"},"source":["class ToyNet(nn.Module):\n","  def __init__(self):\n","    super(ToyNet, self).__init__()\n","    self.layer1 = nn.Sequential(\n","        nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n","        nn.BatchNorm2d(16),\n","        nn.ReLU(inplace=True)\n","    )\n","    self.layer2 = nn.Sequential(\n","        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1, bias=False),\n","        nn.BatchNorm2d(32),\n","        nn.ReLU(inplace=True)\n","    )\n","    self.layer3 = nn.Sequential(\n","        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1, bias=False),\n","        nn.BatchNorm2d(64),\n","        nn.ReLU(inplace=True)\n","    )\n","    self.fc = nn.Sequential(\n","        nn.Linear(8*8*64, 10)\n","    )\n","    for m in self.modules():\n","      if isinstance(m, nn.Conv2d):\n","        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","        m.weight.data.normal_(0, math.sqrt(2./n))\n","      elif isinstance(m, nn.BatchNorm2d):\n","        m.weight.data.fill_(1)\n","        m.bias.data.zero_()\n","\n","  def forward(self, x):\n","    out = self.layer1(x) #32x32\n","    out = self.layer2(out) #16x16\n","    out = self.layer3(out) #8x8\n","\n","    out = out.view(x.size(0), -1)\n","    out = self.fc(out)\n","    \n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["컨볼루션층에 프루닝을 하기 위해 MaskConv2d를 정의. \n","\n","전방계산을 할 때 기존의 weight에다가 mask를 씌우는 형태로 프루닝을 진행\n","\n","이후 위에서 정의한 ToyNet의 convolution층을 MaskConv로 바꿔줌"],"metadata":{"id":"7GJCoPOArkz3"}},{"cell_type":"code","metadata":{"id":"_TDsn1vZZDVi"},"source":["class MaskConv2d(nn.Conv2d):\n","  def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n","                 padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros'):\n","    super(MaskConv2d, self).__init__(in_channels, out_channels, kernel_size, stride,\n","                                     padding, dilation, groups, bias, padding_mode)\n","    # self.mask = ''' implement ''' # add one tensor with Parameter and don't need gradient value\n","    self.alpha = 0.2 # pruning ratio\n","    #>>> torch.ge(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[True, True], [False, True]])\n","    self.mask = torch.ge(self.weight.data.abs(), self.alpha* self.weight.data.std()).type('torch.FloatTensor')\n","    self.mask = self.mask.cuda()\n","\n","  def forward(self, x):\n","    ### static\n","    # print(self.weight.data)\n","    # print(self.mask)\n","    self.weight.data = self.weight.data *self.mask\n","    # print(self.weight.data)\n","    return super(MaskConv2d, self)._conv_forward(x, self.weight, self.bias)\n","    \n","    ### dynamic -> preserve original weight value\n","    # masked_weight = self.weight.data * self.masked_weight\n","    # return super(MaskConv2d, self)._conv_forward(x, masked_weight)\n","\n","\n","class MaskToyNet(nn.Module):\n","  def __init__(self):\n","    super(MaskToyNet, self).__init__()\n","    self.layer1 = nn.Sequential(\n","        MaskConv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n","        nn.BatchNorm2d(16),\n","        nn.ReLU(inplace=True)\n","    )\n","    self.layer2 = nn.Sequential(\n","        MaskConv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1, bias=False),\n","        nn.BatchNorm2d(32),\n","        nn.ReLU(inplace=True)\n","    )\n","    self.layer3 = nn.Sequential(\n","        MaskConv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1, bias=False),\n","        nn.BatchNorm2d(64),\n","        nn.ReLU(inplace=True)\n","    )\n","    self.fc = nn.Sequential(\n","        nn.Linear(8*8*64, 10)\n","    )\n","    for m in self.modules():\n","      if isinstance(m, nn.Conv2d):\n","        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","        m.weight.data.normal_(0, math.sqrt(2./n))\n","      elif isinstance(m, nn.BatchNorm2d):\n","        m.weight.data.fill_(1)\n","        m.bias.data.zero_()\n","\n","  def forward(self, x):\n","    out = self.layer1(x) #32x32\n","    out = self.layer2(out) #16x16\n","    out = self.layer3(out) #8x8\n","\n","    out = out.view(x.size(0), -1)\n","    out = self.fc(out)\n","    \n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cifar 10에 데이터를 받아오기 위해 드라이브 마운트\n","이후 입력을 nomalize하기 위해 Cifar 10 이미지의 RGB mean과 std를 넣고 DA진행"],"metadata":{"id":"Izc7fXMYsptH"}},{"cell_type":"code","metadata":{"id":"0ms-EJRI8Lib","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb0cb777-3291-4490-c2ca-9bc664e7f137"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"aySAwvLS8Mm3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"61f026eb-5bd4-4a37-80b5-9c1a82bbb584"},"source":["!ls '/content/drive/MyDrive/Colab Notebooks/data'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cifar-10-batches-py  cifar-10-python.tar.gz\n"]}]},{"cell_type":"code","metadata":{"id":"rU1mn1_u8f6F"},"source":["normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","transform_train = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(), normalize])\n","transform_valid = transforms.Compose([transforms.ToTensor(), normalize])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s2NXp-r88kO0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"42a6b44f-821a-4ba8-ff8f-5a8d08ece756"},"source":["trainset = datasets.CIFAR10('/content/drive/MyDrive/Colab Notebooks/data', train=True, transform=transform_train, download=True)\n","validset = datasets.CIFAR10('/content/drive/MyDrive/Colab Notebooks/data', train=False, transform=transform_valid, download=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","source":["pytorch의 DataLoaader를 이용해 받아온 Cifar 10이미지를 미니배치 크기 256 단위로 나눠줌"],"metadata":{"id":"CQcAO4w6tPzp"}},{"cell_type":"code","metadata":{"id":"tqcBu40J89k2"},"source":["trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True)\n","validloader = torch.utils.data.DataLoader(validset, batch_size=256, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EDkvwfTV9nht"},"source":["class AverageMeter(object):\n","  def __init__(self, name, fmt=':f'):\n","    self.name = name\n","    self.fmt = fmt\n","    self.reset()\n","  \n","  def reset(self):\n","    self.val = 0\n","    self.avg = 0\n","    self.sum = 0\n","    self.count = 0\n","  \n","  def update(self, val, n=1):\n","    self.val = val\n","    self.sum += val * n\n","    self.count += n\n","    self.avg = self.sum / self.count\n","\n","  def __str__(self):\n","    fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","    return fmtstr.format(**self.__dict__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X-hBn0w79q-N"},"source":["class ProgressMeter(object):\n","  def __init__(self, num_batches, *meters, prefix=\"\"):\n","    self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","    self.meters = meters\n","    self.prefix = prefix\n","\n","  def print(self, batch):\n","    entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","    entries += [str(meter) for meter in self.meters]\n","    print('\\t'.join(entries))\n","\n","  def _get_batch_fmtstr(self, num_batches):\n","    num_digits = len(str(num_batches // 1))\n","    fmt = '{:' + str(num_digits) + 'd}'\n","    return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C7kXdWmD9sd0"},"source":["def adjust_learning_rate(optimi, epoch, lr):\n","  if epoch>=100:\n","    0.02\n","  for param_group in optimi.param_groups:\n","    param_group['lr'] = lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8zwf_3cf9ymF"},"source":["def accuracy(output, target, topk=(1,)):\n","  with torch.no_grad():\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1,-1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","      correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","      res.append(correct_k.mul_(100.0 / batch_size))\n","    return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C6ntv4c990qE"},"source":["def train(train_loader, **kwargs):\n","  epoch = kwargs.get('epoch')\n","  model = kwargs.get('model')\n","  criterion = kwargs.get('criterion')\n","  optimizer = kwargs.get('optimizer')\n","\n","  batch_time = AverageMeter('Time', ':6.3f')\n","  data_time = AverageMeter('Data', ':6.3f')\n","  losses = AverageMeter('Loss', ':.4e')\n","  top1 = AverageMeter('Acc@1', ':6.2f')\n","  top5 = AverageMeter('Acc@5', ':6.2f')\n","  progress = ProgressMeter(len(train_loader), batch_time, data_time, losses, top1, top5, prefix=\"Epoch:[{}]\".format(epoch))\n","  \n","  \n","  model.train()\n","\n","  end = time.time()\n","  for i, (input, target) in enumerate(train_loader):\n","    data_time.update(time.time() - end)\n","    input = Variable(input).cuda()\n","    target = Variable(target).cuda()\n","\n","    output = model(input)\n","    loss = criterion(output, target)\n","\n","    acc1, acc5 = accuracy(output, target, topk=(1,5))\n","    losses.update(loss.item(), input.size(0))\n","    top1.update(acc1[0], input.size(0))\n","    top5.update(acc5[0], input.size(0))\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    batch_time.update(time.time() - end)\n","\n","    if i % 100==0:\n","      progress.print(i)\n","\n","  print('====> Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","\n","  return top1.avg, top5.avg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aBPcqldV92sM"},"source":["def validate(val_loader, model, criterion):\n","  batch_time = AverageMeter('Time', ':6.3f')\n","  losses = AverageMeter('Loss', ':.4e')\n","  top1 = AverageMeter('Acc@1', ':6.2f')\n","  top5 = AverageMeter('Acc@5', ':6.2f')\n","  progress = ProgressMeter(len(val_loader), batch_time, losses, top1, top5, prefix='Test: ')\n","\n","  model.eval()\n","\n","  with torch.no_grad():\n","    end = time.time()\n","    for i, (input, target) in enumerate(val_loader):\n","      input = Variable(input).cuda()\n","      target = target.cuda(non_blocking=True)\n","\n","      output = model(input)\n","      loss = criterion(output, target)\n","\n","      acc1, acc5 = accuracy(output, target, topk=(1,5))\n","      losses.update(loss.item(), input.size(0))\n","      top1.update(acc1[0], input.size(0))\n","      top5.update(acc5[0], input.size(0))\n","\n","      batch_time.update(time.time() - end)\n","\n","      if i % 100 == 0:\n","        progress.print(i)\n","\n","      end = time.time()\n","\n","    print('====> Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","\n","  return top1.avg, top5.avg"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["마스킹을 진행한 parameter의 경우 optimizer로 weight를 update할 필요가 없으므로 \n","weight에 mask가 없는 parameter에 대해서만 update"],"metadata":{"id":"cLxCmCP3uJWG"}},{"cell_type":"code","metadata":{"id":"hwM8utV5nRYy"},"source":["maskedmodel = MaskToyNet().cuda()\n","optimizer = optim.Adam([param for name, param in maskedmodel.named_parameters() if 'mask' not in name]) # list of all parameter except mask tensor\n","criterion = nn.CrossEntropyLoss().cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_R-kNX294HF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f5d53c46-9fc3-4eaa-a21e-57fb4a989a72"},"source":["lr = 1e-4\n","best_acc1 = 0\n","best_acc5 = 0\n","\n","for epoch in range(5):\n","  adjust_learning_rate(optimizer, epoch, lr)\n","\n","  print(\"Epoch : {}, lr : {}\".format(epoch, optimizer.param_groups[0]['lr']))\n","  print('===> [ Training ]')\n","  acc1_train, acc5_train = train(trainloader,\n","                                 epoch=epoch, model=maskedmodel,\n","                                 criterion=criterion, optimizer=optimizer)\n","  \n","  print('===> [ Validation ]')\n","  acc1_valid, acc5_valid = validate(validloader, maskedmodel, criterion)\n","\n","  best_acc1 = max(acc1_valid, best_acc1)\n","  best_acc5 = max(acc5_valid, best_acc5)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : 0, lr : 0.0001\n","===> [ Training ]\n","Epoch:[0][  0/196]\tTime  0.095 ( 0.095)\tData  0.087 ( 0.087)\tLoss 2.3546e+00 (2.3546e+00)\tAcc@1  12.11 ( 12.11)\tAcc@5  50.39 ( 50.39)\n","Epoch:[0][100/196]\tTime  7.786 ( 3.964)\tData  7.779 ( 3.957)\tLoss 1.9269e+00 (2.0486e+00)\tAcc@1  34.38 ( 26.12)\tAcc@5  80.47 ( 75.05)\n","====> Acc@1 30.594 Acc@5 79.786\n","===> [ Validation ]\n","Test: [ 0/40]\tTime  0.043 ( 0.043)\tLoss 1.6702e+00 (1.6702e+00)\tAcc@1  42.19 ( 42.19)\tAcc@5  90.23 ( 90.23)\n","====> Acc@1 40.350 Acc@5 87.960\n","Epoch : 1, lr : 0.0001\n","===> [ Training ]\n","Epoch:[1][  0/196]\tTime  0.091 ( 0.091)\tData  0.084 ( 0.084)\tLoss 1.8217e+00 (1.8217e+00)\tAcc@1  35.55 ( 35.55)\tAcc@5  85.55 ( 85.55)\n","Epoch:[1][100/196]\tTime  7.783 ( 3.935)\tData  7.776 ( 3.928)\tLoss 1.7018e+00 (1.6919e+00)\tAcc@1  39.06 ( 39.38)\tAcc@5  88.28 ( 87.75)\n","====> Acc@1 40.294 Acc@5 88.490\n","===> [ Validation ]\n","Test: [ 0/40]\tTime  0.046 ( 0.046)\tLoss 1.5824e+00 (1.5824e+00)\tAcc@1  44.92 ( 44.92)\tAcc@5  91.80 ( 91.80)\n","====> Acc@1 45.750 Acc@5 91.350\n","Epoch : 2, lr : 0.0001\n","===> [ Training ]\n","Epoch:[2][  0/196]\tTime  0.075 ( 0.075)\tData  0.068 ( 0.068)\tLoss 1.6028e+00 (1.6028e+00)\tAcc@1  45.31 ( 45.31)\tAcc@5  89.84 ( 89.84)\n","Epoch:[2][100/196]\tTime  7.673 ( 3.876)\tData  7.666 ( 3.868)\tLoss 1.5053e+00 (1.5631e+00)\tAcc@1  42.58 ( 43.77)\tAcc@5  92.58 ( 90.11)\n","====> Acc@1 44.362 Acc@5 90.508\n","===> [ Validation ]\n","Test: [ 0/40]\tTime  0.045 ( 0.045)\tLoss 1.3713e+00 (1.3713e+00)\tAcc@1  44.92 ( 44.92)\tAcc@5  93.75 ( 93.75)\n","====> Acc@1 47.880 Acc@5 92.440\n","Epoch : 3, lr : 0.0001\n","===> [ Training ]\n","Epoch:[3][  0/196]\tTime  0.081 ( 0.081)\tData  0.073 ( 0.073)\tLoss 1.5510e+00 (1.5510e+00)\tAcc@1  45.31 ( 45.31)\tAcc@5  85.55 ( 85.55)\n","Epoch:[3][100/196]\tTime  7.807 ( 3.950)\tData  7.800 ( 3.943)\tLoss 1.5156e+00 (1.4899e+00)\tAcc@1  47.66 ( 46.24)\tAcc@5  93.36 ( 91.34)\n","====> Acc@1 46.432 Acc@5 91.716\n","===> [ Validation ]\n","Test: [ 0/40]\tTime  0.046 ( 0.046)\tLoss 1.3135e+00 (1.3135e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  94.92 ( 94.92)\n","====> Acc@1 51.020 Acc@5 93.640\n","Epoch : 4, lr : 0.0001\n","===> [ Training ]\n","Epoch:[4][  0/196]\tTime  0.082 ( 0.082)\tData  0.075 ( 0.075)\tLoss 1.4837e+00 (1.4837e+00)\tAcc@1  48.44 ( 48.44)\tAcc@5  91.02 ( 91.02)\n","Epoch:[4][100/196]\tTime  7.808 ( 3.943)\tData  7.801 ( 3.936)\tLoss 1.4297e+00 (1.4376e+00)\tAcc@1  47.27 ( 47.69)\tAcc@5  92.97 ( 92.52)\n","====> Acc@1 48.404 Acc@5 92.574\n","===> [ Validation ]\n","Test: [ 0/40]\tTime  0.047 ( 0.047)\tLoss 1.2849e+00 (1.2849e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  93.75 ( 93.75)\n","====> Acc@1 52.080 Acc@5 93.950\n"]}]},{"cell_type":"code","metadata":{"id":"h17IufHcXjRC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b9507c27-f721-4fbe-e7c0-8e3a6e3b3a2b"},"source":["### Find Threshold\n","pruning_ratio = 0.2 # We can modify\n","\n","weights = np.array([])\n","for name, param in maskedmodel.named_parameters():\n","  if len(param.size()) == 4 and 'mask' not in name: #only conv weight\n","    weights = np.append(weights, param.data.view(-1).abs().cpu().numpy()) # reshape to 1 dimension, absolute value of param, use CPU tensor, change to numpy\n","\n","threshold = np.sort(weights)[int(weights.shape[0]* pruning_ratio)] # the number of weights array\n","print(f'Threshold : {threshold} with pruning ratio : {pruning_ratio}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Threshold : 0.01622624695301056 with pruning ratio : 0.2\n"]}]},{"cell_type":"markdown","source":["fine-tuning"],"metadata":{"id":"wzLiP8cLXtM-"}},{"cell_type":"code","source":["### Additional Training\n","lr = 1e-4\n","best_acc1 = 0\n","best_acc5 = 0\n","\n","for epoch in range(2):\n","  adjust_learning_rate(optimizer, epoch, lr)\n","\n","  print(\"Epoch : {}, lr : {}\".format(epoch, optimizer.param_groups[0]['lr']))\n","  print('===> [ Training ]')\n","  acc1_train, acc5_train = train(trainloader,\n","                                 epoch=epoch, model=maskedmodel,\n","                                 criterion=criterion, optimizer=optimizer)\n","  \n","  \n","  print('===> [ Validation ]')\n","  acc1_valid, acc5_valid = validate(validloader, maskedmodel, criterion)\n","\n","  best_acc1 = max(acc1_valid, best_acc1)\n","  best_acc5 = max(acc5_valid, best_acc5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPkCBmHLU6Qa","outputId":"e45729c7-15d2-4021-a403-311281e25fac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : 0, lr : 0.0001\n","===> [ Training ]\n","Epoch:[0][  0/196]\tTime  0.082 ( 0.082)\tData  0.075 ( 0.075)\tLoss 1.4124e+00 (1.4124e+00)\tAcc@1  48.44 ( 48.44)\tAcc@5  94.14 ( 94.14)\n","Epoch:[0][100/196]\tTime  7.795 ( 3.954)\tData  7.788 ( 3.947)\tLoss 1.4283e+00 (1.4033e+00)\tAcc@1  48.05 ( 49.97)\tAcc@5  90.23 ( 92.62)\n","====> Acc@1 49.782 Acc@5 92.532\n","===> [ Validation ]\n","Test: [ 0/40]\tTime  0.046 ( 0.046)\tLoss 1.3688e+00 (1.3688e+00)\tAcc@1  51.17 ( 51.17)\tAcc@5  93.75 ( 93.75)\n","====> Acc@1 53.810 Acc@5 94.500\n","Epoch : 1, lr : 0.0001\n","===> [ Training ]\n","Epoch:[1][  0/196]\tTime  0.077 ( 0.077)\tData  0.070 ( 0.070)\tLoss 1.2666e+00 (1.2666e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  94.92 ( 94.92)\n","Epoch:[1][100/196]\tTime  7.795 ( 3.957)\tData  7.788 ( 3.950)\tLoss 1.3822e+00 (1.3825e+00)\tAcc@1  48.05 ( 50.63)\tAcc@5  91.80 ( 93.04)\n","====> Acc@1 50.976 Acc@5 93.200\n","===> [ Validation ]\n","Test: [ 0/40]\tTime  0.045 ( 0.045)\tLoss 1.2629e+00 (1.2629e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  94.53 ( 94.53)\n","====> Acc@1 54.430 Acc@5 94.700\n"]}]},{"cell_type":"code","source":["model = ToyNet().cuda()\n","optimizer = optim.Adam(model.parameters()) # list of all parameter except mask tensor\n","criterion = nn.CrossEntropyLoss().cuda()"],"metadata":{"id":"OJUeW9hcVC-5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["기존 모델과 성능비교"],"metadata":{"id":"B2nKRXtGYG9f"}},{"cell_type":"code","source":["lr = 1e-4\n","best_acc1 = 0\n","best_acc5 = 0\n","\n","for epoch in range(7):\n","  adjust_learning_rate(optimizer, epoch, lr)\n","\n","  print(\"Epoch : {}, lr : {}\".format(epoch, optimizer.param_groups[0]['lr']))\n","  print('===> [ Training ]')\n","  acc1_train, acc5_train = train(trainloader,\n","                                 epoch=epoch, model=model,\n","                                 criterion=criterion, optimizer=optimizer)\n","  \n","  print('===> [ Validation ]')\n","  acc1_valid, acc5_valid = validate(validloader, model, criterion)\n","\n","  best_acc1 = max(acc1_valid, best_acc1)\n","  best_acc5 = max(acc5_valid, best_acc5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zw-GBmwzV23J","outputId":"51b7933f-133f-4d19-99fd-d20649d8caf8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : 0, lr : 0.0001\n","===> [ Training ]\n","Epoch:[0][  0/196]\tTime  0.101 ( 0.101)\tData  0.094 ( 0.094)\tLoss 2.3312e+00 (2.3312e+00)\tAcc@1  16.41 ( 16.41)\tAcc@5  51.95 ( 51.95)\n","Epoch:[0][100/196]\tTime  8.935 ( 4.104)\tData  8.928 ( 4.096)\tLoss 1.7952e+00 (1.9998e+00)\tAcc@1  34.38 ( 27.39)\tAcc@5  88.67 ( 77.74)\n","====> Acc@1 32.100 Acc@5 81.758\n","===> [ Validation ]\n","Test: [ 0/40]\tTime  0.047 ( 0.047)\tLoss 1.5969e+00 (1.5969e+00)\tAcc@1  41.02 ( 41.02)\tAcc@5  89.45 ( 89.45)\n","====> Acc@1 42.460 Acc@5 88.710\n","Epoch : 1, lr : 0.0001\n","===> [ Training ]\n","Epoch:[1][  0/196]\tTime  0.079 ( 0.079)\tData  0.072 ( 0.072)\tLoss 1.6972e+00 (1.6972e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  85.16 ( 85.16)\n","Epoch:[1][100/196]\tTime  7.921 ( 4.010)\tData  7.914 ( 4.003)\tLoss 1.6133e+00 (1.6621e+00)\tAcc@1  46.48 ( 40.59)\tAcc@5  88.28 ( 88.24)\n","====> Acc@1 41.668 Acc@5 88.946\n","===> [ Validation ]\n","Test: [ 0/40]\tTime  0.044 ( 0.044)\tLoss 1.5534e+00 (1.5534e+00)\tAcc@1  41.02 ( 41.02)\tAcc@5  89.45 ( 89.45)\n","====> Acc@1 45.150 Acc@5 91.320\n","Epoch : 2, lr : 0.0001\n","===> [ Training ]\n","Epoch:[2][  0/196]\tTime  0.080 ( 0.080)\tData  0.073 ( 0.073)\tLoss 1.6098e+00 (1.6098e+00)\tAcc@1  44.53 ( 44.53)\tAcc@5  89.45 ( 89.45)\n","Epoch:[2][100/196]\tTime  7.639 ( 3.872)\tData  7.632 ( 3.865)\tLoss 1.5343e+00 (1.5482e+00)\tAcc@1  45.70 ( 44.29)\tAcc@5  89.06 ( 90.32)\n","====> Acc@1 44.870 Acc@5 90.692\n","===> [ Validation ]\n","Test: [ 0/40]\tTime  0.051 ( 0.051)\tLoss 1.2982e+00 (1.2982e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  95.70 ( 95.70)\n","====> Acc@1 48.860 Acc@5 92.840\n","Epoch : 3, lr : 0.0001\n","===> [ Training ]\n","Epoch:[3][  0/196]\tTime  0.083 ( 0.083)\tData  0.076 ( 0.076)\tLoss 1.4855e+00 (1.4855e+00)\tAcc@1  46.48 ( 46.48)\tAcc@5  93.36 ( 93.36)\n","Epoch:[3][100/196]\tTime  7.712 ( 3.912)\tData  7.705 ( 3.904)\tLoss 1.5222e+00 (1.4842e+00)\tAcc@1  46.88 ( 46.79)\tAcc@5  90.62 ( 91.66)\n","====> Acc@1 47.594 Acc@5 91.846\n","===> [ Validation ]\n","Test: [ 0/40]\tTime  0.047 ( 0.047)\tLoss 1.2727e+00 (1.2727e+00)\tAcc@1  53.52 ( 53.52)\tAcc@5  96.09 ( 96.09)\n","====> Acc@1 52.030 Acc@5 93.840\n","Epoch : 4, lr : 0.0001\n","===> [ Training ]\n","Epoch:[4][  0/196]\tTime  0.076 ( 0.076)\tData  0.069 ( 0.069)\tLoss 1.4137e+00 (1.4137e+00)\tAcc@1  47.27 ( 47.27)\tAcc@5  94.14 ( 94.14)\n","Epoch:[4][100/196]\tTime  7.788 ( 3.934)\tData  7.780 ( 3.927)\tLoss 1.4850e+00 (1.4312e+00)\tAcc@1  44.92 ( 48.58)\tAcc@5  91.02 ( 92.44)\n","====> Acc@1 49.376 Acc@5 92.492\n","===> [ Validation ]\n","Test: [ 0/40]\tTime  0.055 ( 0.055)\tLoss 1.3087e+00 (1.3087e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  94.53 ( 94.53)\n","====> Acc@1 53.630 Acc@5 94.280\n","Epoch : 5, lr : 0.0001\n","===> [ Training ]\n","Epoch:[5][  0/196]\tTime  0.078 ( 0.078)\tData  0.070 ( 0.070)\tLoss 1.3975e+00 (1.3975e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  91.80 ( 91.80)\n","Epoch:[5][100/196]\tTime  7.692 ( 3.886)\tData  7.685 ( 3.878)\tLoss 1.3648e+00 (1.3856e+00)\tAcc@1  51.95 ( 50.17)\tAcc@5  92.19 ( 93.09)\n","====> Acc@1 50.668 Acc@5 93.158\n","===> [ Validation ]\n","Test: [ 0/40]\tTime  0.047 ( 0.047)\tLoss 1.3589e+00 (1.3589e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  94.53 ( 94.53)\n","====> Acc@1 54.830 Acc@5 94.600\n","Epoch : 6, lr : 0.0001\n","===> [ Training ]\n","Epoch:[6][  0/196]\tTime  0.077 ( 0.077)\tData  0.069 ( 0.069)\tLoss 1.3776e+00 (1.3776e+00)\tAcc@1  49.61 ( 49.61)\tAcc@5  92.19 ( 92.19)\n","Epoch:[6][100/196]\tTime  8.920 ( 4.784)\tData  8.913 ( 4.776)\tLoss 1.3080e+00 (1.3513e+00)\tAcc@1  56.64 ( 51.68)\tAcc@5  92.97 ( 93.30)\n","====> Acc@1 52.034 Acc@5 93.478\n","===> [ Validation ]\n","Test: [ 0/40]\tTime  0.048 ( 0.048)\tLoss 1.2586e+00 (1.2586e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  94.14 ( 94.14)\n","====> Acc@1 56.170 Acc@5 94.840\n"]}]},{"cell_type":"code","source":["# 파라미터 개수 : torch.count_nonzero"],"metadata":{"id":"9URisaAZWHfg"},"execution_count":null,"outputs":[]}]}