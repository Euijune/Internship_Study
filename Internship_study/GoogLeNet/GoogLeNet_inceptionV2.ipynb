{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GoogLeNet_inceptionV2.ipynb","provenance":[],"collapsed_sections":["LsOcL8g11Z5Y","g058eZ-Z1tOh"],"machine_shape":"hm","authorship_tag":"ABX9TyNSuwdCrfyrlsM5t+4nKwzb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ffee974466cc4d348319c970307e6e74":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5f5e95958c20448d94cb8cd8719fc3cc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d46b47880d9c413eab9f3a54131d6a00","IPY_MODEL_9b48bc51bbc041d98d5b2eb19e82b59a","IPY_MODEL_e287f095bad7421d87c5cd4aeed0eec8"]}},"5f5e95958c20448d94cb8cd8719fc3cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d46b47880d9c413eab9f3a54131d6a00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c27a3209d07f4725b6c58f93faca63e8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b4521b232ddb4713b5aa978a72393ead"}},"9b48bc51bbc041d98d5b2eb19e82b59a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_487d35d2e5ae46a287518e9ce6dbc2ed","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":169001437,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":169001437,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_506a5076a9e8431f82e96ec7c9bd8e75"}},"e287f095bad7421d87c5cd4aeed0eec8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_72196d43467944bda9a5194fedf3b7cb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 169001984/? [00:04&lt;00:00, 34441093.17it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eeb6a9d8e4d64a679039a32d65077281"}},"c27a3209d07f4725b6c58f93faca63e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b4521b232ddb4713b5aa978a72393ead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"487d35d2e5ae46a287518e9ce6dbc2ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"506a5076a9e8431f82e96ec7c9bd8e75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72196d43467944bda9a5194fedf3b7cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eeb6a9d8e4d64a679039a32d65077281":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"mbcuodGG1Rgg"},"source":["##**Import all neceassary packages**"]},{"cell_type":"code","metadata":{"id":"XB-tD0SQ2qJr"},"source":["import numpy as np\n","import time\n","import copy\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torch.backends.cudnn as cudnn\n","from torch.optim.lr_scheduler import MultiStepLR, StepLR\n","\n","from torchvision import datasets, transforms\n","from tqdm.notebook import tqdm as tqdm\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t7dn0AtK1Wi1"},"source":["##**Model - Define GoogLeNet Model**"]},{"cell_type":"markdown","metadata":{"id":"5IKXNtXt1sBT"},"source":["### conv_block, gridReduction, Inception x3, x5, x2, auxiliary classifier"]},{"cell_type":"code","metadata":{"id":"3iEU5aYI1qxK"},"source":["class conv_block(nn.Module):\n","    def __init__(self, in_channels, out_channels, **kwargs):\n","        super(conv_block, self).__init__()\n","\n","        self.conv_layer = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, **kwargs),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","        )\n","    \n","    def forward(self, x):\n","        return self.conv_layer(x)\n","\n","class GridReduction(nn.Module):\n","    def __init__(self, in_fts, out_fts):\n","        super(GridReduction, self).__init__()\n","        self.branch1 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts, kernel_size=(3, 3), stride=(2, 2))\n","        )\n","\n","        self.branch2 = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2))\n","        )\n","\n","    def forward(self, input_img):\n","        o1 = self.branch1(input_img)\n","        o2 = self.branch2(input_img)\n","        x = torch.cat([o1, o2], dim=1)\n","        return x\n","\n","class Inceptionx3(nn.Module):\n","    def __init__(self, in_fts, out_fts):\n","        super(Inceptionx3, self).__init__()\n","        self.branch1 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[0], kernel_size=(1, 1), stride=(1, 1)),\n","            nn.Conv2d(in_channels=out_fts[0], out_channels=out_fts[0], kernel_size=(3, 3), stride=(1, 1), padding=1),\n","            nn.Conv2d(in_channels=out_fts[0], out_channels=out_fts[0], kernel_size=(3, 3), stride=(1, 1), padding=1)\n","        )\n","        self.branch2 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[1], kernel_size=(1, 1), stride=(1, 1)),\n","            nn.Conv2d(in_channels=out_fts[1], out_channels=out_fts[1], kernel_size=(3, 3), stride=(1, 1), padding=1),\n","        )\n","        self.branch3 = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=(3, 3), stride=(1, 1), padding=1),\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[2], kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        self.branch4 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[3], kernel_size=(1, 1), stride=(1, 1))\n","        )\n","\n","    def forward(self, input_img):\n","        o1 = self.branch1(input_img)\n","        o2 = self.branch2(input_img)\n","        o3 = self.branch3(input_img)\n","        o4 = self.branch4(input_img)\n","        x = torch.cat([o1, o2, o3, o4], dim=1)\n","        return x\n","\n","class Inceptionx5(nn.Module):\n","    def __init__(self, in_fts, out_fts, n=7):\n","        super(Inceptionx5, self).__init__()\n","        self.branch1 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[0], kernel_size=(1, 1), stride=(1, 1)),\n","            nn.Conv2d(in_channels=out_fts[0], out_channels=out_fts[0], kernel_size=(1, n), stride=(1, 1),\n","                      padding=(0, n // 2)),\n","            nn.Conv2d(in_channels=out_fts[0], out_channels=out_fts[0], kernel_size=(n, 1), stride=(1, 1),\n","                      padding=(n // 2, 0)),\n","            nn.Conv2d(in_channels=out_fts[0], out_channels=out_fts[0], kernel_size=(1, n), stride=(1, 1),\n","                      padding=(0, n // 2)),\n","            nn.Conv2d(in_channels=out_fts[0], out_channels=out_fts[0], kernel_size=(n, 1), stride=(1, 1),\n","                      padding=(n // 2, 0)),\n","        )\n","        self.branch2 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[1], kernel_size=(1, 1), stride=(1, 1)),\n","            nn.Conv2d(in_channels=out_fts[1], out_channels=out_fts[1], kernel_size=(1, n), stride=(1, 1),\n","                      padding=(0, n // 2)),\n","            nn.Conv2d(in_channels=out_fts[1], out_channels=out_fts[1], kernel_size=(n, 1), stride=(1, 1),\n","                      padding=(n // 2, 0)),\n","        )\n","        self.branch3 = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=(3, 3), stride=(1, 1), padding=1),\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[2], kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        self.branch4 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[3], kernel_size=(1, 1), stride=(1, 1))\n","        )\n","\n","    def forward(self, input_img):\n","        o1 = self.branch1(input_img)\n","        o2 = self.branch2(input_img)\n","        o3 = self.branch3(input_img)\n","        o4 = self.branch4(input_img)\n","        x = torch.cat([o1, o2, o3, o4], dim=1)\n","        return x\n","\n","class Inceptionx2(nn.Module):\n","    def __init__(self, in_fts, out_fts):\n","        super(Inceptionx2, self).__init__()\n","        self.branch1 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[0] // 4, kernel_size=(1, 1)),\n","            nn.Conv2d(in_channels=out_fts[0] // 4, out_channels=out_fts[0] // 4, kernel_size=(3, 3), stride=(1, 1),\n","                      padding=1)\n","        )\n","        self.subbranch1_1 = nn.Sequential(\n","            nn.Conv2d(in_channels=out_fts[0] // 4, out_channels=out_fts[0], kernel_size=(1, 3), stride=(1, 1),\n","                      padding=(0, 3 // 2))\n","        )\n","        self.subbranch1_2 = nn.Sequential(\n","            nn.Conv2d(in_channels=out_fts[0] // 4, out_channels=out_fts[1], kernel_size=(3, 1), stride=(1, 1),\n","                      padding=(3 // 2, 0))\n","        )\n","        self.branch2 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[2] // 4, kernel_size=(1, 1))\n","        )\n","        self.subbranch2_1 = nn.Sequential(\n","            nn.Conv2d(in_channels=out_fts[2] // 4, out_channels=out_fts[2], kernel_size=(1, 3), stride=(1, 1),\n","                      padding=(0, 3 // 2))\n","        )\n","        self.subbranch2_2 = nn.Sequential(\n","            nn.Conv2d(in_channels=out_fts[2] // 4, out_channels=out_fts[3], kernel_size=(3, 1), stride=(1, 1),\n","                      padding=(3 // 2, 0))\n","        )\n","        self.branch3 = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=1),\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[4], kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        self.branch4 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[5], kernel_size=(1, 1), stride=(1, 1))\n","        )\n","\n","    def forward(self, input_img):\n","        o1 = self.branch1(input_img)\n","        o11 = self.subbranch1_1(o1)\n","        o12 = self.subbranch1_2(o1)\n","        o2 = self.branch2(input_img)\n","        o21 = self.subbranch2_1(o2)\n","        o22 = self.subbranch2_2(o2)\n","        o3 = self.branch3(input_img)\n","        o4 = self.branch4(input_img)\n","        x = torch.cat([o11, o12, o21, o22, o3, o4], dim=1)\n","        return x\n","\n","# auxiliary classifier의 loss는 0.3이 곱해지고, 최종 loss에 추가합니다. 정규화 효과가 있습니다. \n","class InceptionAux(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super(InceptionAux, self).__init__()\n","\n","        self.conv = nn.Sequential(\n","            nn.AdaptiveAvgPool2d(output_size=5),\n","            conv_block(in_channels, 128, kernel_size=1),\n","        )\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(5*5*128, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.3),\n","            nn.Linear(1024, num_classes),\n","        )\n","\n","    def forward(self,x):\n","        x = self.conv(x)\n","        x = x.view(x.shape[0], -1)\n","        x = self.fc(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MhEYI32X11rW"},"source":["### Declare Inception V2 model"]},{"cell_type":"code","metadata":{"id":"8NDl4D5s1agB"},"source":["class GoogLeNet_v2(nn.Module):\n","    def __init__(self, aux_logits=True, num_classes=10, init_weights=True):\n","        super(GoogLeNet_v2, self).__init__()\n","        assert aux_logits == True or aux_logits == False\n","        self.aux_logits = aux_logits\n","\n","        # conv_block takes in_channels, out_channels, kernel_size, stride, padding\n","        # Inception block takes out1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool\n","\n","        # 3 X 299 X 299\n","        self.conv1 = conv_block(3, 32, kernel_size=3, stride=2)\n","        self.conv2 = conv_block(32, 32, kernel_size=3, stride=1)\n","        self.conv3 = conv_block(32, 64, kernel_size=3, stride=1, padding=1)\n","        # 64 X 147 X 147\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n","        # 64 X 73 X 73\n","        self.conv4 = conv_block(64, 80, kernel_size=3, stride=1)\n","        self.conv5 = conv_block(80, 192, kernel_size=3, stride=2)\n","        self.conv6 = conv_block(192, 288, kernel_size=3, stride=1, padding=1)\n","        # 288 X 35 X 35\n","        list_incept = [Inceptionx3(in_fts=288, out_fts=[96, 96, 96, 96]),\n","                       Inceptionx3(in_fts=4 * 96, out_fts=[96, 96, 96, 96]),\n","                       Inceptionx3(in_fts=4 * 96, out_fts=[96, 96, 96, 96])]\n","\n","        self.inceptx3 = nn.Sequential(*list_incept)\n","        # 384 X 17 X 17\n","        self.grid_redn_1 = GridReduction(in_fts=4 * 96, out_fts=384)\n","        # 768 X 17 X 17\n","        if self.aux_logits:\n","            self.aux_classifier = InceptionAux(768, num_classes)\n","        else:\n","            self.aux_classifier = None\n","        # 768 X 17 X 17\n","        list_incept = [Inceptionx5(in_fts=768, out_fts=[160, 160, 160, 160]),\n","                       Inceptionx5(in_fts=4 * 160, out_fts=[160, 160, 160, 160]),\n","                       Inceptionx5(in_fts=4 * 160, out_fts=[160, 160, 160, 160]),\n","                       Inceptionx5(in_fts=4 * 160, out_fts=[160, 160, 160, 160]),\n","                       Inceptionx5(in_fts=4 * 160, out_fts=[160, 160, 160, 160])]\n","\n","        self.inceptx5 = nn.Sequential(*list_incept)\n","        # 640 X 8 X 8\n","        self.grid_redn_2 = GridReduction(in_fts=4 * 160, out_fts=640)\n","        # 1280 X 8 X 8\n","        list_incept = [Inceptionx2(in_fts=1280, out_fts=[256, 256, 192, 192, 64, 64]),\n","                       Inceptionx2(in_fts=1024, out_fts=[384, 384, 384, 384, 256, 256])]\n","\n","        self.inceptx2 = nn.Sequential(*list_incept)\n","        # 2048 X 8 X 8\n","        self.avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n","        # 2048 X 1 X 1\n","        self.fc = nn.Linear(2048, num_classes)\n","\n","    def forward(self, input_img):\n","        N = input_img.shape[0]\n","        x = self.conv1(input_img)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.maxpool(x)\n","        x = self.conv4(x)\n","        x = self.conv5(x)\n","        x = self.conv6(x)\n","        x = self.inceptx3(x)\n","        x = self.grid_redn_1(x)\n","        aux_out = self.aux_classifier(x)\n","        x = self.inceptx5(x)\n","        x = self.grid_redn_2(x)\n","        x = self.inceptx2(x)\n","        x = self.avgpool(x)\n","        x = x.reshape(N, -1)\n","        x = self.fc(x)\n","        if self.aux_logits and self.training:\n","            return x, aux_out\n","        else:\n","            return x "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LsOcL8g11Z5Y"},"source":["##**Utils**"]},{"cell_type":"code","metadata":{"id":"7LpvhzjP1mGa"},"source":["class AverageMeter(object):\n","    r\"\"\"Computes and stores the average and current value\n","    \"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt # 출력하는 소수의 자릿수\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def print(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print('\\t'.join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n","    \"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        # _, pred = output.topk(maxk, 1, True, True)\n","        # pred = pred.t()\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n","        _, idx = output.sort(descending=True)\n","        pred = idx[:,:maxk]\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g058eZ-Z1tOh"},"source":["##**Cutout: Main Code for Applying Cutout data augmentation**"]},{"cell_type":"code","metadata":{"id":"WU7zK9wi1mlr"},"source":["class Cutout(object):\n","    \"\"\"Randomly mask out one or more patches from an image.\n","\n","    Args:\n","        n_holes (int): Number of patches to cut out of each image.\n","        length (int): The length (in pixels) of each square patch.\n","    \"\"\"\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        \"\"\"\n","        Args:\n","            img (Tensor): Tensor image of size (C, H, W).\n","        Returns:\n","            Tensor: Image with n_holes of dimension length x length cut out of it.\n","        \"\"\"\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","\n","        return img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4vbg5_d92J7r"},"source":["##**Parameter Settings**"]},{"cell_type":"code","metadata":{"id":"e7SdlZce2KlG"},"source":["dataset = 'cifar100' # cifar10 or cifar100\n","model = 'GoogLeNetV2' # resnet18, resnet50, resnet101, GoogLeNetV1\n","batch_size = 64  # Input batch size for training (default: 128)\n","epochs = 100 # Number of epochs to train (default: 200)\n","learning_rate = 1e-3 # Learning rate\n","data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n","sanity_check = False\n","path2weights = './drive/MyDrive/DeepLearning_competition/Internship/Week_1/GoogLeNet_V2.pth'    # route for model saving\n","\n","cutout = True # Apply Cutout?\n","n_holes = 1 # Number of holes to cut out from image\n","length = 16 # Length of the holes\n","\n","seed = 0 # Random seed (default: 0)\n","print_freq = 100\n","cuda = torch.cuda.is_available()\n","cudnn.benchmark = True  # Should make training should go faster for large models\n","\n","torch.manual_seed(seed)\n","if cuda:\n","    torch.cuda.manual_seed(seed)\n","\n","test_id = dataset + '_' + model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xxsNHUuR2OLD"},"source":["##**Load and preprocess data**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":103,"referenced_widgets":["ffee974466cc4d348319c970307e6e74","5f5e95958c20448d94cb8cd8719fc3cc","d46b47880d9c413eab9f3a54131d6a00","9b48bc51bbc041d98d5b2eb19e82b59a","e287f095bad7421d87c5cd4aeed0eec8","c27a3209d07f4725b6c58f93faca63e8","b4521b232ddb4713b5aa978a72393ead","487d35d2e5ae46a287518e9ce6dbc2ed","506a5076a9e8431f82e96ec7c9bd8e75","72196d43467944bda9a5194fedf3b7cb","eeb6a9d8e4d64a679039a32d65077281"]},"id":"G0xxABoH2Odv","executionInfo":{"status":"ok","timestamp":1631680185939,"user_tz":-540,"elapsed":6990,"user":{"displayName":"ᄋᄋᄌ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07872107978641370856"}},"outputId":"3a44ed27-1496-4bbe-ce1a-b0a4c30fb7ed"},"source":["# Image Preprocessing\n","normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n","                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n","\n","# train\n","train_transform = transforms.Compose([])\n","\n","train_transform.transforms.append(transforms.Resize((299, 299)))\n","if data_augmentation:\n","    train_transform.transforms.append(transforms.RandomCrop(299, 299))\n","    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n","train_transform.transforms.append(transforms.ToTensor())\n","train_transform.transforms.append(normalize)\n","\n","if cutout:\n","    train_transform.transforms.append(Cutout(n_holes=n_holes, length=length))\n","\n","# test\n","test_transform = transforms.Compose([\n","    transforms.Resize((299, 299)),\n","    transforms.ToTensor(),\n","    normalize])\n","\n","if dataset == 'cifar10':\n","    num_classes = 10\n","    train_dataset = datasets.CIFAR10(root='data/',\n","                                     train=True,\n","                                     transform=train_transform,\n","                                     download=True)\n","\n","    test_dataset = datasets.CIFAR10(root='data/',\n","                                    train=False,\n","                                    transform=test_transform,\n","                                    download=True)\n","elif dataset == 'cifar100':\n","    num_classes = 100\n","    train_dataset = datasets.CIFAR100(root='data/',\n","                                      train=True,\n","                                      transform=train_transform,\n","                                      download=True)\n","\n","    test_dataset = datasets.CIFAR100(root='data/',\n","                                     train=False,\n","                                     transform=test_transform,\n","                                     download=True)\n","\n","\n","# Data Loader (Input Pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           pin_memory=True,\n","                                           num_workers=2)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          pin_memory=True,\n","                                          num_workers=2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ffee974466cc4d348319c970307e6e74","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/169001437 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting data/cifar-100-python.tar.gz to data/\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","metadata":{"id":"BUHCSAbQ5HMo"},"source":["##**Main Training**"]},{"cell_type":"code","metadata":{"id":"6cyFfBNQ5NY9"},"source":["def train(train_loader, epoch, model, optimizer, criterion):\n","    batch_time = AverageMeter('Time', ':6.3f') # 소수 출력 형식지정\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(len(train_loader), batch_time, losses,\n","                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n","    # switch to train mode\n","    model.train()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    running_loss = 0.0\n","    running_metric = 0.0\n","    len_data = len(train_loader.dataset)\n","    end = time.time()\n","    for i, (input, target) in enumerate(train_loader):\n","        # measure data loading time\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        # compute output\n","        output = model(input) # output = (x, aux_out)\n","\n","        loss_b, metric_b = loss_batch(criterion, output, target, optimizer)\n","        running_loss += loss_b\n","\n","        if metric_b is not None:\n","            running_metric += metric_b\n","        \n","        if sanity_check is True:\n","            break\n","\n","        # measure accuracy and record loss, accuracy \n","        acc1, acc5 = accuracy(output[0], target, topk=(1, 5))\n","        losses.update(loss_b, input.size(0))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            progress.print(i)\n","    \n","    loss = running_loss / len_data\n","    metric = running_metric / len_data\n","\n","    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","def test(test_loader,epoch, model):\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","\n","    # switch to test mode\n","    model.eval()\n","    for i,(input,target) in enumerate(test_loader):\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        output = model(input)\n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B0R3_dP_zwVT"},"source":["def get_lr(opt):\n","    for param_group in opt.param_groups:\n","        return param_group['lr']\n","\n","\n","\n","def metric_batch(output, target):\n","    pred = output.argmax(dim=1, keepdim=True)\n","    corrects = pred.eq(target.view_as(pred)).sum().item()\n","    return corrects\n","\n","\n","\n","def loss_batch(loss_func, outputs, target, opt=None):\n","    if np.shape(outputs)[0] == 2:\n","        output, aux_out = outputs\n","\n","        output_loss = loss_func(output, target)\n","        aux_out_loss = loss_func(aux_out, target)\n","\n","        loss = output_loss + 0.3*aux_out_loss\n","        metric_b = metric_batch(output, target)\n","\n","    else:\n","        loss = loss_func(outputs, target)\n","        metric_b = metric_batch(outputs, target)\n","\n","    if opt is not None:\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","    \n","    return loss.item(), metric_b"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"634QzH7t5cW2"},"source":["model = GoogLeNet_v2(num_classes=num_classes).cuda()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = StepLR(optimizer, step_size=8, gamma=0.96)\n","\n","criterion = torch.nn.CrossEntropyLoss(reduction='sum').cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FMJr89WBqqX","outputId":"f0430129-62aa-42b1-8958-7ab21f1a0484"},"source":["best_acc = 0\n","for epoch in range(epochs):\n","    current_lr = get_lr(optimizer)\n","    print(\"\\n----- epoch: {}/{}, lr: {} -----\".format(\n","        epoch+1, epochs, optimizer.param_groups[0][\"lr\"]))\n","\n","    # train for one epoch\n","    model.aux_logits = True\n","    start_time = time.time()\n","    train(train_loader, epoch, model, optimizer, criterion)\n","\n","    # auxiliary classifier is not used when testing.\n","    model.aux_logits = False\n","    test_acc = test(test_loader,epoch,model)\n","\n","    elapsed_time = time.time() - start_time\n","    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n","    # learning rate scheduling\n","    scheduler.step()\n","    \n","    # Save model for best accuracy\n","    if best_acc < test_acc:\n","        best_acc = test_acc\n","        torch.save(model.state_dict(), path2weights)\n","\n","torch.save(model.state_dict(), path2weights)\n","print(f\"Best Top-1 Accuracy: {best_acc}\")"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","----- epoch: 1/100, lr: 0.001 -----\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [0][  0/782]\tTime  4.821 ( 4.821)\tLoss 3.8318e+02 (3.8318e+02)\tAcc@1   0.00 (  0.00)\tAcc@5   9.38 (  9.38)\n","Epoch: [0][100/782]\tTime  0.845 ( 0.863)\tLoss 2.1159e+14 (3.8803e+13)\tAcc@1   0.00 (  0.68)\tAcc@5   4.69 (  4.73)\n","Epoch: [0][200/782]\tTime  0.893 ( 0.867)\tLoss 7.0957e+11 (3.8616e+15)\tAcc@1   1.56 (  0.83)\tAcc@5   1.56 (  4.77)\n","Epoch: [0][300/782]\tTime  0.913 ( 0.879)\tLoss 3.5257e+11 (2.5789e+15)\tAcc@1   3.12 (  0.88)\tAcc@5   4.69 (  4.78)\n","Epoch: [0][400/782]\tTime  0.911 ( 0.887)\tLoss 2.4240e+11 (1.9358e+15)\tAcc@1   3.12 (  0.90)\tAcc@5   4.69 (  4.88)\n","Epoch: [0][500/782]\tTime  0.911 ( 0.892)\tLoss 3.4656e+11 (1.5495e+15)\tAcc@1   0.00 (  0.90)\tAcc@5   4.69 (  4.78)\n","Epoch: [0][600/782]\tTime  0.906 ( 0.895)\tLoss 1.0910e+11 (1.2917e+15)\tAcc@1   3.12 (  0.92)\tAcc@5   9.38 (  4.81)\n","Epoch: [0][700/782]\tTime  0.912 ( 0.897)\tLoss 9.4711e+10 (1.1074e+15)\tAcc@1   0.00 (  0.90)\tAcc@5   3.12 (  4.79)\n","==> Train Accuracy: Acc@1 0.912 || Acc@5 4.786\n","==> Test Accuracy:  Acc@1 0.920 || Acc@5 4.580\n","==> 746.38 seconds to train this epoch\n","\n","\n","----- epoch: 2/100, lr: 0.001 -----\n","Epoch: [1][  0/782]\tTime  1.390 ( 1.390)\tLoss 8.1548e+10 (8.1548e+10)\tAcc@1   0.00 (  0.00)\tAcc@5   3.12 (  3.12)\n","Epoch: [1][100/782]\tTime  0.906 ( 0.919)\tLoss 1.2355e+11 (9.1060e+10)\tAcc@1   1.56 (  0.84)\tAcc@5   4.69 (  5.32)\n","Epoch: [1][200/782]\tTime  0.915 ( 0.916)\tLoss 4.1078e+10 (7.5786e+10)\tAcc@1   0.00 (  0.86)\tAcc@5   1.56 (  5.21)\n","Epoch: [1][300/782]\tTime  0.914 ( 0.915)\tLoss 5.4775e+10 (6.9938e+10)\tAcc@1   0.00 (  0.86)\tAcc@5   1.56 (  5.06)\n","Epoch: [1][400/782]\tTime  0.917 ( 0.914)\tLoss 3.1774e+10 (6.4211e+10)\tAcc@1   0.00 (  0.87)\tAcc@5   1.56 (  5.09)\n","Epoch: [1][500/782]\tTime  0.913 ( 0.914)\tLoss 4.7502e+10 (5.9237e+10)\tAcc@1   3.12 (  0.84)\tAcc@5   9.38 (  5.02)\n","Epoch: [1][600/782]\tTime  0.914 ( 0.914)\tLoss 2.2114e+10 (5.4892e+10)\tAcc@1   0.00 (  0.90)\tAcc@5   4.69 (  5.05)\n","Epoch: [1][700/782]\tTime  0.917 ( 0.914)\tLoss 3.0481e+10 (5.1215e+10)\tAcc@1   0.00 (  0.89)\tAcc@5   1.56 (  5.05)\n","==> Train Accuracy: Acc@1 0.914 || Acc@5 5.006\n","==> Test Accuracy:  Acc@1 0.750 || Acc@5 5.360\n","==> 756.92 seconds to train this epoch\n","\n","\n","----- epoch: 3/100, lr: 0.001 -----\n","Epoch: [2][  0/782]\tTime  1.336 ( 1.336)\tLoss 1.7373e+10 (1.7373e+10)\tAcc@1   0.00 (  0.00)\tAcc@5   1.56 (  1.56)\n","Epoch: [2][100/782]\tTime  0.908 ( 0.916)\tLoss 2.7270e+10 (2.3636e+10)\tAcc@1   0.00 (  0.99)\tAcc@5   7.81 (  5.51)\n","Epoch: [2][200/782]\tTime  0.916 ( 0.914)\tLoss 1.8674e+10 (2.2844e+10)\tAcc@1   0.00 (  1.12)\tAcc@5   0.00 (  5.39)\n","Epoch: [2][300/782]\tTime  0.915 ( 0.913)\tLoss 3.8355e+10 (2.1969e+10)\tAcc@1   1.56 (  1.00)\tAcc@5  10.94 (  5.15)\n","Epoch: [2][400/782]\tTime  0.915 ( 0.913)\tLoss 1.5927e+10 (2.1515e+10)\tAcc@1   0.00 (  1.05)\tAcc@5   6.25 (  5.15)\n","Epoch: [2][500/782]\tTime  0.915 ( 0.913)\tLoss 1.9787e+10 (2.0356e+10)\tAcc@1   0.00 (  1.00)\tAcc@5   4.69 (  5.08)\n","Epoch: [2][600/782]\tTime  0.913 ( 0.913)\tLoss 9.2645e+09 (1.9028e+10)\tAcc@1   3.12 (  1.02)\tAcc@5   7.81 (  5.14)\n","Epoch: [2][700/782]\tTime  0.917 ( 0.913)\tLoss 2.2613e+10 (1.8013e+10)\tAcc@1   0.00 (  1.01)\tAcc@5   3.12 (  5.10)\n","==> Train Accuracy: Acc@1 0.990 || Acc@5 5.062\n","==> Test Accuracy:  Acc@1 0.970 || Acc@5 5.020\n","==> 755.94 seconds to train this epoch\n","\n","\n","----- epoch: 4/100, lr: 0.001 -----\n","Epoch: [3][  0/782]\tTime  1.363 ( 1.363)\tLoss 1.8670e+10 (1.8670e+10)\tAcc@1   1.56 (  1.56)\tAcc@5   4.69 (  4.69)\n","Epoch: [3][100/782]\tTime  0.913 ( 0.917)\tLoss 4.9279e+10 (1.0584e+11)\tAcc@1   1.56 (  0.96)\tAcc@5   7.81 (  5.21)\n","Epoch: [3][200/782]\tTime  0.911 ( 0.915)\tLoss 9.9467e+09 (6.2796e+10)\tAcc@1   0.00 (  0.96)\tAcc@5   6.25 (  5.19)\n","Epoch: [3][300/782]\tTime  0.912 ( 0.913)\tLoss 7.5656e+09 (4.4997e+10)\tAcc@1   0.00 (  0.97)\tAcc@5   7.81 (  5.22)\n","Epoch: [3][400/782]\tTime  0.913 ( 0.913)\tLoss 8.4311e+09 (3.5583e+10)\tAcc@1   1.56 (  0.95)\tAcc@5   7.81 (  5.17)\n","Epoch: [3][500/782]\tTime  0.907 ( 0.912)\tLoss 4.2765e+09 (3.0100e+10)\tAcc@1   0.00 (  1.01)\tAcc@5   4.69 (  5.20)\n","Epoch: [3][600/782]\tTime  0.913 ( 0.912)\tLoss 7.1797e+09 (2.6394e+10)\tAcc@1   0.00 (  1.04)\tAcc@5   6.25 (  5.19)\n","Epoch: [3][700/782]\tTime  0.908 ( 0.913)\tLoss 5.9546e+09 (2.3834e+10)\tAcc@1   4.69 (  1.07)\tAcc@5   9.38 (  5.30)\n","==> Train Accuracy: Acc@1 1.066 || Acc@5 5.280\n","==> Test Accuracy:  Acc@1 1.070 || Acc@5 5.100\n","==> 755.78 seconds to train this epoch\n","\n","\n","----- epoch: 5/100, lr: 0.001 -----\n","Epoch: [4][  0/782]\tTime  1.378 ( 1.378)\tLoss 8.1355e+09 (8.1355e+09)\tAcc@1   3.12 (  3.12)\tAcc@5   4.69 (  4.69)\n","Epoch: [4][100/782]\tTime  0.914 ( 0.917)\tLoss 5.2107e+09 (6.6874e+09)\tAcc@1   3.12 (  1.13)\tAcc@5   7.81 (  4.83)\n","Epoch: [4][200/782]\tTime  0.914 ( 0.915)\tLoss 1.2154e+10 (7.4083e+09)\tAcc@1   0.00 (  0.99)\tAcc@5   6.25 (  4.67)\n","Epoch: [4][300/782]\tTime  0.911 ( 0.914)\tLoss 8.4662e+09 (8.1278e+09)\tAcc@1   0.00 (  0.96)\tAcc@5   6.25 (  4.80)\n","Epoch: [4][400/782]\tTime  0.905 ( 0.913)\tLoss 8.1702e+09 (7.4888e+09)\tAcc@1   4.69 (  0.99)\tAcc@5   6.25 (  4.94)\n","Epoch: [4][500/782]\tTime  0.913 ( 0.913)\tLoss 3.8079e+09 (7.2949e+09)\tAcc@1   1.56 (  1.05)\tAcc@5   6.25 (  5.06)\n","Epoch: [4][600/782]\tTime  0.914 ( 0.913)\tLoss 3.3715e+09 (7.0781e+09)\tAcc@1   0.00 (  1.08)\tAcc@5   6.25 (  5.11)\n","Epoch: [4][700/782]\tTime  0.906 ( 0.913)\tLoss 3.2249e+11 (2.0845e+10)\tAcc@1   3.12 (  1.11)\tAcc@5   6.25 (  5.17)\n","==> Train Accuracy: Acc@1 1.096 || Acc@5 5.142\n","==> Test Accuracy:  Acc@1 0.860 || Acc@5 4.590\n","==> 755.81 seconds to train this epoch\n","\n","\n","----- epoch: 6/100, lr: 0.001 -----\n","Epoch: [5][  0/782]\tTime  1.340 ( 1.340)\tLoss 5.6000e+09 (5.6000e+09)\tAcc@1   0.00 (  0.00)\tAcc@5   3.12 (  3.12)\n","Epoch: [5][100/782]\tTime  0.912 ( 0.917)\tLoss 7.5971e+09 (5.8782e+09)\tAcc@1   1.56 (  0.93)\tAcc@5   3.12 (  4.61)\n","Epoch: [5][200/782]\tTime  0.920 ( 0.916)\tLoss 3.2467e+09 (5.2484e+09)\tAcc@1   0.00 (  0.89)\tAcc@5   0.00 (  4.56)\n","Epoch: [5][300/782]\tTime  0.916 ( 0.915)\tLoss 2.3338e+09 (4.7473e+09)\tAcc@1   0.00 (  0.96)\tAcc@5   3.12 (  4.80)\n","Epoch: [5][400/782]\tTime  0.915 ( 0.915)\tLoss 3.8339e+09 (4.6696e+09)\tAcc@1   1.56 (  0.99)\tAcc@5   4.69 (  4.88)\n","Epoch: [5][500/782]\tTime  0.914 ( 0.915)\tLoss 3.4071e+09 (4.5738e+09)\tAcc@1   4.69 (  1.02)\tAcc@5   7.81 (  4.89)\n","Epoch: [5][600/782]\tTime  0.910 ( 0.915)\tLoss 3.7324e+09 (4.3510e+09)\tAcc@1   1.56 (  1.01)\tAcc@5   1.56 (  4.91)\n","Epoch: [5][700/782]\tTime  0.913 ( 0.914)\tLoss 2.5487e+09 (4.2980e+09)\tAcc@1   0.00 (  1.04)\tAcc@5   1.56 (  4.95)\n","==> Train Accuracy: Acc@1 1.038 || Acc@5 4.934\n","==> Test Accuracy:  Acc@1 0.840 || Acc@5 4.870\n","==> 756.58 seconds to train this epoch\n","\n","\n","----- epoch: 7/100, lr: 0.001 -----\n","Epoch: [6][  0/782]\tTime  1.377 ( 1.377)\tLoss 2.1788e+09 (2.1788e+09)\tAcc@1   0.00 (  0.00)\tAcc@5   3.12 (  3.12)\n","Epoch: [6][100/782]\tTime  0.916 ( 0.919)\tLoss 3.4108e+09 (2.9907e+09)\tAcc@1   0.00 (  0.91)\tAcc@5   0.00 (  4.97)\n","Epoch: [6][200/782]\tTime  0.912 ( 0.917)\tLoss 1.8353e+09 (2.6388e+09)\tAcc@1   0.00 (  0.96)\tAcc@5   6.25 (  5.14)\n","Epoch: [6][300/782]\tTime  0.919 ( 0.916)\tLoss 2.8722e+09 (3.0184e+09)\tAcc@1   0.00 (  0.97)\tAcc@5   1.56 (  5.07)\n","Epoch: [6][400/782]\tTime  0.915 ( 0.915)\tLoss 2.4536e+09 (3.0453e+09)\tAcc@1   0.00 (  0.98)\tAcc@5   3.12 (  5.06)\n","Epoch: [6][500/782]\tTime  0.915 ( 0.915)\tLoss 3.2666e+09 (3.0731e+09)\tAcc@1   1.56 (  1.00)\tAcc@5   4.69 (  4.99)\n","Epoch: [6][600/782]\tTime  0.914 ( 0.914)\tLoss 2.7439e+09 (2.9495e+09)\tAcc@1   0.00 (  1.03)\tAcc@5   0.00 (  4.98)\n","Epoch: [6][700/782]\tTime  0.909 ( 0.913)\tLoss 2.4230e+09 (2.8020e+09)\tAcc@1   1.56 (  1.00)\tAcc@5   4.69 (  4.93)\n","==> Train Accuracy: Acc@1 0.990 || Acc@5 4.912\n","==> Test Accuracy:  Acc@1 0.830 || Acc@5 4.710\n","==> 756.22 seconds to train this epoch\n","\n","\n","----- epoch: 8/100, lr: 0.001 -----\n","Epoch: [7][  0/782]\tTime  1.368 ( 1.368)\tLoss 2.0460e+09 (2.0460e+09)\tAcc@1   3.12 (  3.12)\tAcc@5   4.69 (  4.69)\n","Epoch: [7][100/782]\tTime  0.919 ( 0.918)\tLoss 2.3433e+09 (4.4930e+09)\tAcc@1   0.00 (  1.04)\tAcc@5   4.69 (  5.20)\n","Epoch: [7][200/782]\tTime  0.912 ( 0.915)\tLoss 2.3069e+09 (3.6649e+09)\tAcc@1   3.12 (  1.01)\tAcc@5   9.38 (  5.04)\n","Epoch: [7][300/782]\tTime  0.914 ( 0.914)\tLoss 1.3359e+09 (3.0634e+09)\tAcc@1   0.00 (  1.06)\tAcc@5   6.25 (  5.10)\n","Epoch: [7][400/782]\tTime  0.915 ( 0.913)\tLoss 1.2829e+09 (2.6413e+09)\tAcc@1   0.00 (  1.06)\tAcc@5   7.81 (  5.06)\n","Epoch: [7][500/782]\tTime  0.906 ( 0.913)\tLoss 1.5501e+09 (2.4407e+09)\tAcc@1   0.00 (  1.05)\tAcc@5   4.69 (  5.03)\n","Epoch: [7][600/782]\tTime  0.920 ( 0.913)\tLoss 1.8762e+09 (2.3456e+09)\tAcc@1   0.00 (  1.03)\tAcc@5   4.69 (  4.98)\n","Epoch: [7][700/782]\tTime  0.910 ( 0.913)\tLoss 2.9384e+09 (2.2999e+09)\tAcc@1   1.56 (  1.05)\tAcc@5   7.81 (  5.00)\n","==> Train Accuracy: Acc@1 1.060 || Acc@5 5.004\n","==> Test Accuracy:  Acc@1 0.990 || Acc@5 4.960\n","==> 755.31 seconds to train this epoch\n","\n","\n","----- epoch: 9/100, lr: 0.00096 -----\n","Epoch: [8][  0/782]\tTime  1.359 ( 1.359)\tLoss 2.7952e+09 (2.7952e+09)\tAcc@1   0.00 (  0.00)\tAcc@5   3.12 (  3.12)\n","Epoch: [8][100/782]\tTime  0.910 ( 0.919)\tLoss 1.0324e+09 (2.5434e+09)\tAcc@1   1.56 (  0.88)\tAcc@5   7.81 (  5.03)\n","Epoch: [8][200/782]\tTime  0.906 ( 0.915)\tLoss 2.3064e+09 (6.0473e+09)\tAcc@1   1.56 (  0.94)\tAcc@5  12.50 (  5.22)\n","Epoch: [8][300/782]\tTime  0.910 ( 0.913)\tLoss 9.2599e+08 (4.7785e+09)\tAcc@1   3.12 (  0.96)\tAcc@5  12.50 (  5.17)\n","Epoch: [8][400/782]\tTime  0.907 ( 0.912)\tLoss 1.5976e+09 (3.9512e+09)\tAcc@1   3.12 (  0.94)\tAcc@5   4.69 (  5.16)\n","Epoch: [8][500/782]\tTime  0.912 ( 0.912)\tLoss 1.0704e+09 (3.3922e+09)\tAcc@1   1.56 (  0.94)\tAcc@5   3.12 (  5.08)\n","Epoch: [8][600/782]\tTime  0.915 ( 0.912)\tLoss 1.4683e+09 (3.0819e+09)\tAcc@1   0.00 (  0.92)\tAcc@5   6.25 (  5.04)\n","Epoch: [8][700/782]\tTime  0.913 ( 0.912)\tLoss 1.7170e+09 (2.8221e+09)\tAcc@1   0.00 (  0.94)\tAcc@5   6.25 (  5.03)\n","==> Train Accuracy: Acc@1 0.960 || Acc@5 5.044\n","==> Test Accuracy:  Acc@1 0.770 || Acc@5 5.650\n","==> 755.26 seconds to train this epoch\n","\n","\n","----- epoch: 10/100, lr: 0.00096 -----\n","Epoch: [9][  0/782]\tTime  1.334 ( 1.334)\tLoss 1.2723e+09 (1.2723e+09)\tAcc@1   0.00 (  0.00)\tAcc@5   4.69 (  4.69)\n","Epoch: [9][100/782]\tTime  0.914 ( 0.917)\tLoss 1.9041e+09 (1.1339e+09)\tAcc@1   0.00 (  1.01)\tAcc@5   1.56 (  5.37)\n","Epoch: [9][200/782]\tTime  0.915 ( 0.914)\tLoss 1.4579e+09 (1.2470e+09)\tAcc@1   0.00 (  1.03)\tAcc@5   9.38 (  5.08)\n","Epoch: [9][300/782]\tTime  0.915 ( 0.913)\tLoss 7.4056e+08 (1.2132e+09)\tAcc@1   0.00 (  1.11)\tAcc@5   3.12 (  5.05)\n","Epoch: [9][400/782]\tTime  0.915 ( 0.913)\tLoss 8.1898e+08 (1.1302e+09)\tAcc@1   0.00 (  1.12)\tAcc@5   7.81 (  5.18)\n","Epoch: [9][500/782]\tTime  0.915 ( 0.913)\tLoss 6.1026e+08 (1.0556e+09)\tAcc@1   0.00 (  1.06)\tAcc@5   3.12 (  5.22)\n"]}]}]}