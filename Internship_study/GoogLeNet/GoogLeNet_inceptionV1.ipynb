{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"GoogLeNet_inceptionV1.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyP2X+9ndq9x6ADXPG1n52x4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mbcuodGG1Rgg"},"source":["##**Import all neceassary packages**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XB-tD0SQ2qJr","executionInfo":{"status":"ok","timestamp":1631982755184,"user_tz":-540,"elapsed":498,"user":{"displayName":"ᄋᄋᄌ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07872107978641370856"}},"outputId":"b42cb0bb-989b-455d-960d-fdc493f68d33"},"source":["import numpy as np\n","import time\n","import copy\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torch.backends.cudnn as cudnn\n","from torch.optim.lr_scheduler import MultiStepLR, StepLR\n","\n","from torchvision import datasets, transforms\n","\n","from tqdm.notebook import tqdm as tqdm\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"t7dn0AtK1Wi1"},"source":["##**Model - Define GoogLeNet Model**"]},{"cell_type":"markdown","metadata":{"id":"2Jv5CfP-muh0"},"source":["## Inception 저장용 (수정 및 실행 금지)"]},{"cell_type":"code","metadata":{"id":"0i7ssTZkmsOq","executionInfo":{"status":"ok","timestamp":1631982755708,"user_tz":-540,"elapsed":3,"user":{"displayName":"ᄋᄋᄌ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07872107978641370856"}}},"source":["class GoogLeNet(nn.Module):\n","    def __init__(self, aux_logits=True, num_classes=10, init_weights=True):\n","        super(GoogLeNet, self).__init__()\n","        assert aux_logits == True or aux_logits == False\n","        self.aux_logits = aux_logits\n","\n","        # conv_block takes in_channels, out_channels, kernel_size, stride, padding\n","        # Inception block takes out1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool\n","\n","        self.conv1 = conv_block(3, 64, kernel_size=7, stride=2, padding=3)\n","        self.maxpool1 = nn.MaxPool2d(3, 2, 1)\n","        self.conv2 = conv_block(64, 192, kernel_size=3, stride=1, padding=1)\n","        self.maxpool2 = nn.MaxPool2d(3, 2, 1)\n","        self.inception3a = Inception_block(192, 64, 96, 128, 16, 32, 32)\n","        self.inception3b = Inception_block(256, 128, 128, 192, 32, 96, 64)\n","        self.maxpool3 = nn.MaxPool2d(3, 2, 1)\n","        self.inception4a = Inception_block(480, 192, 96, 208, 16, 48, 64)\n","\n","        # auxiliary classifier\n","\n","        self.inception4b = Inception_block(512, 160, 112, 224, 24, 64, 64)\n","        self.inception4c = Inception_block(512, 128, 128, 256, 24, 64, 64)\n","        self.inception4d = Inception_block(512, 112, 144, 288, 32, 64, 64)\n","\n","        # auxiliary classifier\n","\n","        self.inception4e = Inception_block(528, 256, 160, 320, 32, 128, 128)\n","        self.maxpool4 = nn.MaxPool2d(3, 2, 1)\n","        self.inception5a = Inception_block(832, 256, 160, 320, 32, 128, 128)\n","        self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\n","\n","        self.avgpool = nn.AvgPool2d(7, 1)\n","        self.dropout = nn.Dropout(p=0.4)\n","        self.fc1 = nn.Linear(1024, num_classes)\n","\n","        if self.aux_logits:\n","            self.aux1 = InceptionAux(512, num_classes)\n","            self.aux2 = InceptionAux(528, num_classes)\n","        else:\n","            self.aux1 = self.aux2 = None\n","\n","        # weight initialization\n","        if init_weights:\n","            self._initialize_weights()\n","\n","    def forward(self, x):\n","        print(x.size())\n","        x = self.conv1(x)\n","        x = self.maxpool1(x)\n","        print(x.size())\n","        x = self.conv2(x)\n","        x = self.maxpool2(x)\n","        print(x.size())\n","        x = self.inception3a(x)\n","        x = self.inception3b(x)\n","        x = self.maxpool3(x)\n","        print(x.size())\n","        x = self.inception4a(x)\n","\n","        if self.aux_logits and self.training:\n","            aux1 = self.aux1(x)\n","\n","        x = self.inception4b(x)\n","        x = self.inception4c(x)\n","        x = self.inception4d(x)\n","\n","        if self.aux_logits and self.training:\n","            aux2 = self.aux2(x)\n","\n","        x = self.inception4e(x)\n","        x = self.maxpool4(x)\n","        x = self.inception5a(x)\n","        x = self.inception5b(x)\n","        x = self.avgpool(x)\n","\n","        x = x.view(x.shape[0], -1)\n","\n","        x = self.dropout(x)\n","        x = self.fc1(x)\n","\n","        if self.aux_logits and self.training:\n","            return x, aux1, aux2\n","        else:\n","            return x \n","\n","    # define weight initialization function\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01)\n","                nn.init.constant_(m.bias, 0)\n","\n","class conv_block(nn.Module):\n","    def __init__(self, in_channels, out_channels, **kwargs):\n","        super(conv_block, self).__init__()\n","\n","        self.conv_layer = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, **kwargs),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","        )\n","    \n","    def forward(self, x):\n","        return self.conv_layer(x)\n","\n","class Inception_block(nn.Module):\n","    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool):\n","        super(Inception_block, self).__init__()\n","\n","        self.branch1 = conv_block(in_channels, out_1x1, kernel_size=1)\n","\n","        self.branch2 = nn.Sequential(\n","            conv_block(in_channels, red_3x3, kernel_size=1),\n","            conv_block(red_3x3, out_3x3, kernel_size=3, padding=1),\n","        )\n","\n","        self.branch3 = nn.Sequential(\n","            conv_block(in_channels, red_5x5, kernel_size=1),\n","            conv_block(red_5x5, out_5x5, kernel_size=5, padding=2),\n","        )\n","\n","        self.branch4 = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n","            conv_block(in_channels, out_1x1pool, kernel_size=1)\n","        )\n","\n","    def forward(self, x):\n","        # 0차원은 batch이므로 1차원인 filter 수를 기준으로 각 branch의 출력값을 묶어줍니다. \n","        x = torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], 1)\n","        return x\n","\n","# auxiliary classifier의 loss는 0.3이 곱해지고, 최종 loss에 추가합니다. 정규화 효과가 있습니다. \n","class InceptionAux(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super(InceptionAux, self).__init__()\n","\n","        self.conv = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=5, stride=3),\n","            conv_block(in_channels, 128, kernel_size=1),\n","        )\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(2048, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.3),\n","            nn.Linear(1024, num_classes),\n","        )\n","\n","    def forward(self,x):\n","        print(\"aux before : \", x.size())\n","        x = self.conv(x)\n","        print(\"aux : \", x.size())\n","        x = x.view(x.shape[0], -1)\n","        print(\"aux : \", x.size())\n","        x = self.fc(x)\n","        print(\"aux after : \", x.size())\n","        return x"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fmfa20ANm0xS"},"source":["## 현재 적용되는 모델"]},{"cell_type":"code","metadata":{"id":"8NDl4D5s1agB","executionInfo":{"status":"ok","timestamp":1631982756207,"user_tz":-540,"elapsed":502,"user":{"displayName":"ᄋᄋᄌ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07872107978641370856"}}},"source":["class GoogLeNet(nn.Module):\n","    def __init__(self, aux_logits=True, num_classes=10, init_weights=True):\n","        super(GoogLeNet, self).__init__()\n","        assert aux_logits == True or aux_logits == False\n","        self.aux_logits = aux_logits\n","\n","        # conv_block takes in_channels, out_channels, kernel_size, stride, padding\n","        # Inception block takes out1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool\n","\n","        # in : 32 x 32 x 3\n","        self.conv1 = conv_block(3, 64, kernel_size=7, stride=2, padding=3)\n","        # out : 16 x 16 x 64\n","        self.maxpool1 = nn.MaxPool2d(3, 2, 1)\n","        # out : 8 x 8 x 64\n","        self.conv2 = conv_block(64, 192, kernel_size=3, stride=1, padding=1)\n","        self.maxpool2 = nn.MaxPool2d(3, 1, 1)\n","        # out : 8 x 8 x 192\n","        self.inception3a = Inception_block(192, 64, 96, 128, 16, 32, 32)\n","        self.inception3b = Inception_block(256, 128, 128, 192, 32, 96, 64)\n","        self.maxpool3 = nn.MaxPool2d(3, 1, 1)\n","        # out : 8 x 8 x 480\n","        self.inception4a = Inception_block(480, 192, 96, 208, 16, 48, 64)\n","\n","        # auxiliary classifier\n","\n","        self.inception4b = Inception_block(512, 160, 112, 224, 24, 64, 64)\n","        self.inception4c = Inception_block(512, 128, 128, 256, 24, 64, 64)\n","        self.inception4d = Inception_block(512, 112, 144, 288, 32, 64, 64)\n","\n","        # auxiliary classifier\n","\n","        self.inception4e = Inception_block(528, 256, 160, 320, 32, 128, 128)\n","        self.maxpool4 = nn.MaxPool2d(3, 1, 1)\n","        # out : 8 x 8 x 832\n","        self.inception5a = Inception_block(832, 256, 160, 320, 32, 128, 128)\n","        self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\n","\n","        # out : 8 x 8 x 1024\n","        self.avgpool = nn.AvgPool2d(8, 1)\n","        self.dropout = nn.Dropout(p=0.4)\n","        self.fc1 = nn.Linear(1024, num_classes)\n","\n","        if self.aux_logits:\n","            self.aux1 = InceptionAux(512, num_classes)\n","            self.aux2 = InceptionAux(528, num_classes)\n","        else:\n","            self.aux1 = self.aux2 = None\n","\n","        # weight initialization\n","        if init_weights:\n","            self._initialize_weights()\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.maxpool1(x)\n","        x = self.conv2(x)\n","        x = self.maxpool2(x)\n","        x = self.inception3a(x)\n","        x = self.inception3b(x)\n","        x = self.maxpool3(x)\n","        x = self.inception4a(x)\n","        if self.aux_logits and self.training:\n","            aux1 = self.aux1(x)\n","\n","        x = self.inception4b(x)\n","        x = self.inception4c(x)\n","        x = self.inception4d(x)\n","\n","        if self.aux_logits and self.training:\n","            aux2 = self.aux2(x)\n","\n","        x = self.inception4e(x)\n","        x = self.maxpool4(x)\n","        x = self.inception5a(x)\n","        x = self.inception5b(x)\n","        x = self.avgpool(x)\n","\n","        x = x.view(x.shape[0], -1)\n","\n","        x = self.dropout(x)\n","        x = self.fc1(x)\n","\n","        if self.aux_logits and self.training:\n","            return x, aux1, aux2\n","        else:\n","            return x \n","\n","    # define weight initialization function\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01)\n","                nn.init.constant_(m.bias, 0)\n","\n","class conv_block(nn.Module):\n","    def __init__(self, in_channels, out_channels, **kwargs):\n","        super(conv_block, self).__init__()\n","\n","        self.conv_layer = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, **kwargs),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","        )\n","    \n","    def forward(self, x):\n","        return self.conv_layer(x)\n","\n","class Inception_block(nn.Module):\n","    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool):\n","        super(Inception_block, self).__init__()\n","\n","        self.branch1 = conv_block(in_channels, out_1x1, kernel_size=1)\n","\n","        self.branch2 = nn.Sequential(\n","            conv_block(in_channels, red_3x3, kernel_size=1),\n","            conv_block(red_3x3, out_3x3, kernel_size=3, padding=1),\n","        )\n","\n","        self.branch3 = nn.Sequential(\n","            conv_block(in_channels, red_5x5, kernel_size=1),\n","            conv_block(red_5x5, out_5x5, kernel_size=5, padding=2),\n","        )\n","\n","        self.branch4 = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n","            conv_block(in_channels, out_1x1pool, kernel_size=1)\n","        )\n","\n","    def forward(self, x):\n","        # 0차원은 batch이므로 1차원인 filter 수를 기준으로 각 branch의 출력값을 묶어줍니다. \n","        x = torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], 1)\n","        return x\n","\n","# auxiliary classifier의 loss는 0.3이 곱해지고, 최종 loss에 추가합니다. 정규화 효과가 있습니다. \n","class InceptionAux(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super(InceptionAux, self).__init__()\n","\n","        self.conv = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=5, stride=3),\n","            conv_block(in_channels, 128, kernel_size=1),\n","        )\n","\n","        self.fc = nn.Sequential(\n","            #nn.Linear(2048, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.3),\n","            nn.Linear(512, num_classes),\n","        )\n","\n","    def forward(self,x):\n","        #print(\"aux before : \", x.size())\n","        x = self.conv(x)\n","        #print(\"aux : \", x.size())\n","        x = x.view(x.shape[0], -1)\n","        #print(\"aux : \", x.size())\n","        x = self.fc(x)\n","        #print(\"aux after : \", x.size())\n","        return x"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LsOcL8g11Z5Y"},"source":["##**Utils**"]},{"cell_type":"code","metadata":{"id":"7LpvhzjP1mGa","executionInfo":{"status":"ok","timestamp":1631982756208,"user_tz":-540,"elapsed":4,"user":{"displayName":"ᄋᄋᄌ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07872107978641370856"}}},"source":["class AverageMeter(object):\n","    r\"\"\"Computes and stores the average and current value\n","    \"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt # 출력하는 소수의 자릿수\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def print(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print('\\t'.join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n","    \"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        # _, pred = output.topk(maxk, 1, True, True)\n","        # pred = pred.t()\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n","        _, idx = output.sort(descending=True)\n","        pred = idx[:,:maxk]\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g058eZ-Z1tOh"},"source":["##**Cutout: Main Code for Applying Cutout data augmentation**"]},{"cell_type":"code","metadata":{"id":"WU7zK9wi1mlr","executionInfo":{"status":"ok","timestamp":1631982756208,"user_tz":-540,"elapsed":4,"user":{"displayName":"ᄋᄋᄌ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07872107978641370856"}}},"source":["class Cutout(object):\n","    \"\"\"Randomly mask out one or more patches from an image.\n","\n","    Args:\n","        n_holes (int): Number of patches to cut out of each image.\n","        length (int): The length (in pixels) of each square patch.\n","    \"\"\"\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        \"\"\"\n","        Args:\n","            img (Tensor): Tensor image of size (C, H, W).\n","        Returns:\n","            Tensor: Image with n_holes of dimension length x length cut out of it.\n","        \"\"\"\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","\n","        return img"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4vbg5_d92J7r"},"source":["##**Parameter Settings**"]},{"cell_type":"code","metadata":{"id":"e7SdlZce2KlG","executionInfo":{"status":"ok","timestamp":1631982756208,"user_tz":-540,"elapsed":3,"user":{"displayName":"ᄋᄋᄌ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07872107978641370856"}}},"source":["dataset = 'cifar100' # cifar10 or cifar100\n","model = 'GoogLeNetV1' # resnet18, resnet50, resnet101\n","batch_size = 64  # Input batch size for training (default: 128)\n","epochs = 100 # Number of epochs to train (default: 200)\n","learning_rate = 1e-3 # Learning rate\n","data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n","sanity_check = False\n","path2weights = './drive/MyDrive/DeepLearning_competition/Internship/Week_1/GoogLeNet_V1.pth'    # route for model saving\n","\n","cutout = False # Apply Cutout?\n","n_holes = 1 # Number of holes to cut out from image\n","length = 16 # Length of the holes\n","\n","seed = 0 # Random seed (default: 0)\n","print_freq = 100\n","cuda = torch.cuda.is_available()\n","cudnn.benchmark = True  # Should make training should go faster for large models\n","\n","torch.manual_seed(seed)\n","if cuda:\n","    torch.cuda.manual_seed(seed)\n","\n","test_id = dataset + '_' + model"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xxsNHUuR2OLD"},"source":["##**Load and preprocess data**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G0xxABoH2Odv","executionInfo":{"status":"ok","timestamp":1631982757833,"user_tz":-540,"elapsed":1628,"user":{"displayName":"ᄋᄋᄌ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07872107978641370856"}},"outputId":"c6149f3d-91f1-48c4-c00f-0d591eed2d15"},"source":["# Image Preprocessing\n","normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n","                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n","\n","# train\n","train_transform = transforms.Compose([])\n","\n","train_transform.transforms.append(transforms.Resize((32, 32)))\n","if data_augmentation:\n","    #train_transform.transforms.append(transforms.RandomCrop(224, 224))\n","    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n","train_transform.transforms.append(transforms.ToTensor())\n","train_transform.transforms.append(normalize)\n","\n","if cutout:\n","    train_transform.transforms.append(Cutout(n_holes=n_holes, length=length))\n","\n","# test\n","test_transform = transforms.Compose([\n","    transforms.Resize((32, 32)),\n","    transforms.ToTensor(),\n","    normalize])\n","\n","if dataset == 'cifar10':\n","    num_classes = 10\n","    train_dataset = datasets.CIFAR10(root='data/',\n","                                     train=True,\n","                                     transform=train_transform,\n","                                     download=True)\n","\n","    test_dataset = datasets.CIFAR10(root='data/',\n","                                    train=False,\n","                                    transform=test_transform,\n","                                    download=True)\n","elif dataset == 'cifar100':\n","    num_classes = 100\n","    train_dataset = datasets.CIFAR100(root='data/',\n","                                      train=True,\n","                                      transform=train_transform,\n","                                      download=True)\n","\n","    test_dataset = datasets.CIFAR100(root='data/',\n","                                     train=False,\n","                                     transform=test_transform,\n","                                     download=True)\n","\n","\n","# Data Loader (Input Pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           pin_memory=True,\n","                                           num_workers=2)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          pin_memory=True,\n","                                          num_workers=2)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","metadata":{"id":"BUHCSAbQ5HMo"},"source":["##**Main Training**"]},{"cell_type":"code","metadata":{"id":"6cyFfBNQ5NY9","executionInfo":{"status":"ok","timestamp":1631982757834,"user_tz":-540,"elapsed":5,"user":{"displayName":"ᄋᄋᄌ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07872107978641370856"}}},"source":["def train(train_loader, epoch, model, optimizer, criterion):\n","    batch_time = AverageMeter('Time', ':6.3f') # 소수 출력 형식지정\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(len(train_loader), batch_time, losses,\n","                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n","    # switch to train mode\n","    model.train()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    running_loss = 0.0\n","    running_metric = 0.0\n","    len_data = len(train_loader.dataset)\n","    end = time.time()\n","    for i, (input, target) in enumerate(train_loader):\n","        # measure data loading time\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        # compute output\n","        output = model(input) # output = (x, aux1, aux2)\n","\n","        loss_b, metric_b = loss_batch(criterion, output, target, optimizer)\n","        running_loss += loss_b\n","\n","        if metric_b is not None:\n","            running_metric += metric_b\n","        \n","        if sanity_check is True:\n","            break\n","\n","        # measure accuracy and record loss, accuracy \n","        acc1, acc5 = accuracy(output[0], target, topk=(1, 5))\n","        losses.update(loss_b, input.size(0))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            progress.print(i)\n","    \n","    loss = running_loss / len_data\n","    metric = running_metric / len_data\n","\n","    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","def test(test_loader,epoch, model):\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","\n","    # switch to test mode\n","    model.eval()\n","    for i,(input,target) in enumerate(test_loader):\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        output = model(input)\n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"B0R3_dP_zwVT","executionInfo":{"status":"ok","timestamp":1631982758320,"user_tz":-540,"elapsed":4,"user":{"displayName":"ᄋᄋᄌ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07872107978641370856"}}},"source":["def get_lr(opt):\n","    for param_group in opt.param_groups:\n","        return param_group['lr']\n","\n","\n","\n","def metric_batch(output, target):\n","    pred = output.argmax(dim=1, keepdim=True)\n","    corrects = pred.eq(target.view_as(pred)).sum().item()\n","    return corrects\n","\n","\n","\n","def loss_batch(loss_func, outputs, target, opt=None):\n","    if np.shape(outputs)[0] == 3:\n","        output, aux1, aux2 = outputs\n","\n","        output_loss = loss_func(output, target)\n","        aux1_loss = loss_func(aux1, target)\n","        aux2_loss = loss_func(aux2, target)\n","\n","        loss = output_loss + 0.3*(aux1_loss + aux2_loss)\n","        metric_b = metric_batch(output,target)\n","\n","    else:\n","        loss = loss_func(outputs, target)\n","        metric_b = metric_batch(outputs, target)\n","\n","    if opt is not None:\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","    \n","    return loss.item(), metric_b"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"634QzH7t5cW2","executionInfo":{"status":"ok","timestamp":1631982760681,"user_tz":-540,"elapsed":2364,"user":{"displayName":"ᄋᄋᄌ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07872107978641370856"}}},"source":["model = GoogLeNet(num_classes=num_classes).cuda()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n","\n","criterion = torch.nn.CrossEntropyLoss(reduction='sum').cuda()"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FMJr89WBqqX","executionInfo":{"status":"ok","timestamp":1631987358732,"user_tz":-540,"elapsed":4598057,"user":{"displayName":"ᄋᄋᄌ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07872107978641370856"}},"outputId":"0c719f2d-fa34-4f6f-be96-6e0192af625e"},"source":["best_acc = 0\n","for epoch in range(epochs):\n","    current_lr = get_lr(optimizer)\n","    print(\"\\n----- epoch: {}/{}, lr: {} -----\".format(\n","        epoch, epochs, optimizer.param_groups[0][\"lr\"]))\n","\n","    # train for one epoch\n","    model.aux_logits = True\n","    start_time = time.time()\n","    train(train_loader, epoch, model, optimizer, criterion)\n","\n","    # auxiliary classifier is not used when testing.\n","    model.aux_logits = False\n","    test_acc = test(test_loader,epoch,model)\n","\n","    elapsed_time = time.time() - start_time\n","    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n","    # learning rate scheduling\n","    scheduler.step()\n","    \n","    # Save model for best accuracy\n","    if best_acc < test_acc:\n","        best_acc = test_acc\n","        torch.save(model.state_dict(), path2weights)\n","\n","torch.save(model.state_dict(), path2weights)\n","print(f\"Best Top-1 Accuracy: {best_acc}\")"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","----- epoch: 0/100, lr: 0.001 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [0][  0/782]\tTime  0.765 ( 0.765)\tLoss 4.6993e+02 (4.6993e+02)\tAcc@1   0.00 (  0.00)\tAcc@5  12.50 ( 12.50)\n","Epoch: [0][100/782]\tTime  0.054 ( 0.062)\tLoss 4.1102e+02 (4.3923e+02)\tAcc@1   6.25 (  4.97)\tAcc@5  26.56 ( 17.53)\n","Epoch: [0][200/782]\tTime  0.054 ( 0.058)\tLoss 4.1026e+02 (4.2378e+02)\tAcc@1  10.94 (  6.41)\tAcc@5  25.00 ( 21.46)\n","Epoch: [0][300/782]\tTime  0.054 ( 0.057)\tLoss 3.7313e+02 (4.1354e+02)\tAcc@1  12.50 (  7.02)\tAcc@5  35.94 ( 24.11)\n","Epoch: [0][400/782]\tTime  0.053 ( 0.057)\tLoss 3.8751e+02 (4.0447e+02)\tAcc@1  10.94 (  8.10)\tAcc@5  29.69 ( 26.57)\n","Epoch: [0][500/782]\tTime  0.055 ( 0.056)\tLoss 3.6684e+02 (3.9715e+02)\tAcc@1  15.62 (  9.02)\tAcc@5  34.38 ( 28.50)\n","Epoch: [0][600/782]\tTime  0.054 ( 0.056)\tLoss 3.8298e+02 (3.9052e+02)\tAcc@1  18.75 (  9.94)\tAcc@5  39.06 ( 30.42)\n","Epoch: [0][700/782]\tTime  0.059 ( 0.056)\tLoss 3.4690e+02 (3.8407e+02)\tAcc@1  15.62 ( 10.84)\tAcc@5  48.44 ( 32.21)\n","==> Train Accuracy: Acc@1 11.456 || Acc@5 33.462\n","==> Test Accuracy:  Acc@1 15.840 || Acc@5 44.070\n","==> 46.82 seconds to train this epoch\n","\n","\n","----- epoch: 1/100, lr: 0.001 -----\n","Epoch: [1][  0/782]\tTime  0.153 ( 0.153)\tLoss 3.3472e+02 (3.3472e+02)\tAcc@1  10.94 ( 10.94)\tAcc@5  42.19 ( 42.19)\n","Epoch: [1][100/782]\tTime  0.053 ( 0.057)\tLoss 3.4708e+02 (3.3236e+02)\tAcc@1   9.38 ( 17.84)\tAcc@5  39.06 ( 46.44)\n","Epoch: [1][200/782]\tTime  0.054 ( 0.057)\tLoss 2.9833e+02 (3.2599e+02)\tAcc@1  21.88 ( 19.31)\tAcc@5  56.25 ( 48.67)\n","Epoch: [1][300/782]\tTime  0.055 ( 0.056)\tLoss 2.8416e+02 (3.2281e+02)\tAcc@1  32.81 ( 20.05)\tAcc@5  59.38 ( 49.62)\n","Epoch: [1][400/782]\tTime  0.054 ( 0.056)\tLoss 3.3847e+02 (3.1998e+02)\tAcc@1  17.19 ( 20.52)\tAcc@5  42.19 ( 50.39)\n","Epoch: [1][500/782]\tTime  0.055 ( 0.056)\tLoss 2.9731e+02 (3.1671e+02)\tAcc@1  21.88 ( 21.11)\tAcc@5  56.25 ( 51.31)\n","Epoch: [1][600/782]\tTime  0.056 ( 0.056)\tLoss 3.4055e+02 (3.1385e+02)\tAcc@1  15.62 ( 21.71)\tAcc@5  42.19 ( 52.09)\n","Epoch: [1][700/782]\tTime  0.053 ( 0.056)\tLoss 3.2540e+02 (3.1120e+02)\tAcc@1  21.88 ( 22.29)\tAcc@5  56.25 ( 52.78)\n","==> Train Accuracy: Acc@1 22.644 || Acc@5 53.414\n","==> Test Accuracy:  Acc@1 24.970 || Acc@5 56.820\n","==> 46.02 seconds to train this epoch\n","\n","\n","----- epoch: 2/100, lr: 0.001 -----\n","Epoch: [2][  0/782]\tTime  0.151 ( 0.151)\tLoss 2.7593e+02 (2.7593e+02)\tAcc@1  21.88 ( 21.88)\tAcc@5  56.25 ( 56.25)\n","Epoch: [2][100/782]\tTime  0.054 ( 0.056)\tLoss 2.6156e+02 (2.7954e+02)\tAcc@1  28.12 ( 28.34)\tAcc@5  64.06 ( 60.49)\n","Epoch: [2][200/782]\tTime  0.054 ( 0.056)\tLoss 2.7590e+02 (2.8096e+02)\tAcc@1  23.44 ( 27.40)\tAcc@5  67.19 ( 60.00)\n","Epoch: [2][300/782]\tTime  0.053 ( 0.055)\tLoss 2.5463e+02 (2.7806e+02)\tAcc@1  35.94 ( 28.11)\tAcc@5  68.75 ( 60.92)\n","Epoch: [2][400/782]\tTime  0.059 ( 0.056)\tLoss 2.5557e+02 (2.7748e+02)\tAcc@1  34.38 ( 28.49)\tAcc@5  64.06 ( 61.12)\n","Epoch: [2][500/782]\tTime  0.054 ( 0.056)\tLoss 2.8660e+02 (2.7637e+02)\tAcc@1  28.12 ( 28.73)\tAcc@5  62.50 ( 61.30)\n","Epoch: [2][600/782]\tTime  0.059 ( 0.056)\tLoss 2.7259e+02 (2.7462e+02)\tAcc@1  32.81 ( 29.11)\tAcc@5  67.19 ( 61.67)\n","Epoch: [2][700/782]\tTime  0.054 ( 0.056)\tLoss 2.5887e+02 (2.7291e+02)\tAcc@1  32.81 ( 29.46)\tAcc@5  60.94 ( 62.11)\n","==> Train Accuracy: Acc@1 29.760 || Acc@5 62.460\n","==> Test Accuracy:  Acc@1 32.600 || Acc@5 65.070\n","==> 45.89 seconds to train this epoch\n","\n","\n","----- epoch: 3/100, lr: 0.001 -----\n","Epoch: [3][  0/782]\tTime  0.152 ( 0.152)\tLoss 2.9492e+02 (2.9492e+02)\tAcc@1  18.75 ( 18.75)\tAcc@5  57.81 ( 57.81)\n","Epoch: [3][100/782]\tTime  0.057 ( 0.056)\tLoss 2.5504e+02 (2.5263e+02)\tAcc@1  29.69 ( 33.52)\tAcc@5  70.31 ( 67.70)\n","Epoch: [3][200/782]\tTime  0.054 ( 0.056)\tLoss 2.7488e+02 (2.5094e+02)\tAcc@1  25.00 ( 33.96)\tAcc@5  62.50 ( 67.66)\n","Epoch: [3][300/782]\tTime  0.054 ( 0.056)\tLoss 2.4279e+02 (2.5095e+02)\tAcc@1  34.38 ( 34.01)\tAcc@5  70.31 ( 67.63)\n","Epoch: [3][400/782]\tTime  0.054 ( 0.055)\tLoss 2.6549e+02 (2.4980e+02)\tAcc@1  29.69 ( 34.36)\tAcc@5  70.31 ( 67.99)\n","Epoch: [3][500/782]\tTime  0.059 ( 0.056)\tLoss 2.2231e+02 (2.4834e+02)\tAcc@1  42.19 ( 34.67)\tAcc@5  65.62 ( 68.29)\n","Epoch: [3][600/782]\tTime  0.055 ( 0.056)\tLoss 2.4030e+02 (2.4717e+02)\tAcc@1  35.94 ( 34.86)\tAcc@5  73.44 ( 68.44)\n","Epoch: [3][700/782]\tTime  0.054 ( 0.056)\tLoss 2.8907e+02 (2.4672e+02)\tAcc@1  34.38 ( 34.92)\tAcc@5  57.81 ( 68.47)\n","==> Train Accuracy: Acc@1 35.016 || Acc@5 68.508\n","==> Test Accuracy:  Acc@1 37.520 || Acc@5 69.790\n","==> 46.20 seconds to train this epoch\n","\n","\n","----- epoch: 4/100, lr: 0.001 -----\n","Epoch: [4][  0/782]\tTime  0.161 ( 0.161)\tLoss 2.1638e+02 (2.1638e+02)\tAcc@1  45.31 ( 45.31)\tAcc@5  71.88 ( 71.88)\n","Epoch: [4][100/782]\tTime  0.054 ( 0.055)\tLoss 2.2108e+02 (2.2875e+02)\tAcc@1  39.06 ( 38.86)\tAcc@5  71.88 ( 71.83)\n","Epoch: [4][200/782]\tTime  0.053 ( 0.055)\tLoss 2.0830e+02 (2.2856e+02)\tAcc@1  37.50 ( 38.91)\tAcc@5  75.00 ( 71.97)\n","Epoch: [4][300/782]\tTime  0.057 ( 0.055)\tLoss 2.1722e+02 (2.2917e+02)\tAcc@1  42.19 ( 38.78)\tAcc@5  71.88 ( 71.92)\n","Epoch: [4][400/782]\tTime  0.054 ( 0.055)\tLoss 2.3116e+02 (2.2901e+02)\tAcc@1  46.88 ( 39.02)\tAcc@5  65.62 ( 71.87)\n","Epoch: [4][500/782]\tTime  0.054 ( 0.055)\tLoss 2.1462e+02 (2.2868e+02)\tAcc@1  46.88 ( 39.22)\tAcc@5  78.12 ( 72.12)\n","Epoch: [4][600/782]\tTime  0.059 ( 0.055)\tLoss 2.2400e+02 (2.2804e+02)\tAcc@1  34.38 ( 39.35)\tAcc@5  71.88 ( 72.29)\n","Epoch: [4][700/782]\tTime  0.060 ( 0.055)\tLoss 2.1510e+02 (2.2803e+02)\tAcc@1  43.75 ( 39.39)\tAcc@5  76.56 ( 72.25)\n","==> Train Accuracy: Acc@1 39.438 || Acc@5 72.314\n","==> Test Accuracy:  Acc@1 40.430 || Acc@5 72.230\n","==> 45.66 seconds to train this epoch\n","\n","\n","----- epoch: 5/100, lr: 0.001 -----\n","Epoch: [5][  0/782]\tTime  0.144 ( 0.144)\tLoss 2.3463e+02 (2.3463e+02)\tAcc@1  45.31 ( 45.31)\tAcc@5  71.88 ( 71.88)\n","Epoch: [5][100/782]\tTime  0.058 ( 0.056)\tLoss 1.8281e+02 (2.1204e+02)\tAcc@1  43.75 ( 42.90)\tAcc@5  85.94 ( 75.90)\n","Epoch: [5][200/782]\tTime  0.056 ( 0.056)\tLoss 2.0205e+02 (2.0975e+02)\tAcc@1  43.75 ( 43.93)\tAcc@5  81.25 ( 76.11)\n","Epoch: [5][300/782]\tTime  0.054 ( 0.055)\tLoss 2.2555e+02 (2.1031e+02)\tAcc@1  39.06 ( 43.57)\tAcc@5  78.12 ( 75.97)\n","Epoch: [5][400/782]\tTime  0.054 ( 0.055)\tLoss 2.4244e+02 (2.1117e+02)\tAcc@1  37.50 ( 43.30)\tAcc@5  64.06 ( 75.79)\n","Epoch: [5][500/782]\tTime  0.054 ( 0.055)\tLoss 1.9114e+02 (2.1160e+02)\tAcc@1  45.31 ( 43.24)\tAcc@5  82.81 ( 75.74)\n","Epoch: [5][600/782]\tTime  0.054 ( 0.055)\tLoss 2.2447e+02 (2.1124e+02)\tAcc@1  43.75 ( 43.27)\tAcc@5  78.12 ( 75.78)\n","Epoch: [5][700/782]\tTime  0.055 ( 0.055)\tLoss 2.3924e+02 (2.1176e+02)\tAcc@1  43.75 ( 43.21)\tAcc@5  68.75 ( 75.68)\n","==> Train Accuracy: Acc@1 43.296 || Acc@5 75.594\n","==> Test Accuracy:  Acc@1 43.220 || Acc@5 74.970\n","==> 45.63 seconds to train this epoch\n","\n","\n","----- epoch: 6/100, lr: 0.001 -----\n","Epoch: [6][  0/782]\tTime  0.150 ( 0.150)\tLoss 1.8453e+02 (1.8453e+02)\tAcc@1  54.69 ( 54.69)\tAcc@5  84.38 ( 84.38)\n","Epoch: [6][100/782]\tTime  0.054 ( 0.056)\tLoss 1.9031e+02 (1.9201e+02)\tAcc@1  53.12 ( 46.75)\tAcc@5  75.00 ( 79.15)\n","Epoch: [6][200/782]\tTime  0.054 ( 0.056)\tLoss 2.0332e+02 (1.9718e+02)\tAcc@1  45.31 ( 46.17)\tAcc@5  85.94 ( 78.42)\n","Epoch: [6][300/782]\tTime  0.053 ( 0.056)\tLoss 1.7095e+02 (1.9806e+02)\tAcc@1  54.69 ( 45.96)\tAcc@5  79.69 ( 78.17)\n","Epoch: [6][400/782]\tTime  0.054 ( 0.056)\tLoss 2.0775e+02 (1.9857e+02)\tAcc@1  42.19 ( 46.10)\tAcc@5  76.56 ( 77.97)\n","Epoch: [6][500/782]\tTime  0.054 ( 0.055)\tLoss 2.0784e+02 (1.9913e+02)\tAcc@1  32.81 ( 45.78)\tAcc@5  81.25 ( 77.90)\n","Epoch: [6][600/782]\tTime  0.053 ( 0.055)\tLoss 1.5699e+02 (1.9889e+02)\tAcc@1  56.25 ( 45.93)\tAcc@5  85.94 ( 77.93)\n","Epoch: [6][700/782]\tTime  0.053 ( 0.055)\tLoss 1.9627e+02 (1.9938e+02)\tAcc@1  42.19 ( 45.88)\tAcc@5  73.44 ( 77.86)\n","==> Train Accuracy: Acc@1 45.910 || Acc@5 77.920\n","==> Test Accuracy:  Acc@1 42.640 || Acc@5 74.710\n","==> 45.81 seconds to train this epoch\n","\n","\n","----- epoch: 7/100, lr: 0.001 -----\n","Epoch: [7][  0/782]\tTime  0.149 ( 0.149)\tLoss 1.4253e+02 (1.4253e+02)\tAcc@1  57.81 ( 57.81)\tAcc@5  84.38 ( 84.38)\n","Epoch: [7][100/782]\tTime  0.054 ( 0.055)\tLoss 1.8360e+02 (1.8192e+02)\tAcc@1  45.31 ( 49.97)\tAcc@5  79.69 ( 81.13)\n","Epoch: [7][200/782]\tTime  0.053 ( 0.055)\tLoss 2.1103e+02 (1.8391e+02)\tAcc@1  42.19 ( 49.50)\tAcc@5  79.69 ( 81.16)\n","Epoch: [7][300/782]\tTime  0.055 ( 0.055)\tLoss 1.9180e+02 (1.8473e+02)\tAcc@1  40.62 ( 49.08)\tAcc@5  81.25 ( 80.85)\n","Epoch: [7][400/782]\tTime  0.055 ( 0.055)\tLoss 2.0521e+02 (1.8556e+02)\tAcc@1  43.75 ( 49.00)\tAcc@5  81.25 ( 80.70)\n","Epoch: [7][500/782]\tTime  0.059 ( 0.055)\tLoss 1.7222e+02 (1.8631e+02)\tAcc@1  53.12 ( 48.98)\tAcc@5  81.25 ( 80.49)\n","Epoch: [7][600/782]\tTime  0.054 ( 0.055)\tLoss 1.9735e+02 (1.8678e+02)\tAcc@1  50.00 ( 48.90)\tAcc@5  78.12 ( 80.40)\n","Epoch: [7][700/782]\tTime  0.053 ( 0.055)\tLoss 1.9413e+02 (1.8677e+02)\tAcc@1  50.00 ( 48.94)\tAcc@5  82.81 ( 80.37)\n","==> Train Accuracy: Acc@1 49.048 || Acc@5 80.394\n","==> Test Accuracy:  Acc@1 45.450 || Acc@5 75.910\n","==> 45.62 seconds to train this epoch\n","\n","\n","----- epoch: 8/100, lr: 0.001 -----\n","Epoch: [8][  0/782]\tTime  0.147 ( 0.147)\tLoss 1.9326e+02 (1.9326e+02)\tAcc@1  50.00 ( 50.00)\tAcc@5  75.00 ( 75.00)\n","Epoch: [8][100/782]\tTime  0.054 ( 0.055)\tLoss 1.5626e+02 (1.7042e+02)\tAcc@1  59.38 ( 51.87)\tAcc@5  89.06 ( 83.83)\n","Epoch: [8][200/782]\tTime  0.054 ( 0.056)\tLoss 1.7246e+02 (1.7409e+02)\tAcc@1  54.69 ( 51.15)\tAcc@5  85.94 ( 82.91)\n","Epoch: [8][300/782]\tTime  0.054 ( 0.056)\tLoss 1.8929e+02 (1.7549e+02)\tAcc@1  45.31 ( 51.13)\tAcc@5  76.56 ( 82.44)\n","Epoch: [8][400/782]\tTime  0.059 ( 0.056)\tLoss 1.6255e+02 (1.7529e+02)\tAcc@1  51.56 ( 51.18)\tAcc@5  84.38 ( 82.56)\n","Epoch: [8][500/782]\tTime  0.054 ( 0.056)\tLoss 2.1362e+02 (1.7666e+02)\tAcc@1  39.06 ( 50.93)\tAcc@5  75.00 ( 82.34)\n","Epoch: [8][600/782]\tTime  0.053 ( 0.055)\tLoss 1.6556e+02 (1.7707e+02)\tAcc@1  51.56 ( 50.97)\tAcc@5  82.81 ( 82.28)\n","Epoch: [8][700/782]\tTime  0.053 ( 0.055)\tLoss 1.4959e+02 (1.7702e+02)\tAcc@1  56.25 ( 50.90)\tAcc@5  84.38 ( 82.34)\n","==> Train Accuracy: Acc@1 50.906 || Acc@5 82.244\n","==> Test Accuracy:  Acc@1 45.160 || Acc@5 75.270\n","==> 45.79 seconds to train this epoch\n","\n","\n","----- epoch: 9/100, lr: 0.001 -----\n","Epoch: [9][  0/782]\tTime  0.157 ( 0.157)\tLoss 1.5696e+02 (1.5696e+02)\tAcc@1  56.25 ( 56.25)\tAcc@5  87.50 ( 87.50)\n","Epoch: [9][100/782]\tTime  0.053 ( 0.056)\tLoss 1.5338e+02 (1.6703e+02)\tAcc@1  54.69 ( 53.09)\tAcc@5  85.94 ( 84.05)\n","Epoch: [9][200/782]\tTime  0.054 ( 0.056)\tLoss 1.6277e+02 (1.6634e+02)\tAcc@1  51.56 ( 53.43)\tAcc@5  81.25 ( 84.08)\n","Epoch: [9][300/782]\tTime  0.053 ( 0.056)\tLoss 1.7087e+02 (1.6687e+02)\tAcc@1  51.56 ( 53.51)\tAcc@5  82.81 ( 83.67)\n","Epoch: [9][400/782]\tTime  0.053 ( 0.056)\tLoss 1.8073e+02 (1.6730e+02)\tAcc@1  48.44 ( 53.52)\tAcc@5  82.81 ( 83.76)\n","Epoch: [9][500/782]\tTime  0.054 ( 0.055)\tLoss 1.2759e+02 (1.6718e+02)\tAcc@1  62.50 ( 53.51)\tAcc@5  95.31 ( 83.92)\n","Epoch: [9][600/782]\tTime  0.053 ( 0.055)\tLoss 1.8369e+02 (1.6718e+02)\tAcc@1  50.00 ( 53.57)\tAcc@5  76.56 ( 83.87)\n","Epoch: [9][700/782]\tTime  0.054 ( 0.055)\tLoss 1.5599e+02 (1.6764e+02)\tAcc@1  56.25 ( 53.49)\tAcc@5  87.50 ( 83.80)\n","==> Train Accuracy: Acc@1 53.412 || Acc@5 83.760\n","==> Test Accuracy:  Acc@1 47.640 || Acc@5 77.930\n","==> 45.61 seconds to train this epoch\n","\n","\n","----- epoch: 10/100, lr: 0.001 -----\n","Epoch: [10][  0/782]\tTime  0.150 ( 0.150)\tLoss 1.7331e+02 (1.7331e+02)\tAcc@1  50.00 ( 50.00)\tAcc@5  85.94 ( 85.94)\n","Epoch: [10][100/782]\tTime  0.054 ( 0.056)\tLoss 1.7442e+02 (1.5335e+02)\tAcc@1  48.44 ( 56.82)\tAcc@5  76.56 ( 85.61)\n","Epoch: [10][200/782]\tTime  0.055 ( 0.055)\tLoss 1.4574e+02 (1.5593e+02)\tAcc@1  56.25 ( 56.27)\tAcc@5  87.50 ( 85.59)\n","Epoch: [10][300/782]\tTime  0.055 ( 0.055)\tLoss 1.5354e+02 (1.5703e+02)\tAcc@1  53.12 ( 56.07)\tAcc@5  82.81 ( 85.45)\n","Epoch: [10][400/782]\tTime  0.053 ( 0.055)\tLoss 1.4039e+02 (1.5816e+02)\tAcc@1  62.50 ( 55.73)\tAcc@5  87.50 ( 85.30)\n","Epoch: [10][500/782]\tTime  0.055 ( 0.055)\tLoss 1.5530e+02 (1.5754e+02)\tAcc@1  56.25 ( 55.91)\tAcc@5  81.25 ( 85.37)\n","Epoch: [10][600/782]\tTime  0.053 ( 0.055)\tLoss 1.5221e+02 (1.5821e+02)\tAcc@1  57.81 ( 55.82)\tAcc@5  84.38 ( 85.34)\n","Epoch: [10][700/782]\tTime  0.054 ( 0.055)\tLoss 1.6812e+02 (1.5912e+02)\tAcc@1  56.25 ( 55.56)\tAcc@5  85.94 ( 85.20)\n","==> Train Accuracy: Acc@1 55.666 || Acc@5 85.314\n","==> Test Accuracy:  Acc@1 47.760 || Acc@5 77.870\n","==> 45.47 seconds to train this epoch\n","\n","\n","----- epoch: 11/100, lr: 0.001 -----\n","Epoch: [11][  0/782]\tTime  0.140 ( 0.140)\tLoss 1.1561e+02 (1.1561e+02)\tAcc@1  62.50 ( 62.50)\tAcc@5  95.31 ( 95.31)\n","Epoch: [11][100/782]\tTime  0.053 ( 0.056)\tLoss 1.1859e+02 (1.4170e+02)\tAcc@1  64.06 ( 60.80)\tAcc@5  90.62 ( 88.15)\n","Epoch: [11][200/782]\tTime  0.054 ( 0.055)\tLoss 1.3343e+02 (1.4387e+02)\tAcc@1  62.50 ( 59.90)\tAcc@5  87.50 ( 87.98)\n","Epoch: [11][300/782]\tTime  0.054 ( 0.055)\tLoss 1.3557e+02 (1.4554e+02)\tAcc@1  60.94 ( 59.26)\tAcc@5  89.06 ( 87.67)\n","Epoch: [11][400/782]\tTime  0.059 ( 0.055)\tLoss 1.6025e+02 (1.4748e+02)\tAcc@1  45.31 ( 58.85)\tAcc@5  89.06 ( 87.27)\n","Epoch: [11][500/782]\tTime  0.058 ( 0.055)\tLoss 1.9155e+02 (1.4853e+02)\tAcc@1  51.56 ( 58.51)\tAcc@5  82.81 ( 87.10)\n","Epoch: [11][600/782]\tTime  0.055 ( 0.055)\tLoss 1.3954e+02 (1.4899e+02)\tAcc@1  62.50 ( 58.39)\tAcc@5  87.50 ( 87.02)\n","Epoch: [11][700/782]\tTime  0.054 ( 0.055)\tLoss 1.4453e+02 (1.4904e+02)\tAcc@1  64.06 ( 58.36)\tAcc@5  92.19 ( 87.04)\n","==> Train Accuracy: Acc@1 58.254 || Acc@5 86.956\n","==> Test Accuracy:  Acc@1 49.610 || Acc@5 78.100\n","==> 45.74 seconds to train this epoch\n","\n","\n","----- epoch: 12/100, lr: 0.001 -----\n","Epoch: [12][  0/782]\tTime  0.168 ( 0.168)\tLoss 1.3560e+02 (1.3560e+02)\tAcc@1  57.81 ( 57.81)\tAcc@5  90.62 ( 90.62)\n","Epoch: [12][100/782]\tTime  0.055 ( 0.057)\tLoss 1.6440e+02 (1.3866e+02)\tAcc@1  54.69 ( 61.28)\tAcc@5  89.06 ( 88.46)\n","Epoch: [12][200/782]\tTime  0.053 ( 0.056)\tLoss 1.4870e+02 (1.3708e+02)\tAcc@1  57.81 ( 61.63)\tAcc@5  87.50 ( 88.58)\n","Epoch: [12][300/782]\tTime  0.055 ( 0.056)\tLoss 1.7075e+02 (1.3846e+02)\tAcc@1  56.25 ( 61.11)\tAcc@5  84.38 ( 88.57)\n","Epoch: [12][400/782]\tTime  0.054 ( 0.056)\tLoss 1.6325e+02 (1.3997e+02)\tAcc@1  51.56 ( 60.72)\tAcc@5  79.69 ( 88.36)\n","Epoch: [12][500/782]\tTime  0.055 ( 0.056)\tLoss 1.3647e+02 (1.4061e+02)\tAcc@1  59.38 ( 60.55)\tAcc@5  87.50 ( 88.29)\n","Epoch: [12][600/782]\tTime  0.054 ( 0.056)\tLoss 1.1915e+02 (1.4149e+02)\tAcc@1  73.44 ( 60.38)\tAcc@5  87.50 ( 88.14)\n","Epoch: [12][700/782]\tTime  0.054 ( 0.056)\tLoss 1.6716e+02 (1.4158e+02)\tAcc@1  53.12 ( 60.32)\tAcc@5  85.94 ( 88.11)\n","==> Train Accuracy: Acc@1 60.102 || Acc@5 88.018\n","==> Test Accuracy:  Acc@1 49.750 || Acc@5 78.990\n","==> 46.08 seconds to train this epoch\n","\n","\n","----- epoch: 13/100, lr: 0.001 -----\n","Epoch: [13][  0/782]\tTime  0.158 ( 0.158)\tLoss 1.5519e+02 (1.5519e+02)\tAcc@1  56.25 ( 56.25)\tAcc@5  85.94 ( 85.94)\n","Epoch: [13][100/782]\tTime  0.054 ( 0.057)\tLoss 1.3937e+02 (1.3122e+02)\tAcc@1  56.25 ( 62.98)\tAcc@5  89.06 ( 89.29)\n","Epoch: [13][200/782]\tTime  0.054 ( 0.056)\tLoss 1.2863e+02 (1.3152e+02)\tAcc@1  64.06 ( 62.86)\tAcc@5  92.19 ( 89.21)\n","Epoch: [13][300/782]\tTime  0.053 ( 0.055)\tLoss 1.2861e+02 (1.3069e+02)\tAcc@1  67.19 ( 63.12)\tAcc@5  89.06 ( 89.50)\n","Epoch: [13][400/782]\tTime  0.059 ( 0.055)\tLoss 1.4754e+02 (1.3171e+02)\tAcc@1  62.50 ( 62.88)\tAcc@5  84.38 ( 89.39)\n","Epoch: [13][500/782]\tTime  0.054 ( 0.055)\tLoss 1.1545e+02 (1.3270e+02)\tAcc@1  62.50 ( 62.59)\tAcc@5  93.75 ( 89.30)\n","Epoch: [13][600/782]\tTime  0.054 ( 0.055)\tLoss 1.2732e+02 (1.3369e+02)\tAcc@1  64.06 ( 62.31)\tAcc@5  84.38 ( 89.16)\n","Epoch: [13][700/782]\tTime  0.054 ( 0.055)\tLoss 1.1740e+02 (1.3430e+02)\tAcc@1  67.19 ( 62.20)\tAcc@5  93.75 ( 89.09)\n","==> Train Accuracy: Acc@1 61.966 || Acc@5 89.012\n","==> Test Accuracy:  Acc@1 49.090 || Acc@5 78.700\n","==> 45.80 seconds to train this epoch\n","\n","\n","----- epoch: 14/100, lr: 0.001 -----\n","Epoch: [14][  0/782]\tTime  0.148 ( 0.148)\tLoss 1.4940e+02 (1.4940e+02)\tAcc@1  59.38 ( 59.38)\tAcc@5  87.50 ( 87.50)\n","Epoch: [14][100/782]\tTime  0.056 ( 0.055)\tLoss 9.1152e+01 (1.2013e+02)\tAcc@1  73.44 ( 65.55)\tAcc@5  98.44 ( 91.54)\n","Epoch: [14][200/782]\tTime  0.054 ( 0.055)\tLoss 1.1912e+02 (1.2122e+02)\tAcc@1  68.75 ( 65.61)\tAcc@5  87.50 ( 91.18)\n","Epoch: [14][300/782]\tTime  0.054 ( 0.055)\tLoss 1.4476e+02 (1.2389e+02)\tAcc@1  54.69 ( 64.92)\tAcc@5  89.06 ( 90.82)\n","Epoch: [14][400/782]\tTime  0.054 ( 0.055)\tLoss 1.4699e+02 (1.2563e+02)\tAcc@1  62.50 ( 64.29)\tAcc@5  89.06 ( 90.58)\n","Epoch: [14][500/782]\tTime  0.055 ( 0.055)\tLoss 1.3645e+02 (1.2650e+02)\tAcc@1  54.69 ( 64.00)\tAcc@5  92.19 ( 90.38)\n","Epoch: [14][600/782]\tTime  0.054 ( 0.055)\tLoss 1.2692e+02 (1.2646e+02)\tAcc@1  59.38 ( 64.08)\tAcc@5  89.06 ( 90.33)\n","Epoch: [14][700/782]\tTime  0.054 ( 0.055)\tLoss 1.1295e+02 (1.2732e+02)\tAcc@1  70.31 ( 63.93)\tAcc@5  90.62 ( 90.19)\n","==> Train Accuracy: Acc@1 63.824 || Acc@5 90.142\n","==> Test Accuracy:  Acc@1 50.930 || Acc@5 79.890\n","==> 45.33 seconds to train this epoch\n","\n","\n","----- epoch: 15/100, lr: 0.001 -----\n","Epoch: [15][  0/782]\tTime  0.146 ( 0.146)\tLoss 1.0085e+02 (1.0085e+02)\tAcc@1  76.56 ( 76.56)\tAcc@5  95.31 ( 95.31)\n","Epoch: [15][100/782]\tTime  0.055 ( 0.055)\tLoss 1.3176e+02 (1.1387e+02)\tAcc@1  56.25 ( 67.85)\tAcc@5  89.06 ( 92.03)\n","Epoch: [15][200/782]\tTime  0.059 ( 0.055)\tLoss 1.2528e+02 (1.1524e+02)\tAcc@1  57.81 ( 66.84)\tAcc@5  95.31 ( 92.19)\n","Epoch: [15][300/782]\tTime  0.056 ( 0.055)\tLoss 1.2704e+02 (1.1647e+02)\tAcc@1  65.62 ( 66.60)\tAcc@5  84.38 ( 91.90)\n","Epoch: [15][400/782]\tTime  0.054 ( 0.056)\tLoss 1.2714e+02 (1.1762e+02)\tAcc@1  59.38 ( 66.39)\tAcc@5  89.06 ( 91.70)\n","Epoch: [15][500/782]\tTime  0.054 ( 0.055)\tLoss 1.4063e+02 (1.1879e+02)\tAcc@1  59.38 ( 66.13)\tAcc@5  84.38 ( 91.53)\n","Epoch: [15][600/782]\tTime  0.059 ( 0.055)\tLoss 8.3814e+01 (1.1953e+02)\tAcc@1  73.44 ( 65.97)\tAcc@5  90.62 ( 91.37)\n","Epoch: [15][700/782]\tTime  0.053 ( 0.055)\tLoss 1.4255e+02 (1.2023e+02)\tAcc@1  60.94 ( 65.85)\tAcc@5  89.06 ( 91.26)\n","==> Train Accuracy: Acc@1 65.756 || Acc@5 91.196\n","==> Test Accuracy:  Acc@1 51.390 || Acc@5 80.390\n","==> 45.79 seconds to train this epoch\n","\n","\n","----- epoch: 16/100, lr: 0.001 -----\n","Epoch: [16][  0/782]\tTime  0.159 ( 0.159)\tLoss 1.1098e+02 (1.1098e+02)\tAcc@1  68.75 ( 68.75)\tAcc@5  93.75 ( 93.75)\n","Epoch: [16][100/782]\tTime  0.061 ( 0.057)\tLoss 1.1766e+02 (1.0867e+02)\tAcc@1  62.50 ( 69.18)\tAcc@5  93.75 ( 92.19)\n","Epoch: [16][200/782]\tTime  0.054 ( 0.057)\tLoss 1.1063e+02 (1.0972e+02)\tAcc@1  62.50 ( 68.72)\tAcc@5  95.31 ( 92.55)\n","Epoch: [16][300/782]\tTime  0.060 ( 0.056)\tLoss 1.0711e+02 (1.1089e+02)\tAcc@1  67.19 ( 68.22)\tAcc@5  90.62 ( 92.52)\n","Epoch: [16][400/782]\tTime  0.054 ( 0.056)\tLoss 1.3541e+02 (1.1183e+02)\tAcc@1  71.88 ( 68.07)\tAcc@5  89.06 ( 92.40)\n","Epoch: [16][500/782]\tTime  0.054 ( 0.056)\tLoss 1.1397e+02 (1.1248e+02)\tAcc@1  70.31 ( 67.89)\tAcc@5  93.75 ( 92.28)\n","Epoch: [16][600/782]\tTime  0.053 ( 0.056)\tLoss 1.0593e+02 (1.1351e+02)\tAcc@1  78.12 ( 67.56)\tAcc@5  90.62 ( 92.15)\n","Epoch: [16][700/782]\tTime  0.055 ( 0.056)\tLoss 9.0345e+01 (1.1468e+02)\tAcc@1  70.31 ( 67.29)\tAcc@5 100.00 ( 92.01)\n","==> Train Accuracy: Acc@1 67.128 || Acc@5 91.916\n","==> Test Accuracy:  Acc@1 52.240 || Acc@5 80.830\n","==> 46.20 seconds to train this epoch\n","\n","\n","----- epoch: 17/100, lr: 0.001 -----\n","Epoch: [17][  0/782]\tTime  0.153 ( 0.153)\tLoss 8.7259e+01 (8.7259e+01)\tAcc@1  73.44 ( 73.44)\tAcc@5  93.75 ( 93.75)\n","Epoch: [17][100/782]\tTime  0.055 ( 0.056)\tLoss 9.7566e+01 (1.0137e+02)\tAcc@1  67.19 ( 70.90)\tAcc@5  95.31 ( 94.04)\n","Epoch: [17][200/782]\tTime  0.055 ( 0.056)\tLoss 1.0532e+02 (1.0249e+02)\tAcc@1  73.44 ( 70.17)\tAcc@5  90.62 ( 94.08)\n","Epoch: [17][300/782]\tTime  0.061 ( 0.056)\tLoss 9.3303e+01 (1.0375e+02)\tAcc@1  76.56 ( 69.90)\tAcc@5  93.75 ( 93.88)\n","Epoch: [17][400/782]\tTime  0.053 ( 0.056)\tLoss 1.0410e+02 (1.0472e+02)\tAcc@1  76.56 ( 69.70)\tAcc@5  96.88 ( 93.62)\n","Epoch: [17][500/782]\tTime  0.054 ( 0.055)\tLoss 1.2152e+02 (1.0584e+02)\tAcc@1  64.06 ( 69.39)\tAcc@5  89.06 ( 93.42)\n","Epoch: [17][600/782]\tTime  0.054 ( 0.055)\tLoss 1.3215e+02 (1.0664e+02)\tAcc@1  59.38 ( 69.27)\tAcc@5  93.75 ( 93.21)\n","Epoch: [17][700/782]\tTime  0.054 ( 0.055)\tLoss 1.2338e+02 (1.0744e+02)\tAcc@1  64.06 ( 69.17)\tAcc@5  92.19 ( 93.06)\n","==> Train Accuracy: Acc@1 68.948 || Acc@5 92.988\n","==> Test Accuracy:  Acc@1 52.370 || Acc@5 80.600\n","==> 45.82 seconds to train this epoch\n","\n","\n","----- epoch: 18/100, lr: 0.001 -----\n","Epoch: [18][  0/782]\tTime  0.145 ( 0.145)\tLoss 1.3299e+02 (1.3299e+02)\tAcc@1  64.06 ( 64.06)\tAcc@5  90.62 ( 90.62)\n","Epoch: [18][100/782]\tTime  0.053 ( 0.057)\tLoss 9.5483e+01 (9.5462e+01)\tAcc@1  73.44 ( 72.56)\tAcc@5  96.88 ( 94.66)\n","Epoch: [18][200/782]\tTime  0.054 ( 0.056)\tLoss 7.3572e+01 (9.6880e+01)\tAcc@1  81.25 ( 71.87)\tAcc@5  96.88 ( 94.26)\n","Epoch: [18][300/782]\tTime  0.056 ( 0.056)\tLoss 9.9953e+01 (9.7966e+01)\tAcc@1  68.75 ( 71.48)\tAcc@5  96.88 ( 94.10)\n","Epoch: [18][400/782]\tTime  0.058 ( 0.056)\tLoss 1.0017e+02 (9.8932e+01)\tAcc@1  71.88 ( 71.42)\tAcc@5  93.75 ( 93.99)\n","Epoch: [18][500/782]\tTime  0.054 ( 0.055)\tLoss 1.2352e+02 (1.0081e+02)\tAcc@1  68.75 ( 70.90)\tAcc@5  95.31 ( 93.74)\n","Epoch: [18][600/782]\tTime  0.054 ( 0.055)\tLoss 1.1996e+02 (1.0168e+02)\tAcc@1  71.88 ( 70.70)\tAcc@5  89.06 ( 93.59)\n","Epoch: [18][700/782]\tTime  0.055 ( 0.055)\tLoss 8.5239e+01 (1.0212e+02)\tAcc@1  78.12 ( 70.60)\tAcc@5  93.75 ( 93.51)\n","==> Train Accuracy: Acc@1 70.566 || Acc@5 93.544\n","==> Test Accuracy:  Acc@1 51.540 || Acc@5 79.750\n","==> 45.73 seconds to train this epoch\n","\n","\n","----- epoch: 19/100, lr: 0.001 -----\n","Epoch: [19][  0/782]\tTime  0.167 ( 0.167)\tLoss 1.1395e+02 (1.1395e+02)\tAcc@1  67.19 ( 67.19)\tAcc@5  95.31 ( 95.31)\n","Epoch: [19][100/782]\tTime  0.055 ( 0.056)\tLoss 1.2493e+02 (8.8039e+01)\tAcc@1  68.75 ( 75.00)\tAcc@5  90.62 ( 95.28)\n","Epoch: [19][200/782]\tTime  0.055 ( 0.055)\tLoss 9.4786e+01 (8.9318e+01)\tAcc@1  76.56 ( 74.55)\tAcc@5  95.31 ( 95.03)\n","Epoch: [19][300/782]\tTime  0.054 ( 0.056)\tLoss 8.3468e+01 (9.1241e+01)\tAcc@1  75.00 ( 73.83)\tAcc@5  96.88 ( 94.84)\n","Epoch: [19][400/782]\tTime  0.054 ( 0.055)\tLoss 1.0900e+02 (9.1903e+01)\tAcc@1  65.62 ( 73.66)\tAcc@5  96.88 ( 94.74)\n","Epoch: [19][500/782]\tTime  0.059 ( 0.056)\tLoss 9.8445e+01 (9.3102e+01)\tAcc@1  71.88 ( 73.33)\tAcc@5  95.31 ( 94.60)\n","Epoch: [19][600/782]\tTime  0.059 ( 0.055)\tLoss 1.0604e+02 (9.4189e+01)\tAcc@1  71.88 ( 72.95)\tAcc@5  92.19 ( 94.49)\n","Epoch: [19][700/782]\tTime  0.054 ( 0.056)\tLoss 9.9385e+01 (9.5101e+01)\tAcc@1  73.44 ( 72.68)\tAcc@5  93.75 ( 94.37)\n","==> Train Accuracy: Acc@1 72.408 || Acc@5 94.338\n","==> Test Accuracy:  Acc@1 50.210 || Acc@5 78.810\n","==> 45.91 seconds to train this epoch\n","\n","\n","----- epoch: 20/100, lr: 0.001 -----\n","Epoch: [20][  0/782]\tTime  0.154 ( 0.154)\tLoss 6.8811e+01 (6.8811e+01)\tAcc@1  81.25 ( 81.25)\tAcc@5  98.44 ( 98.44)\n","Epoch: [20][100/782]\tTime  0.054 ( 0.056)\tLoss 8.4402e+01 (8.3112e+01)\tAcc@1  81.25 ( 76.36)\tAcc@5  93.75 ( 95.93)\n","Epoch: [20][200/782]\tTime  0.059 ( 0.056)\tLoss 1.0796e+02 (8.5680e+01)\tAcc@1  67.19 ( 75.44)\tAcc@5  90.62 ( 95.57)\n","Epoch: [20][300/782]\tTime  0.054 ( 0.055)\tLoss 1.2298e+02 (8.6243e+01)\tAcc@1  68.75 ( 75.16)\tAcc@5  89.06 ( 95.43)\n","Epoch: [20][400/782]\tTime  0.054 ( 0.056)\tLoss 1.1802e+02 (8.7979e+01)\tAcc@1  73.44 ( 74.61)\tAcc@5  90.62 ( 95.29)\n","Epoch: [20][500/782]\tTime  0.054 ( 0.056)\tLoss 1.0703e+02 (8.8987e+01)\tAcc@1  68.75 ( 74.38)\tAcc@5  92.19 ( 95.20)\n","Epoch: [20][600/782]\tTime  0.060 ( 0.055)\tLoss 1.0342e+02 (9.0389e+01)\tAcc@1  68.75 ( 73.96)\tAcc@5  92.19 ( 95.07)\n","Epoch: [20][700/782]\tTime  0.063 ( 0.055)\tLoss 8.3471e+01 (9.1114e+01)\tAcc@1  78.12 ( 73.69)\tAcc@5  93.75 ( 95.02)\n","==> Train Accuracy: Acc@1 73.616 || Acc@5 94.962\n","==> Test Accuracy:  Acc@1 52.560 || Acc@5 80.560\n","==> 46.10 seconds to train this epoch\n","\n","\n","----- epoch: 21/100, lr: 0.001 -----\n","Epoch: [21][  0/782]\tTime  0.147 ( 0.147)\tLoss 1.0521e+02 (1.0521e+02)\tAcc@1  70.31 ( 70.31)\tAcc@5  92.19 ( 92.19)\n","Epoch: [21][100/782]\tTime  0.059 ( 0.057)\tLoss 9.1991e+01 (7.9012e+01)\tAcc@1  68.75 ( 76.50)\tAcc@5  95.31 ( 96.18)\n","Epoch: [21][200/782]\tTime  0.054 ( 0.057)\tLoss 9.7942e+01 (8.0222e+01)\tAcc@1  75.00 ( 76.46)\tAcc@5  95.31 ( 96.10)\n","Epoch: [21][300/782]\tTime  0.053 ( 0.056)\tLoss 8.2280e+01 (8.2455e+01)\tAcc@1  67.19 ( 75.97)\tAcc@5  98.44 ( 95.83)\n","Epoch: [21][400/782]\tTime  0.057 ( 0.056)\tLoss 1.0148e+02 (8.3154e+01)\tAcc@1  64.06 ( 75.64)\tAcc@5  95.31 ( 95.94)\n","Epoch: [21][500/782]\tTime  0.054 ( 0.056)\tLoss 8.3153e+01 (8.4203e+01)\tAcc@1  79.69 ( 75.30)\tAcc@5  95.31 ( 95.85)\n","Epoch: [21][600/782]\tTime  0.054 ( 0.056)\tLoss 8.6072e+01 (8.5069e+01)\tAcc@1  71.88 ( 75.06)\tAcc@5  96.88 ( 95.74)\n","Epoch: [21][700/782]\tTime  0.056 ( 0.056)\tLoss 5.9955e+01 (8.5769e+01)\tAcc@1  82.81 ( 74.94)\tAcc@5  98.44 ( 95.69)\n","==> Train Accuracy: Acc@1 74.792 || Acc@5 95.578\n","==> Test Accuracy:  Acc@1 51.640 || Acc@5 80.070\n","==> 46.10 seconds to train this epoch\n","\n","\n","----- epoch: 22/100, lr: 0.001 -----\n","Epoch: [22][  0/782]\tTime  0.153 ( 0.153)\tLoss 7.1660e+01 (7.1660e+01)\tAcc@1  84.38 ( 84.38)\tAcc@5  96.88 ( 96.88)\n","Epoch: [22][100/782]\tTime  0.054 ( 0.057)\tLoss 8.5615e+01 (7.5048e+01)\tAcc@1  76.56 ( 78.11)\tAcc@5  93.75 ( 96.23)\n","Epoch: [22][200/782]\tTime  0.053 ( 0.056)\tLoss 5.0967e+01 (7.6012e+01)\tAcc@1  82.81 ( 77.92)\tAcc@5 100.00 ( 96.25)\n","Epoch: [22][300/782]\tTime  0.055 ( 0.056)\tLoss 6.6764e+01 (7.7429e+01)\tAcc@1  84.38 ( 77.60)\tAcc@5 100.00 ( 96.28)\n","Epoch: [22][400/782]\tTime  0.054 ( 0.056)\tLoss 8.3563e+01 (7.7758e+01)\tAcc@1  73.44 ( 77.46)\tAcc@5  95.31 ( 96.31)\n","Epoch: [22][500/782]\tTime  0.055 ( 0.056)\tLoss 9.6667e+01 (7.8735e+01)\tAcc@1  71.88 ( 77.02)\tAcc@5  96.88 ( 96.26)\n","Epoch: [22][600/782]\tTime  0.055 ( 0.056)\tLoss 9.0731e+01 (7.9929e+01)\tAcc@1  76.56 ( 76.85)\tAcc@5  93.75 ( 96.08)\n","Epoch: [22][700/782]\tTime  0.054 ( 0.056)\tLoss 7.4502e+01 (8.0815e+01)\tAcc@1  78.12 ( 76.59)\tAcc@5  95.31 ( 96.01)\n","==> Train Accuracy: Acc@1 76.444 || Acc@5 95.992\n","==> Test Accuracy:  Acc@1 51.290 || Acc@5 79.610\n","==> 45.93 seconds to train this epoch\n","\n","\n","----- epoch: 23/100, lr: 0.001 -----\n","Epoch: [23][  0/782]\tTime  0.153 ( 0.153)\tLoss 5.7930e+01 (5.7930e+01)\tAcc@1  78.12 ( 78.12)\tAcc@5  95.31 ( 95.31)\n","Epoch: [23][100/782]\tTime  0.055 ( 0.056)\tLoss 8.8286e+01 (6.7914e+01)\tAcc@1  67.19 ( 80.09)\tAcc@5  93.75 ( 97.12)\n","Epoch: [23][200/782]\tTime  0.060 ( 0.056)\tLoss 7.0431e+01 (6.9726e+01)\tAcc@1  81.25 ( 80.10)\tAcc@5  96.88 ( 96.89)\n","Epoch: [23][300/782]\tTime  0.054 ( 0.056)\tLoss 8.2965e+01 (7.2181e+01)\tAcc@1  79.69 ( 79.09)\tAcc@5  96.88 ( 96.83)\n","Epoch: [23][400/782]\tTime  0.060 ( 0.056)\tLoss 9.1271e+01 (7.2990e+01)\tAcc@1  70.31 ( 78.91)\tAcc@5  96.88 ( 96.79)\n","Epoch: [23][500/782]\tTime  0.054 ( 0.056)\tLoss 7.2704e+01 (7.3836e+01)\tAcc@1  79.69 ( 78.69)\tAcc@5  93.75 ( 96.77)\n","Epoch: [23][600/782]\tTime  0.054 ( 0.055)\tLoss 7.7933e+01 (7.4709e+01)\tAcc@1  70.31 ( 78.34)\tAcc@5  96.88 ( 96.69)\n","Epoch: [23][700/782]\tTime  0.054 ( 0.055)\tLoss 1.0322e+02 (7.5934e+01)\tAcc@1  70.31 ( 78.00)\tAcc@5  98.44 ( 96.58)\n","==> Train Accuracy: Acc@1 77.776 || Acc@5 96.498\n","==> Test Accuracy:  Acc@1 52.020 || Acc@5 79.390\n","==> 46.01 seconds to train this epoch\n","\n","\n","----- epoch: 24/100, lr: 0.001 -----\n","Epoch: [24][  0/782]\tTime  0.152 ( 0.152)\tLoss 8.2482e+01 (8.2482e+01)\tAcc@1  79.69 ( 79.69)\tAcc@5  98.44 ( 98.44)\n","Epoch: [24][100/782]\tTime  0.054 ( 0.056)\tLoss 7.3181e+01 (6.3748e+01)\tAcc@1  79.69 ( 81.67)\tAcc@5  96.88 ( 97.43)\n","Epoch: [24][200/782]\tTime  0.055 ( 0.055)\tLoss 6.1818e+01 (6.4495e+01)\tAcc@1  79.69 ( 81.48)\tAcc@5  98.44 ( 97.50)\n","Epoch: [24][300/782]\tTime  0.054 ( 0.055)\tLoss 9.0526e+01 (6.7371e+01)\tAcc@1  76.56 ( 80.59)\tAcc@5  96.88 ( 97.18)\n","Epoch: [24][400/782]\tTime  0.058 ( 0.055)\tLoss 7.6366e+01 (6.9088e+01)\tAcc@1  71.88 ( 80.17)\tAcc@5  98.44 ( 97.02)\n","Epoch: [24][500/782]\tTime  0.054 ( 0.055)\tLoss 6.2161e+01 (7.0007e+01)\tAcc@1  87.50 ( 79.93)\tAcc@5  96.88 ( 97.03)\n","Epoch: [24][600/782]\tTime  0.055 ( 0.055)\tLoss 5.1367e+01 (7.0346e+01)\tAcc@1  84.38 ( 79.88)\tAcc@5  96.88 ( 96.99)\n","Epoch: [24][700/782]\tTime  0.053 ( 0.055)\tLoss 7.6526e+01 (7.1177e+01)\tAcc@1  75.00 ( 79.64)\tAcc@5  95.31 ( 96.91)\n","==> Train Accuracy: Acc@1 79.438 || Acc@5 96.862\n","==> Test Accuracy:  Acc@1 52.950 || Acc@5 79.850\n","==> 45.52 seconds to train this epoch\n","\n","\n","----- epoch: 25/100, lr: 0.001 -----\n","Epoch: [25][  0/782]\tTime  0.160 ( 0.160)\tLoss 4.1697e+01 (4.1697e+01)\tAcc@1  89.06 ( 89.06)\tAcc@5  98.44 ( 98.44)\n","Epoch: [25][100/782]\tTime  0.053 ( 0.056)\tLoss 1.2062e+02 (6.1811e+01)\tAcc@1  68.75 ( 81.96)\tAcc@5  90.62 ( 97.71)\n","Epoch: [25][200/782]\tTime  0.054 ( 0.056)\tLoss 7.6576e+01 (6.2503e+01)\tAcc@1  78.12 ( 81.91)\tAcc@5  96.88 ( 97.70)\n","Epoch: [25][300/782]\tTime  0.055 ( 0.055)\tLoss 4.7046e+01 (6.4077e+01)\tAcc@1  87.50 ( 81.57)\tAcc@5 100.00 ( 97.46)\n","Epoch: [25][400/782]\tTime  0.053 ( 0.055)\tLoss 9.8463e+01 (6.5359e+01)\tAcc@1  76.56 ( 80.98)\tAcc@5  96.88 ( 97.43)\n","Epoch: [25][500/782]\tTime  0.054 ( 0.055)\tLoss 8.1358e+01 (6.6628e+01)\tAcc@1  79.69 ( 80.51)\tAcc@5  96.88 ( 97.38)\n","Epoch: [25][600/782]\tTime  0.060 ( 0.056)\tLoss 6.0443e+01 (6.7926e+01)\tAcc@1  85.94 ( 80.25)\tAcc@5  95.31 ( 97.30)\n","Epoch: [25][700/782]\tTime  0.059 ( 0.056)\tLoss 5.7571e+01 (6.8464e+01)\tAcc@1  78.12 ( 80.10)\tAcc@5  96.88 ( 97.26)\n","==> Train Accuracy: Acc@1 79.926 || Acc@5 97.188\n","==> Test Accuracy:  Acc@1 52.740 || Acc@5 80.330\n","==> 46.21 seconds to train this epoch\n","\n","\n","----- epoch: 26/100, lr: 0.001 -----\n","Epoch: [26][  0/782]\tTime  0.156 ( 0.156)\tLoss 4.2443e+01 (4.2443e+01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n","Epoch: [26][100/782]\tTime  0.060 ( 0.058)\tLoss 5.0836e+01 (5.6230e+01)\tAcc@1  81.25 ( 84.13)\tAcc@5 100.00 ( 98.30)\n","Epoch: [26][200/782]\tTime  0.055 ( 0.058)\tLoss 5.4485e+01 (5.8340e+01)\tAcc@1  82.81 ( 83.36)\tAcc@5 100.00 ( 98.18)\n","Epoch: [26][300/782]\tTime  0.059 ( 0.057)\tLoss 9.3904e+01 (6.0229e+01)\tAcc@1  70.31 ( 82.68)\tAcc@5  96.88 ( 98.09)\n","Epoch: [26][400/782]\tTime  0.056 ( 0.057)\tLoss 6.6705e+01 (6.1216e+01)\tAcc@1  87.50 ( 82.27)\tAcc@5  96.88 ( 98.03)\n","Epoch: [26][500/782]\tTime  0.055 ( 0.057)\tLoss 6.6722e+01 (6.2640e+01)\tAcc@1  84.38 ( 81.98)\tAcc@5  93.75 ( 97.87)\n","Epoch: [26][600/782]\tTime  0.056 ( 0.057)\tLoss 6.4839e+01 (6.3660e+01)\tAcc@1  84.38 ( 81.76)\tAcc@5  96.88 ( 97.75)\n","Epoch: [26][700/782]\tTime  0.060 ( 0.057)\tLoss 6.1067e+01 (6.4636e+01)\tAcc@1  87.50 ( 81.50)\tAcc@5  98.44 ( 97.63)\n","==> Train Accuracy: Acc@1 81.354 || Acc@5 97.592\n","==> Test Accuracy:  Acc@1 52.390 || Acc@5 80.410\n","==> 46.89 seconds to train this epoch\n","\n","\n","----- epoch: 27/100, lr: 0.001 -----\n","Epoch: [27][  0/782]\tTime  0.152 ( 0.152)\tLoss 6.7762e+01 (6.7762e+01)\tAcc@1  81.25 ( 81.25)\tAcc@5  96.88 ( 96.88)\n","Epoch: [27][100/782]\tTime  0.055 ( 0.057)\tLoss 3.6816e+01 (5.4791e+01)\tAcc@1  89.06 ( 84.67)\tAcc@5 100.00 ( 98.21)\n","Epoch: [27][200/782]\tTime  0.055 ( 0.056)\tLoss 6.1109e+01 (5.5090e+01)\tAcc@1  76.56 ( 84.34)\tAcc@5  96.88 ( 98.20)\n","Epoch: [27][300/782]\tTime  0.055 ( 0.056)\tLoss 6.0523e+01 (5.7158e+01)\tAcc@1  84.38 ( 83.80)\tAcc@5  98.44 ( 98.05)\n","Epoch: [27][400/782]\tTime  0.060 ( 0.056)\tLoss 7.5953e+01 (5.7364e+01)\tAcc@1  76.56 ( 83.62)\tAcc@5  96.88 ( 98.09)\n","Epoch: [27][500/782]\tTime  0.056 ( 0.056)\tLoss 5.9953e+01 (5.8652e+01)\tAcc@1  82.81 ( 83.19)\tAcc@5 100.00 ( 98.05)\n","Epoch: [27][600/782]\tTime  0.055 ( 0.056)\tLoss 7.0151e+01 (6.0021e+01)\tAcc@1  81.25 ( 82.78)\tAcc@5  96.88 ( 97.99)\n","Epoch: [27][700/782]\tTime  0.055 ( 0.056)\tLoss 5.5849e+01 (6.1000e+01)\tAcc@1  81.25 ( 82.36)\tAcc@5  98.44 ( 97.94)\n","==> Train Accuracy: Acc@1 82.194 || Acc@5 97.884\n","==> Test Accuracy:  Acc@1 52.190 || Acc@5 79.870\n","==> 45.88 seconds to train this epoch\n","\n","\n","----- epoch: 28/100, lr: 0.001 -----\n","Epoch: [28][  0/782]\tTime  0.149 ( 0.149)\tLoss 6.3505e+01 (6.3505e+01)\tAcc@1  81.25 ( 81.25)\tAcc@5  96.88 ( 96.88)\n","Epoch: [28][100/782]\tTime  0.054 ( 0.056)\tLoss 7.9541e+01 (5.0884e+01)\tAcc@1  75.00 ( 85.80)\tAcc@5  98.44 ( 98.73)\n","Epoch: [28][200/782]\tTime  0.054 ( 0.056)\tLoss 5.5403e+01 (5.1479e+01)\tAcc@1  84.38 ( 85.60)\tAcc@5  96.88 ( 98.64)\n","Epoch: [28][300/782]\tTime  0.054 ( 0.056)\tLoss 6.4478e+01 (5.3907e+01)\tAcc@1  82.81 ( 84.72)\tAcc@5  98.44 ( 98.43)\n","Epoch: [28][400/782]\tTime  0.054 ( 0.056)\tLoss 6.6831e+01 (5.4907e+01)\tAcc@1  76.56 ( 84.45)\tAcc@5 100.00 ( 98.34)\n","Epoch: [28][500/782]\tTime  0.055 ( 0.056)\tLoss 8.4124e+01 (5.5897e+01)\tAcc@1  76.56 ( 84.13)\tAcc@5  93.75 ( 98.31)\n","Epoch: [28][600/782]\tTime  0.054 ( 0.055)\tLoss 6.4661e+01 (5.7017e+01)\tAcc@1  84.38 ( 83.71)\tAcc@5  98.44 ( 98.26)\n","Epoch: [28][700/782]\tTime  0.054 ( 0.055)\tLoss 7.4171e+01 (5.8006e+01)\tAcc@1  78.12 ( 83.48)\tAcc@5  98.44 ( 98.15)\n","==> Train Accuracy: Acc@1 83.230 || Acc@5 98.114\n","==> Test Accuracy:  Acc@1 52.300 || Acc@5 79.900\n","==> 45.90 seconds to train this epoch\n","\n","\n","----- epoch: 29/100, lr: 0.001 -----\n","Epoch: [29][  0/782]\tTime  0.139 ( 0.139)\tLoss 6.6343e+01 (6.6343e+01)\tAcc@1  82.81 ( 82.81)\tAcc@5  98.44 ( 98.44)\n","Epoch: [29][100/782]\tTime  0.059 ( 0.058)\tLoss 5.4445e+01 (4.5993e+01)\tAcc@1  82.81 ( 87.38)\tAcc@5  96.88 ( 98.78)\n","Epoch: [29][200/782]\tTime  0.054 ( 0.057)\tLoss 3.9711e+01 (4.8260e+01)\tAcc@1  90.62 ( 86.57)\tAcc@5 100.00 ( 98.66)\n","Epoch: [29][300/782]\tTime  0.054 ( 0.056)\tLoss 5.9673e+01 (5.0025e+01)\tAcc@1  81.25 ( 85.89)\tAcc@5  98.44 ( 98.68)\n","Epoch: [29][400/782]\tTime  0.060 ( 0.056)\tLoss 6.7778e+01 (5.1054e+01)\tAcc@1  79.69 ( 85.63)\tAcc@5  92.19 ( 98.57)\n","Epoch: [29][500/782]\tTime  0.055 ( 0.056)\tLoss 9.0334e+01 (5.2631e+01)\tAcc@1  79.69 ( 85.10)\tAcc@5  96.88 ( 98.46)\n","Epoch: [29][600/782]\tTime  0.055 ( 0.056)\tLoss 6.5600e+01 (5.3492e+01)\tAcc@1  76.56 ( 84.82)\tAcc@5  96.88 ( 98.46)\n","Epoch: [29][700/782]\tTime  0.054 ( 0.056)\tLoss 5.4980e+01 (5.4259e+01)\tAcc@1  81.25 ( 84.61)\tAcc@5  98.44 ( 98.43)\n","==> Train Accuracy: Acc@1 84.362 || Acc@5 98.396\n","==> Test Accuracy:  Acc@1 53.100 || Acc@5 79.730\n","==> 46.54 seconds to train this epoch\n","\n","\n","----- epoch: 30/100, lr: 0.0001 -----\n","Epoch: [30][  0/782]\tTime  0.148 ( 0.148)\tLoss 4.1590e+01 (4.1590e+01)\tAcc@1  84.38 ( 84.38)\tAcc@5 100.00 (100.00)\n","Epoch: [30][100/782]\tTime  0.053 ( 0.056)\tLoss 4.1033e+01 (4.0569e+01)\tAcc@1  90.62 ( 89.31)\tAcc@5  98.44 ( 99.21)\n","Epoch: [30][200/782]\tTime  0.056 ( 0.055)\tLoss 3.0578e+01 (3.8115e+01)\tAcc@1  92.19 ( 89.96)\tAcc@5  98.44 ( 99.24)\n","Epoch: [30][300/782]\tTime  0.057 ( 0.055)\tLoss 2.0430e+01 (3.6739e+01)\tAcc@1  96.88 ( 90.44)\tAcc@5 100.00 ( 99.27)\n","Epoch: [30][400/782]\tTime  0.055 ( 0.055)\tLoss 4.6194e+01 (3.5511e+01)\tAcc@1  90.62 ( 90.84)\tAcc@5  96.88 ( 99.33)\n","Epoch: [30][500/782]\tTime  0.055 ( 0.055)\tLoss 2.2578e+01 (3.4330e+01)\tAcc@1  95.31 ( 91.18)\tAcc@5  98.44 ( 99.39)\n","Epoch: [30][600/782]\tTime  0.054 ( 0.055)\tLoss 3.3895e+01 (3.3623e+01)\tAcc@1  92.19 ( 91.39)\tAcc@5  98.44 ( 99.43)\n","Epoch: [30][700/782]\tTime  0.054 ( 0.055)\tLoss 3.0163e+01 (3.2777e+01)\tAcc@1  93.75 ( 91.67)\tAcc@5 100.00 ( 99.44)\n","==> Train Accuracy: Acc@1 91.774 || Acc@5 99.454\n","==> Test Accuracy:  Acc@1 56.100 || Acc@5 82.180\n","==> 45.80 seconds to train this epoch\n","\n","\n","----- epoch: 31/100, lr: 0.0001 -----\n","Epoch: [31][  0/782]\tTime  0.146 ( 0.146)\tLoss 2.8306e+01 (2.8306e+01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n","Epoch: [31][100/782]\tTime  0.054 ( 0.056)\tLoss 1.7500e+01 (2.4556e+01)\tAcc@1  93.75 ( 94.35)\tAcc@5 100.00 ( 99.74)\n","Epoch: [31][200/782]\tTime  0.054 ( 0.056)\tLoss 2.0564e+01 (2.5482e+01)\tAcc@1  92.19 ( 93.99)\tAcc@5 100.00 ( 99.69)\n","Epoch: [31][300/782]\tTime  0.054 ( 0.056)\tLoss 3.5082e+01 (2.5671e+01)\tAcc@1  92.19 ( 94.01)\tAcc@5 100.00 ( 99.65)\n","Epoch: [31][400/782]\tTime  0.054 ( 0.056)\tLoss 2.9100e+01 (2.5459e+01)\tAcc@1  92.19 ( 94.07)\tAcc@5 100.00 ( 99.65)\n","Epoch: [31][500/782]\tTime  0.055 ( 0.056)\tLoss 2.4106e+01 (2.4898e+01)\tAcc@1  93.75 ( 94.25)\tAcc@5 100.00 ( 99.69)\n","Epoch: [31][600/782]\tTime  0.054 ( 0.056)\tLoss 2.9101e+01 (2.4745e+01)\tAcc@1  93.75 ( 94.30)\tAcc@5 100.00 ( 99.70)\n","Epoch: [31][700/782]\tTime  0.059 ( 0.056)\tLoss 1.8260e+01 (2.4611e+01)\tAcc@1  93.75 ( 94.28)\tAcc@5 100.00 ( 99.71)\n","==> Train Accuracy: Acc@1 94.302 || Acc@5 99.704\n","==> Test Accuracy:  Acc@1 55.820 || Acc@5 82.030\n","==> 46.20 seconds to train this epoch\n","\n","\n","----- epoch: 32/100, lr: 0.0001 -----\n","Epoch: [32][  0/782]\tTime  0.140 ( 0.140)\tLoss 1.6672e+01 (1.6672e+01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [32][100/782]\tTime  0.056 ( 0.056)\tLoss 2.8038e+01 (2.2057e+01)\tAcc@1  90.62 ( 94.86)\tAcc@5 100.00 ( 99.85)\n","Epoch: [32][200/782]\tTime  0.053 ( 0.055)\tLoss 1.7749e+01 (2.1406e+01)\tAcc@1  95.31 ( 95.22)\tAcc@5 100.00 ( 99.81)\n","Epoch: [32][300/782]\tTime  0.053 ( 0.055)\tLoss 1.8158e+01 (2.1509e+01)\tAcc@1  93.75 ( 95.08)\tAcc@5 100.00 ( 99.80)\n","Epoch: [32][400/782]\tTime  0.054 ( 0.055)\tLoss 2.3078e+01 (2.1013e+01)\tAcc@1  93.75 ( 95.27)\tAcc@5 100.00 ( 99.83)\n","Epoch: [32][500/782]\tTime  0.053 ( 0.055)\tLoss 1.3915e+01 (2.1091e+01)\tAcc@1  96.88 ( 95.22)\tAcc@5 100.00 ( 99.83)\n","Epoch: [32][600/782]\tTime  0.054 ( 0.055)\tLoss 1.8282e+01 (2.1123e+01)\tAcc@1  95.31 ( 95.20)\tAcc@5 100.00 ( 99.82)\n","Epoch: [32][700/782]\tTime  0.054 ( 0.055)\tLoss 1.6435e+01 (2.1264e+01)\tAcc@1  95.31 ( 95.19)\tAcc@5 100.00 ( 99.80)\n","==> Train Accuracy: Acc@1 95.194 || Acc@5 99.792\n","==> Test Accuracy:  Acc@1 56.310 || Acc@5 82.030\n","==> 45.83 seconds to train this epoch\n","\n","\n","----- epoch: 33/100, lr: 0.0001 -----\n","Epoch: [33][  0/782]\tTime  0.160 ( 0.160)\tLoss 1.6239e+01 (1.6239e+01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [33][100/782]\tTime  0.054 ( 0.058)\tLoss 3.0410e+01 (1.9995e+01)\tAcc@1  92.19 ( 95.90)\tAcc@5 100.00 ( 99.75)\n","Epoch: [33][200/782]\tTime  0.056 ( 0.057)\tLoss 2.6888e+01 (1.9526e+01)\tAcc@1  92.19 ( 95.89)\tAcc@5 100.00 ( 99.81)\n","Epoch: [33][300/782]\tTime  0.054 ( 0.056)\tLoss 1.5345e+01 (1.9542e+01)\tAcc@1  96.88 ( 95.74)\tAcc@5 100.00 ( 99.83)\n","Epoch: [33][400/782]\tTime  0.054 ( 0.056)\tLoss 2.8277e+01 (1.9295e+01)\tAcc@1  93.75 ( 95.80)\tAcc@5 100.00 ( 99.84)\n","Epoch: [33][500/782]\tTime  0.055 ( 0.056)\tLoss 1.6029e+01 (1.9532e+01)\tAcc@1  96.88 ( 95.81)\tAcc@5 100.00 ( 99.83)\n","Epoch: [33][600/782]\tTime  0.058 ( 0.056)\tLoss 3.9856e+01 (1.9462e+01)\tAcc@1  89.06 ( 95.87)\tAcc@5  98.44 ( 99.83)\n","Epoch: [33][700/782]\tTime  0.054 ( 0.056)\tLoss 1.9523e+01 (1.9433e+01)\tAcc@1  96.88 ( 95.86)\tAcc@5 100.00 ( 99.83)\n","==> Train Accuracy: Acc@1 95.822 || Acc@5 99.824\n","==> Test Accuracy:  Acc@1 55.670 || Acc@5 81.900\n","==> 45.95 seconds to train this epoch\n","\n","\n","----- epoch: 34/100, lr: 0.0001 -----\n","Epoch: [34][  0/782]\tTime  0.149 ( 0.149)\tLoss 3.3198e+01 (3.3198e+01)\tAcc@1  93.75 ( 93.75)\tAcc@5  98.44 ( 98.44)\n","Epoch: [34][100/782]\tTime  0.054 ( 0.056)\tLoss 1.6411e+01 (1.7532e+01)\tAcc@1  95.31 ( 96.16)\tAcc@5 100.00 ( 99.91)\n","Epoch: [34][200/782]\tTime  0.054 ( 0.055)\tLoss 1.5334e+01 (1.7719e+01)\tAcc@1  96.88 ( 96.20)\tAcc@5 100.00 ( 99.91)\n","Epoch: [34][300/782]\tTime  0.055 ( 0.055)\tLoss 3.7431e+01 (1.7704e+01)\tAcc@1  92.19 ( 96.26)\tAcc@5  98.44 ( 99.89)\n","Epoch: [34][400/782]\tTime  0.054 ( 0.055)\tLoss 1.6426e+01 (1.7867e+01)\tAcc@1  93.75 ( 96.19)\tAcc@5 100.00 ( 99.88)\n","Epoch: [34][500/782]\tTime  0.059 ( 0.055)\tLoss 2.3968e+01 (1.7678e+01)\tAcc@1  93.75 ( 96.22)\tAcc@5 100.00 ( 99.87)\n","Epoch: [34][600/782]\tTime  0.054 ( 0.055)\tLoss 1.6530e+01 (1.7677e+01)\tAcc@1  96.88 ( 96.23)\tAcc@5 100.00 ( 99.88)\n","Epoch: [34][700/782]\tTime  0.054 ( 0.055)\tLoss 1.5829e+01 (1.7818e+01)\tAcc@1  95.31 ( 96.19)\tAcc@5 100.00 ( 99.88)\n","==> Train Accuracy: Acc@1 96.188 || Acc@5 99.876\n","==> Test Accuracy:  Acc@1 56.070 || Acc@5 81.870\n","==> 45.94 seconds to train this epoch\n","\n","\n","----- epoch: 35/100, lr: 0.0001 -----\n","Epoch: [35][  0/782]\tTime  0.153 ( 0.153)\tLoss 2.3879e+01 (2.3879e+01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n","Epoch: [35][100/782]\tTime  0.055 ( 0.056)\tLoss 1.4244e+01 (1.6181e+01)\tAcc@1  96.88 ( 96.77)\tAcc@5 100.00 ( 99.92)\n","Epoch: [35][200/782]\tTime  0.060 ( 0.055)\tLoss 1.3530e+01 (1.6499e+01)\tAcc@1  98.44 ( 96.74)\tAcc@5 100.00 ( 99.89)\n","Epoch: [35][300/782]\tTime  0.054 ( 0.056)\tLoss 1.5783e+01 (1.6320e+01)\tAcc@1  98.44 ( 96.85)\tAcc@5 100.00 ( 99.90)\n","Epoch: [35][400/782]\tTime  0.055 ( 0.055)\tLoss 2.7167e+01 (1.6449e+01)\tAcc@1  93.75 ( 96.75)\tAcc@5 100.00 ( 99.91)\n","Epoch: [35][500/782]\tTime  0.060 ( 0.055)\tLoss 1.8852e+01 (1.6484e+01)\tAcc@1  98.44 ( 96.73)\tAcc@5  98.44 ( 99.89)\n","Epoch: [35][600/782]\tTime  0.054 ( 0.055)\tLoss 1.3955e+01 (1.6381e+01)\tAcc@1  95.31 ( 96.74)\tAcc@5 100.00 ( 99.90)\n","Epoch: [35][700/782]\tTime  0.056 ( 0.055)\tLoss 2.6063e+01 (1.6506e+01)\tAcc@1  90.62 ( 96.73)\tAcc@5 100.00 ( 99.90)\n","==> Train Accuracy: Acc@1 96.706 || Acc@5 99.890\n","==> Test Accuracy:  Acc@1 55.900 || Acc@5 81.640\n","==> 45.95 seconds to train this epoch\n","\n","\n","----- epoch: 36/100, lr: 0.0001 -----\n","Epoch: [36][  0/782]\tTime  0.142 ( 0.142)\tLoss 9.4838e+00 (9.4838e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [36][100/782]\tTime  0.054 ( 0.056)\tLoss 8.3404e+00 (1.5153e+01)\tAcc@1 100.00 ( 97.05)\tAcc@5 100.00 ( 99.91)\n","Epoch: [36][200/782]\tTime  0.054 ( 0.055)\tLoss 7.4611e+00 (1.4937e+01)\tAcc@1 100.00 ( 97.15)\tAcc@5 100.00 ( 99.91)\n","Epoch: [36][300/782]\tTime  0.055 ( 0.056)\tLoss 1.4818e+01 (1.5064e+01)\tAcc@1  98.44 ( 97.07)\tAcc@5 100.00 ( 99.92)\n","Epoch: [36][400/782]\tTime  0.055 ( 0.056)\tLoss 2.3710e+01 (1.5143e+01)\tAcc@1  92.19 ( 97.10)\tAcc@5 100.00 ( 99.91)\n","Epoch: [36][500/782]\tTime  0.054 ( 0.056)\tLoss 1.5890e+01 (1.5298e+01)\tAcc@1  96.88 ( 97.06)\tAcc@5 100.00 ( 99.92)\n","Epoch: [36][600/782]\tTime  0.061 ( 0.056)\tLoss 8.3073e+00 (1.5328e+01)\tAcc@1 100.00 ( 97.07)\tAcc@5 100.00 ( 99.92)\n","Epoch: [36][700/782]\tTime  0.059 ( 0.056)\tLoss 1.5922e+01 (1.5232e+01)\tAcc@1  98.44 ( 97.09)\tAcc@5 100.00 ( 99.93)\n","==> Train Accuracy: Acc@1 97.042 || Acc@5 99.928\n","==> Test Accuracy:  Acc@1 55.600 || Acc@5 81.710\n","==> 46.34 seconds to train this epoch\n","\n","\n","----- epoch: 37/100, lr: 0.0001 -----\n","Epoch: [37][  0/782]\tTime  0.151 ( 0.151)\tLoss 2.1175e+01 (2.1175e+01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [37][100/782]\tTime  0.059 ( 0.058)\tLoss 1.9452e+01 (1.3910e+01)\tAcc@1  96.88 ( 97.63)\tAcc@5 100.00 ( 99.98)\n","Epoch: [37][200/782]\tTime  0.054 ( 0.057)\tLoss 2.1908e+01 (1.4032e+01)\tAcc@1  93.75 ( 97.51)\tAcc@5 100.00 ( 99.98)\n","Epoch: [37][300/782]\tTime  0.054 ( 0.057)\tLoss 1.2274e+01 (1.3956e+01)\tAcc@1  96.88 ( 97.51)\tAcc@5 100.00 ( 99.96)\n","Epoch: [37][400/782]\tTime  0.055 ( 0.057)\tLoss 1.5832e+01 (1.4102e+01)\tAcc@1  95.31 ( 97.44)\tAcc@5 100.00 ( 99.96)\n","Epoch: [37][500/782]\tTime  0.055 ( 0.056)\tLoss 7.9235e+00 (1.3950e+01)\tAcc@1 100.00 ( 97.48)\tAcc@5 100.00 ( 99.94)\n","Epoch: [37][600/782]\tTime  0.054 ( 0.056)\tLoss 1.8286e+01 (1.3965e+01)\tAcc@1  95.31 ( 97.49)\tAcc@5 100.00 ( 99.94)\n","Epoch: [37][700/782]\tTime  0.054 ( 0.056)\tLoss 1.8652e+01 (1.4011e+01)\tAcc@1  96.88 ( 97.47)\tAcc@5 100.00 ( 99.94)\n","==> Train Accuracy: Acc@1 97.406 || Acc@5 99.940\n","==> Test Accuracy:  Acc@1 55.740 || Acc@5 81.480\n","==> 46.46 seconds to train this epoch\n","\n","\n","----- epoch: 38/100, lr: 0.0001 -----\n","Epoch: [38][  0/782]\tTime  0.149 ( 0.149)\tLoss 1.3061e+01 (1.3061e+01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n","Epoch: [38][100/782]\tTime  0.059 ( 0.057)\tLoss 1.3038e+01 (1.3057e+01)\tAcc@1  98.44 ( 97.76)\tAcc@5 100.00 ( 99.95)\n","Epoch: [38][200/782]\tTime  0.061 ( 0.057)\tLoss 1.2596e+01 (1.2970e+01)\tAcc@1  98.44 ( 97.66)\tAcc@5 100.00 ( 99.95)\n","Epoch: [38][300/782]\tTime  0.054 ( 0.056)\tLoss 2.5842e+01 (1.3171e+01)\tAcc@1  96.88 ( 97.63)\tAcc@5  98.44 ( 99.94)\n","Epoch: [38][400/782]\tTime  0.054 ( 0.056)\tLoss 1.5614e+01 (1.3244e+01)\tAcc@1  96.88 ( 97.59)\tAcc@5 100.00 ( 99.94)\n","Epoch: [38][500/782]\tTime  0.054 ( 0.056)\tLoss 2.8012e+01 (1.3140e+01)\tAcc@1  93.75 ( 97.63)\tAcc@5 100.00 ( 99.95)\n","Epoch: [38][600/782]\tTime  0.061 ( 0.056)\tLoss 9.4074e+00 (1.3202e+01)\tAcc@1  96.88 ( 97.63)\tAcc@5 100.00 ( 99.96)\n","Epoch: [38][700/782]\tTime  0.056 ( 0.056)\tLoss 1.0629e+01 (1.3323e+01)\tAcc@1 100.00 ( 97.61)\tAcc@5 100.00 ( 99.96)\n","==> Train Accuracy: Acc@1 97.580 || Acc@5 99.956\n","==> Test Accuracy:  Acc@1 55.730 || Acc@5 81.460\n","==> 46.32 seconds to train this epoch\n","\n","\n","----- epoch: 39/100, lr: 0.0001 -----\n","Epoch: [39][  0/782]\tTime  0.151 ( 0.151)\tLoss 1.1995e+01 (1.1995e+01)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [39][100/782]\tTime  0.061 ( 0.058)\tLoss 2.0102e+01 (1.2267e+01)\tAcc@1  98.44 ( 97.88)\tAcc@5 100.00 ( 99.94)\n","Epoch: [39][200/782]\tTime  0.055 ( 0.057)\tLoss 6.7607e+00 (1.2378e+01)\tAcc@1  98.44 ( 97.94)\tAcc@5 100.00 ( 99.94)\n","Epoch: [39][300/782]\tTime  0.054 ( 0.056)\tLoss 1.4855e+01 (1.2439e+01)\tAcc@1  96.88 ( 97.91)\tAcc@5 100.00 ( 99.94)\n","Epoch: [39][400/782]\tTime  0.054 ( 0.057)\tLoss 8.2382e+00 (1.2529e+01)\tAcc@1  98.44 ( 97.78)\tAcc@5 100.00 ( 99.95)\n","Epoch: [39][500/782]\tTime  0.054 ( 0.056)\tLoss 2.6570e+01 (1.2619e+01)\tAcc@1  90.62 ( 97.75)\tAcc@5 100.00 ( 99.96)\n","Epoch: [39][600/782]\tTime  0.056 ( 0.056)\tLoss 1.1174e+01 (1.2666e+01)\tAcc@1 100.00 ( 97.73)\tAcc@5 100.00 ( 99.96)\n","Epoch: [39][700/782]\tTime  0.061 ( 0.056)\tLoss 1.4996e+01 (1.2653e+01)\tAcc@1  98.44 ( 97.77)\tAcc@5 100.00 ( 99.96)\n","==> Train Accuracy: Acc@1 97.734 || Acc@5 99.948\n","==> Test Accuracy:  Acc@1 55.580 || Acc@5 81.170\n","==> 46.42 seconds to train this epoch\n","\n","\n","----- epoch: 40/100, lr: 0.0001 -----\n","Epoch: [40][  0/782]\tTime  0.151 ( 0.151)\tLoss 7.9320e+00 (7.9320e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [40][100/782]\tTime  0.054 ( 0.056)\tLoss 1.4619e+01 (1.1196e+01)\tAcc@1  96.88 ( 98.22)\tAcc@5 100.00 ( 99.98)\n","Epoch: [40][200/782]\tTime  0.054 ( 0.056)\tLoss 5.7811e+00 (1.1611e+01)\tAcc@1 100.00 ( 98.03)\tAcc@5 100.00 ( 99.98)\n","Epoch: [40][300/782]\tTime  0.054 ( 0.056)\tLoss 1.0472e+01 (1.1735e+01)\tAcc@1  96.88 ( 98.06)\tAcc@5 100.00 ( 99.98)\n","Epoch: [40][400/782]\tTime  0.055 ( 0.056)\tLoss 1.3446e+01 (1.1811e+01)\tAcc@1  98.44 ( 98.02)\tAcc@5 100.00 ( 99.98)\n","Epoch: [40][500/782]\tTime  0.055 ( 0.056)\tLoss 8.4964e+00 (1.1794e+01)\tAcc@1  98.44 ( 97.99)\tAcc@5 100.00 ( 99.98)\n","Epoch: [40][600/782]\tTime  0.053 ( 0.056)\tLoss 8.7384e+00 (1.1771e+01)\tAcc@1  96.88 ( 98.03)\tAcc@5 100.00 ( 99.98)\n","Epoch: [40][700/782]\tTime  0.054 ( 0.056)\tLoss 8.7383e+00 (1.1720e+01)\tAcc@1 100.00 ( 98.06)\tAcc@5 100.00 ( 99.98)\n","==> Train Accuracy: Acc@1 98.030 || Acc@5 99.974\n","==> Test Accuracy:  Acc@1 55.550 || Acc@5 81.180\n","==> 46.45 seconds to train this epoch\n","\n","\n","----- epoch: 41/100, lr: 0.0001 -----\n","Epoch: [41][  0/782]\tTime  0.152 ( 0.152)\tLoss 1.5026e+01 (1.5026e+01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n","Epoch: [41][100/782]\tTime  0.054 ( 0.057)\tLoss 1.5095e+01 (1.0760e+01)\tAcc@1  98.44 ( 98.48)\tAcc@5 100.00 ( 99.98)\n","Epoch: [41][200/782]\tTime  0.054 ( 0.056)\tLoss 5.2654e+00 (1.0762e+01)\tAcc@1 100.00 ( 98.30)\tAcc@5 100.00 ( 99.98)\n","Epoch: [41][300/782]\tTime  0.054 ( 0.056)\tLoss 1.0083e+01 (1.0720e+01)\tAcc@1  98.44 ( 98.33)\tAcc@5 100.00 ( 99.98)\n","Epoch: [41][400/782]\tTime  0.054 ( 0.056)\tLoss 8.9446e+00 (1.0878e+01)\tAcc@1 100.00 ( 98.29)\tAcc@5 100.00 ( 99.97)\n","Epoch: [41][500/782]\tTime  0.054 ( 0.056)\tLoss 1.3552e+01 (1.1157e+01)\tAcc@1  98.44 ( 98.23)\tAcc@5 100.00 ( 99.96)\n","Epoch: [41][600/782]\tTime  0.055 ( 0.055)\tLoss 1.7248e+01 (1.1347e+01)\tAcc@1  95.31 ( 98.20)\tAcc@5 100.00 ( 99.96)\n","Epoch: [41][700/782]\tTime  0.054 ( 0.055)\tLoss 1.6627e+01 (1.1505e+01)\tAcc@1  96.88 ( 98.13)\tAcc@5 100.00 ( 99.97)\n","==> Train Accuracy: Acc@1 98.118 || Acc@5 99.966\n","==> Test Accuracy:  Acc@1 55.460 || Acc@5 81.340\n","==> 46.08 seconds to train this epoch\n","\n","\n","----- epoch: 42/100, lr: 0.0001 -----\n","Epoch: [42][  0/782]\tTime  0.158 ( 0.158)\tLoss 3.2725e+00 (3.2725e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [42][100/782]\tTime  0.055 ( 0.057)\tLoss 1.2492e+01 (1.0378e+01)\tAcc@1  98.44 ( 98.48)\tAcc@5 100.00 ( 99.95)\n","Epoch: [42][200/782]\tTime  0.060 ( 0.056)\tLoss 3.6772e+01 (1.0434e+01)\tAcc@1  93.75 ( 98.39)\tAcc@5  96.88 ( 99.95)\n","Epoch: [42][300/782]\tTime  0.059 ( 0.056)\tLoss 2.3765e+01 (1.0550e+01)\tAcc@1  92.19 ( 98.42)\tAcc@5 100.00 ( 99.96)\n","Epoch: [42][400/782]\tTime  0.053 ( 0.056)\tLoss 1.3611e+01 (1.0660e+01)\tAcc@1  96.88 ( 98.37)\tAcc@5 100.00 ( 99.96)\n","Epoch: [42][500/782]\tTime  0.054 ( 0.056)\tLoss 1.1623e+01 (1.0587e+01)\tAcc@1  98.44 ( 98.38)\tAcc@5 100.00 ( 99.97)\n","Epoch: [42][600/782]\tTime  0.055 ( 0.056)\tLoss 7.5399e+00 (1.0822e+01)\tAcc@1 100.00 ( 98.30)\tAcc@5 100.00 ( 99.97)\n","Epoch: [42][700/782]\tTime  0.055 ( 0.056)\tLoss 6.7032e+00 (1.0831e+01)\tAcc@1  98.44 ( 98.28)\tAcc@5 100.00 ( 99.98)\n","==> Train Accuracy: Acc@1 98.260 || Acc@5 99.976\n","==> Test Accuracy:  Acc@1 55.410 || Acc@5 81.220\n","==> 46.42 seconds to train this epoch\n","\n","\n","----- epoch: 43/100, lr: 0.0001 -----\n","Epoch: [43][  0/782]\tTime  0.145 ( 0.145)\tLoss 1.1241e+01 (1.1241e+01)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [43][100/782]\tTime  0.060 ( 0.059)\tLoss 8.6527e+00 (1.0012e+01)\tAcc@1 100.00 ( 98.42)\tAcc@5 100.00 ( 99.98)\n","Epoch: [43][200/782]\tTime  0.054 ( 0.058)\tLoss 8.2842e+00 (1.0024e+01)\tAcc@1 100.00 ( 98.41)\tAcc@5 100.00 ( 99.98)\n","Epoch: [43][300/782]\tTime  0.055 ( 0.057)\tLoss 1.9997e+01 (1.0042e+01)\tAcc@1  96.88 ( 98.34)\tAcc@5 100.00 ( 99.98)\n","Epoch: [43][400/782]\tTime  0.060 ( 0.057)\tLoss 1.4529e+01 (1.0039e+01)\tAcc@1  96.88 ( 98.36)\tAcc@5 100.00 ( 99.99)\n","Epoch: [43][500/782]\tTime  0.055 ( 0.057)\tLoss 1.0012e+01 (1.0114e+01)\tAcc@1  96.88 ( 98.34)\tAcc@5 100.00 ( 99.99)\n","Epoch: [43][600/782]\tTime  0.054 ( 0.056)\tLoss 8.5108e+00 (1.0284e+01)\tAcc@1  98.44 ( 98.32)\tAcc@5 100.00 ( 99.98)\n","Epoch: [43][700/782]\tTime  0.054 ( 0.056)\tLoss 6.0241e+00 (1.0357e+01)\tAcc@1 100.00 ( 98.30)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 98.288 || Acc@5 99.984\n","==> Test Accuracy:  Acc@1 55.600 || Acc@5 81.250\n","==> 46.47 seconds to train this epoch\n","\n","\n","----- epoch: 44/100, lr: 0.0001 -----\n","Epoch: [44][  0/782]\tTime  0.153 ( 0.153)\tLoss 5.5924e+00 (5.5924e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [44][100/782]\tTime  0.054 ( 0.057)\tLoss 8.9883e+00 (1.0194e+01)\tAcc@1  98.44 ( 98.48)\tAcc@5 100.00 (100.00)\n","Epoch: [44][200/782]\tTime  0.059 ( 0.056)\tLoss 1.3855e+01 (9.9852e+00)\tAcc@1  98.44 ( 98.57)\tAcc@5 100.00 ( 99.98)\n","Epoch: [44][300/782]\tTime  0.055 ( 0.056)\tLoss 9.9676e+00 (9.8430e+00)\tAcc@1 100.00 ( 98.61)\tAcc@5 100.00 ( 99.98)\n","Epoch: [44][400/782]\tTime  0.055 ( 0.056)\tLoss 6.8758e+00 (9.5464e+00)\tAcc@1  98.44 ( 98.66)\tAcc@5 100.00 ( 99.98)\n","Epoch: [44][500/782]\tTime  0.058 ( 0.056)\tLoss 1.0351e+01 (9.5964e+00)\tAcc@1  98.44 ( 98.63)\tAcc@5 100.00 ( 99.98)\n","Epoch: [44][600/782]\tTime  0.054 ( 0.056)\tLoss 1.4323e+01 (9.6107e+00)\tAcc@1  98.44 ( 98.62)\tAcc@5 100.00 ( 99.98)\n","Epoch: [44][700/782]\tTime  0.055 ( 0.056)\tLoss 1.6900e+01 (9.7346e+00)\tAcc@1  96.88 ( 98.59)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 98.586 || Acc@5 99.988\n","==> Test Accuracy:  Acc@1 55.510 || Acc@5 81.120\n","==> 46.39 seconds to train this epoch\n","\n","\n","----- epoch: 45/100, lr: 0.0001 -----\n","Epoch: [45][  0/782]\tTime  0.153 ( 0.153)\tLoss 3.1834e+00 (3.1834e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [45][100/782]\tTime  0.055 ( 0.057)\tLoss 1.0504e+01 (9.5325e+00)\tAcc@1  98.44 ( 98.42)\tAcc@5 100.00 (100.00)\n","Epoch: [45][200/782]\tTime  0.055 ( 0.056)\tLoss 6.5421e+00 (9.4412e+00)\tAcc@1  98.44 ( 98.60)\tAcc@5 100.00 ( 99.99)\n","Epoch: [45][300/782]\tTime  0.060 ( 0.056)\tLoss 1.0439e+01 (9.6209e+00)\tAcc@1  96.88 ( 98.53)\tAcc@5 100.00 ( 99.99)\n","Epoch: [45][400/782]\tTime  0.054 ( 0.056)\tLoss 1.2471e+01 (9.5947e+00)\tAcc@1  98.44 ( 98.55)\tAcc@5 100.00 ( 99.99)\n","Epoch: [45][500/782]\tTime  0.054 ( 0.056)\tLoss 1.2997e+01 (9.4938e+00)\tAcc@1  96.88 ( 98.57)\tAcc@5 100.00 ( 99.98)\n","Epoch: [45][600/782]\tTime  0.054 ( 0.056)\tLoss 3.8127e+00 (9.6083e+00)\tAcc@1 100.00 ( 98.52)\tAcc@5 100.00 ( 99.99)\n","Epoch: [45][700/782]\tTime  0.054 ( 0.056)\tLoss 9.9451e+00 (9.6996e+00)\tAcc@1  96.88 ( 98.51)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 98.514 || Acc@5 99.990\n","==> Test Accuracy:  Acc@1 55.330 || Acc@5 80.890\n","==> 46.03 seconds to train this epoch\n","\n","\n","----- epoch: 46/100, lr: 0.0001 -----\n","Epoch: [46][  0/782]\tTime  0.142 ( 0.142)\tLoss 4.3538e+00 (4.3538e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [46][100/782]\tTime  0.054 ( 0.057)\tLoss 9.1559e+00 (9.0434e+00)\tAcc@1  95.31 ( 98.70)\tAcc@5 100.00 (100.00)\n","Epoch: [46][200/782]\tTime  0.054 ( 0.056)\tLoss 5.1891e+00 (9.0331e+00)\tAcc@1 100.00 ( 98.71)\tAcc@5 100.00 (100.00)\n","Epoch: [46][300/782]\tTime  0.054 ( 0.056)\tLoss 6.1464e+00 (8.9855e+00)\tAcc@1 100.00 ( 98.70)\tAcc@5 100.00 (100.00)\n","Epoch: [46][400/782]\tTime  0.059 ( 0.055)\tLoss 8.9670e+00 (9.0700e+00)\tAcc@1 100.00 ( 98.71)\tAcc@5 100.00 (100.00)\n","Epoch: [46][500/782]\tTime  0.054 ( 0.055)\tLoss 9.4472e+00 (8.9921e+00)\tAcc@1  98.44 ( 98.74)\tAcc@5 100.00 (100.00)\n","Epoch: [46][600/782]\tTime  0.053 ( 0.056)\tLoss 6.9214e+00 (9.0450e+00)\tAcc@1  98.44 ( 98.71)\tAcc@5 100.00 ( 99.99)\n","Epoch: [46][700/782]\tTime  0.054 ( 0.055)\tLoss 4.8944e+00 (9.0707e+00)\tAcc@1  98.44 ( 98.71)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 98.702 || Acc@5 99.994\n","==> Test Accuracy:  Acc@1 55.190 || Acc@5 80.980\n","==> 45.90 seconds to train this epoch\n","\n","\n","----- epoch: 47/100, lr: 0.0001 -----\n","Epoch: [47][  0/782]\tTime  0.151 ( 0.151)\tLoss 8.6488e+00 (8.6488e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [47][100/782]\tTime  0.054 ( 0.056)\tLoss 5.3653e+00 (8.9053e+00)\tAcc@1 100.00 ( 98.76)\tAcc@5 100.00 ( 99.98)\n","Epoch: [47][200/782]\tTime  0.054 ( 0.055)\tLoss 9.9044e+00 (8.8901e+00)\tAcc@1  96.88 ( 98.69)\tAcc@5 100.00 ( 99.98)\n","Epoch: [47][300/782]\tTime  0.054 ( 0.055)\tLoss 6.7978e+00 (8.9344e+00)\tAcc@1 100.00 ( 98.69)\tAcc@5 100.00 ( 99.98)\n","Epoch: [47][400/782]\tTime  0.054 ( 0.056)\tLoss 1.0692e+01 (8.9323e+00)\tAcc@1  98.44 ( 98.71)\tAcc@5 100.00 ( 99.98)\n","Epoch: [47][500/782]\tTime  0.053 ( 0.056)\tLoss 1.2910e+01 (9.0581e+00)\tAcc@1  98.44 ( 98.68)\tAcc@5 100.00 ( 99.98)\n","Epoch: [47][600/782]\tTime  0.054 ( 0.056)\tLoss 7.5511e+00 (9.0006e+00)\tAcc@1  98.44 ( 98.67)\tAcc@5 100.00 ( 99.98)\n","Epoch: [47][700/782]\tTime  0.054 ( 0.055)\tLoss 5.5078e+00 (8.9659e+00)\tAcc@1 100.00 ( 98.70)\tAcc@5 100.00 ( 99.98)\n","==> Train Accuracy: Acc@1 98.720 || Acc@5 99.986\n","==> Test Accuracy:  Acc@1 55.530 || Acc@5 80.930\n","==> 46.15 seconds to train this epoch\n","\n","\n","----- epoch: 48/100, lr: 0.0001 -----\n","Epoch: [48][  0/782]\tTime  0.148 ( 0.148)\tLoss 5.9202e+00 (5.9202e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [48][100/782]\tTime  0.059 ( 0.056)\tLoss 4.8694e+00 (7.7592e+00)\tAcc@1 100.00 ( 99.06)\tAcc@5 100.00 (100.00)\n","Epoch: [48][200/782]\tTime  0.055 ( 0.056)\tLoss 8.8808e+00 (7.8991e+00)\tAcc@1  98.44 ( 98.99)\tAcc@5 100.00 (100.00)\n","Epoch: [48][300/782]\tTime  0.060 ( 0.056)\tLoss 3.1416e+00 (7.9171e+00)\tAcc@1 100.00 ( 98.94)\tAcc@5 100.00 ( 99.99)\n","Epoch: [48][400/782]\tTime  0.054 ( 0.056)\tLoss 9.3645e+00 (8.1074e+00)\tAcc@1 100.00 ( 98.90)\tAcc@5 100.00 ( 99.99)\n","Epoch: [48][500/782]\tTime  0.054 ( 0.056)\tLoss 1.0359e+01 (8.2743e+00)\tAcc@1  96.88 ( 98.88)\tAcc@5 100.00 ( 99.99)\n","Epoch: [48][600/782]\tTime  0.060 ( 0.056)\tLoss 4.5236e+00 (8.2246e+00)\tAcc@1 100.00 ( 98.89)\tAcc@5 100.00 ( 99.99)\n","Epoch: [48][700/782]\tTime  0.053 ( 0.056)\tLoss 1.0123e+01 (8.3373e+00)\tAcc@1  98.44 ( 98.86)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 98.852 || Acc@5 99.990\n","==> Test Accuracy:  Acc@1 55.250 || Acc@5 80.770\n","==> 46.29 seconds to train this epoch\n","\n","\n","----- epoch: 49/100, lr: 0.0001 -----\n","Epoch: [49][  0/782]\tTime  0.152 ( 0.152)\tLoss 5.7907e+00 (5.7907e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [49][100/782]\tTime  0.054 ( 0.057)\tLoss 7.9452e+00 (7.7965e+00)\tAcc@1  98.44 ( 99.06)\tAcc@5 100.00 (100.00)\n","Epoch: [49][200/782]\tTime  0.055 ( 0.056)\tLoss 7.2940e+00 (8.0754e+00)\tAcc@1 100.00 ( 98.92)\tAcc@5 100.00 (100.00)\n","Epoch: [49][300/782]\tTime  0.055 ( 0.055)\tLoss 6.0484e+00 (8.1077e+00)\tAcc@1 100.00 ( 98.91)\tAcc@5 100.00 ( 99.98)\n","Epoch: [49][400/782]\tTime  0.053 ( 0.055)\tLoss 7.2260e+00 (8.1499e+00)\tAcc@1 100.00 ( 98.89)\tAcc@5 100.00 ( 99.98)\n","Epoch: [49][500/782]\tTime  0.060 ( 0.055)\tLoss 5.3900e+00 (8.0520e+00)\tAcc@1 100.00 ( 98.91)\tAcc@5 100.00 ( 99.99)\n","Epoch: [49][600/782]\tTime  0.054 ( 0.055)\tLoss 9.8627e+00 (8.0784e+00)\tAcc@1  98.44 ( 98.93)\tAcc@5 100.00 ( 99.99)\n","Epoch: [49][700/782]\tTime  0.053 ( 0.055)\tLoss 4.3380e+00 (8.0084e+00)\tAcc@1 100.00 ( 98.96)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 98.958 || Acc@5 99.992\n","==> Test Accuracy:  Acc@1 55.610 || Acc@5 81.110\n","==> 45.81 seconds to train this epoch\n","\n","\n","----- epoch: 50/100, lr: 0.0001 -----\n","Epoch: [50][  0/782]\tTime  0.147 ( 0.147)\tLoss 1.5661e+00 (1.5661e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [50][100/782]\tTime  0.054 ( 0.057)\tLoss 6.2246e+00 (7.2920e+00)\tAcc@1  98.44 ( 99.21)\tAcc@5 100.00 (100.00)\n","Epoch: [50][200/782]\tTime  0.060 ( 0.056)\tLoss 6.5311e+00 (7.3355e+00)\tAcc@1 100.00 ( 99.15)\tAcc@5 100.00 (100.00)\n","Epoch: [50][300/782]\tTime  0.058 ( 0.056)\tLoss 8.0730e+00 (7.4925e+00)\tAcc@1 100.00 ( 99.07)\tAcc@5 100.00 (100.00)\n","Epoch: [50][400/782]\tTime  0.055 ( 0.056)\tLoss 7.1388e+00 (7.5113e+00)\tAcc@1 100.00 ( 99.07)\tAcc@5 100.00 (100.00)\n","Epoch: [50][500/782]\tTime  0.055 ( 0.056)\tLoss 1.6140e+01 (7.6035e+00)\tAcc@1  96.88 ( 99.05)\tAcc@5 100.00 ( 99.99)\n","Epoch: [50][600/782]\tTime  0.054 ( 0.056)\tLoss 1.2514e+01 (7.6731e+00)\tAcc@1  98.44 ( 99.03)\tAcc@5 100.00 ( 99.99)\n","Epoch: [50][700/782]\tTime  0.055 ( 0.056)\tLoss 4.5748e+00 (7.6808e+00)\tAcc@1 100.00 ( 99.01)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 99.010 || Acc@5 99.994\n","==> Test Accuracy:  Acc@1 55.370 || Acc@5 80.920\n","==> 46.15 seconds to train this epoch\n","\n","\n","----- epoch: 51/100, lr: 0.0001 -----\n","Epoch: [51][  0/782]\tTime  0.150 ( 0.150)\tLoss 4.8251e+00 (4.8251e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [51][100/782]\tTime  0.055 ( 0.057)\tLoss 4.6768e+00 (7.0108e+00)\tAcc@1 100.00 ( 99.24)\tAcc@5 100.00 (100.00)\n","Epoch: [51][200/782]\tTime  0.060 ( 0.056)\tLoss 6.7591e+00 (7.1983e+00)\tAcc@1 100.00 ( 99.23)\tAcc@5 100.00 (100.00)\n","Epoch: [51][300/782]\tTime  0.054 ( 0.056)\tLoss 3.2385e+00 (7.3093e+00)\tAcc@1 100.00 ( 99.10)\tAcc@5 100.00 ( 99.99)\n","Epoch: [51][400/782]\tTime  0.054 ( 0.055)\tLoss 4.8122e+00 (7.2677e+00)\tAcc@1 100.00 ( 99.08)\tAcc@5 100.00 (100.00)\n","Epoch: [51][500/782]\tTime  0.060 ( 0.055)\tLoss 6.3876e+00 (7.2835e+00)\tAcc@1  98.44 ( 99.06)\tAcc@5 100.00 (100.00)\n","Epoch: [51][600/782]\tTime  0.059 ( 0.056)\tLoss 6.1036e+00 (7.4033e+00)\tAcc@1 100.00 ( 99.06)\tAcc@5 100.00 (100.00)\n","Epoch: [51][700/782]\tTime  0.059 ( 0.056)\tLoss 1.1583e+01 (7.4332e+00)\tAcc@1  98.44 ( 99.05)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.984 || Acc@5 99.996\n","==> Test Accuracy:  Acc@1 55.120 || Acc@5 80.630\n","==> 46.19 seconds to train this epoch\n","\n","\n","----- epoch: 52/100, lr: 0.0001 -----\n","Epoch: [52][  0/782]\tTime  0.152 ( 0.152)\tLoss 5.3570e+00 (5.3570e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [52][100/782]\tTime  0.055 ( 0.057)\tLoss 1.1807e+01 (6.7638e+00)\tAcc@1  98.44 ( 99.26)\tAcc@5 100.00 ( 99.98)\n","Epoch: [52][200/782]\tTime  0.060 ( 0.056)\tLoss 1.0037e+01 (7.2409e+00)\tAcc@1  98.44 ( 99.12)\tAcc@5 100.00 ( 99.97)\n","Epoch: [52][300/782]\tTime  0.056 ( 0.056)\tLoss 7.0162e+00 (7.2655e+00)\tAcc@1  98.44 ( 99.10)\tAcc@5 100.00 ( 99.98)\n","Epoch: [52][400/782]\tTime  0.055 ( 0.056)\tLoss 3.8631e+00 (7.2019e+00)\tAcc@1 100.00 ( 99.08)\tAcc@5 100.00 ( 99.98)\n","Epoch: [52][500/782]\tTime  0.055 ( 0.056)\tLoss 4.4039e+00 (7.2026e+00)\tAcc@1 100.00 ( 99.09)\tAcc@5 100.00 ( 99.99)\n","Epoch: [52][600/782]\tTime  0.059 ( 0.056)\tLoss 1.3288e+01 (7.2265e+00)\tAcc@1  93.75 ( 99.07)\tAcc@5 100.00 ( 99.99)\n","Epoch: [52][700/782]\tTime  0.055 ( 0.056)\tLoss 1.2796e+01 (7.2732e+00)\tAcc@1  95.31 ( 99.05)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 99.008 || Acc@5 99.990\n","==> Test Accuracy:  Acc@1 55.220 || Acc@5 80.820\n","==> 46.33 seconds to train this epoch\n","\n","\n","----- epoch: 53/100, lr: 0.0001 -----\n","Epoch: [53][  0/782]\tTime  0.147 ( 0.147)\tLoss 7.2133e+00 (7.2133e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [53][100/782]\tTime  0.055 ( 0.057)\tLoss 9.1096e+00 (6.7016e+00)\tAcc@1  98.44 ( 99.21)\tAcc@5 100.00 (100.00)\n","Epoch: [53][200/782]\tTime  0.054 ( 0.056)\tLoss 1.0002e+01 (7.2983e+00)\tAcc@1  98.44 ( 98.97)\tAcc@5 100.00 (100.00)\n","Epoch: [53][300/782]\tTime  0.055 ( 0.056)\tLoss 6.4450e+00 (7.4387e+00)\tAcc@1  98.44 ( 98.93)\tAcc@5 100.00 ( 99.99)\n","Epoch: [53][400/782]\tTime  0.055 ( 0.056)\tLoss 6.9105e+00 (7.5397e+00)\tAcc@1 100.00 ( 98.90)\tAcc@5 100.00 ( 99.99)\n","Epoch: [53][500/782]\tTime  0.054 ( 0.056)\tLoss 6.7464e+00 (7.4237e+00)\tAcc@1 100.00 ( 98.93)\tAcc@5 100.00 ( 99.99)\n","Epoch: [53][600/782]\tTime  0.055 ( 0.056)\tLoss 5.9726e+00 (7.4309e+00)\tAcc@1  98.44 ( 98.91)\tAcc@5 100.00 ( 99.99)\n","Epoch: [53][700/782]\tTime  0.054 ( 0.056)\tLoss 5.9274e+00 (7.4570e+00)\tAcc@1 100.00 ( 98.94)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.950 || Acc@5 99.994\n","==> Test Accuracy:  Acc@1 55.190 || Acc@5 80.650\n","==> 46.40 seconds to train this epoch\n","\n","\n","----- epoch: 54/100, lr: 0.0001 -----\n","Epoch: [54][  0/782]\tTime  0.161 ( 0.161)\tLoss 7.2575e+00 (7.2575e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [54][100/782]\tTime  0.054 ( 0.057)\tLoss 5.3507e+00 (6.3975e+00)\tAcc@1 100.00 ( 99.23)\tAcc@5 100.00 (100.00)\n","Epoch: [54][200/782]\tTime  0.054 ( 0.056)\tLoss 6.6715e+00 (6.8139e+00)\tAcc@1  98.44 ( 99.11)\tAcc@5 100.00 (100.00)\n","Epoch: [54][300/782]\tTime  0.054 ( 0.056)\tLoss 5.6758e+00 (6.8187e+00)\tAcc@1  98.44 ( 99.14)\tAcc@5 100.00 (100.00)\n","Epoch: [54][400/782]\tTime  0.054 ( 0.056)\tLoss 5.3374e+00 (7.0021e+00)\tAcc@1 100.00 ( 99.05)\tAcc@5 100.00 (100.00)\n","Epoch: [54][500/782]\tTime  0.054 ( 0.056)\tLoss 5.1352e+00 (7.0770e+00)\tAcc@1 100.00 ( 99.04)\tAcc@5 100.00 (100.00)\n","Epoch: [54][600/782]\tTime  0.053 ( 0.056)\tLoss 7.0107e+00 (7.0255e+00)\tAcc@1  98.44 ( 99.08)\tAcc@5 100.00 (100.00)\n","Epoch: [54][700/782]\tTime  0.058 ( 0.056)\tLoss 1.3343e+01 (7.0884e+00)\tAcc@1  95.31 ( 99.06)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.012 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.370 || Acc@5 80.670\n","==> 46.19 seconds to train this epoch\n","\n","\n","----- epoch: 55/100, lr: 0.0001 -----\n","Epoch: [55][  0/782]\tTime  0.146 ( 0.146)\tLoss 6.7363e+00 (6.7363e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [55][100/782]\tTime  0.060 ( 0.057)\tLoss 5.2921e+00 (6.7418e+00)\tAcc@1 100.00 ( 99.26)\tAcc@5 100.00 (100.00)\n","Epoch: [55][200/782]\tTime  0.054 ( 0.056)\tLoss 4.9004e+00 (6.8362e+00)\tAcc@1 100.00 ( 99.18)\tAcc@5 100.00 (100.00)\n","Epoch: [55][300/782]\tTime  0.056 ( 0.056)\tLoss 1.5154e+01 (6.7780e+00)\tAcc@1  98.44 ( 99.14)\tAcc@5 100.00 (100.00)\n","Epoch: [55][400/782]\tTime  0.060 ( 0.056)\tLoss 8.3012e+00 (6.7480e+00)\tAcc@1  98.44 ( 99.17)\tAcc@5 100.00 (100.00)\n","Epoch: [55][500/782]\tTime  0.054 ( 0.056)\tLoss 8.8884e+00 (6.7574e+00)\tAcc@1  98.44 ( 99.16)\tAcc@5 100.00 (100.00)\n","Epoch: [55][600/782]\tTime  0.055 ( 0.056)\tLoss 1.1258e+01 (6.7984e+00)\tAcc@1  95.31 ( 99.15)\tAcc@5 100.00 (100.00)\n","Epoch: [55][700/782]\tTime  0.054 ( 0.056)\tLoss 7.7939e+00 (6.8606e+00)\tAcc@1 100.00 ( 99.12)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.120 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 54.980 || Acc@5 80.780\n","==> 46.20 seconds to train this epoch\n","\n","\n","----- epoch: 56/100, lr: 0.0001 -----\n","Epoch: [56][  0/782]\tTime  0.139 ( 0.139)\tLoss 9.8476e+00 (9.8476e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [56][100/782]\tTime  0.054 ( 0.056)\tLoss 4.0734e+00 (6.5314e+00)\tAcc@1 100.00 ( 99.27)\tAcc@5 100.00 (100.00)\n","Epoch: [56][200/782]\tTime  0.055 ( 0.055)\tLoss 5.6780e+00 (6.2919e+00)\tAcc@1 100.00 ( 99.31)\tAcc@5 100.00 (100.00)\n","Epoch: [56][300/782]\tTime  0.059 ( 0.055)\tLoss 5.5199e+00 (6.5672e+00)\tAcc@1 100.00 ( 99.26)\tAcc@5 100.00 (100.00)\n","Epoch: [56][400/782]\tTime  0.059 ( 0.055)\tLoss 4.8978e+00 (6.6061e+00)\tAcc@1  98.44 ( 99.23)\tAcc@5 100.00 (100.00)\n","Epoch: [56][500/782]\tTime  0.054 ( 0.055)\tLoss 9.2567e+00 (6.6095e+00)\tAcc@1 100.00 ( 99.20)\tAcc@5 100.00 (100.00)\n","Epoch: [56][600/782]\tTime  0.059 ( 0.055)\tLoss 6.5602e+00 (6.5815e+00)\tAcc@1 100.00 ( 99.19)\tAcc@5 100.00 (100.00)\n","Epoch: [56][700/782]\tTime  0.055 ( 0.055)\tLoss 6.3701e+00 (6.6117e+00)\tAcc@1  98.44 ( 99.17)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.174 || Acc@5 99.998\n","==> Test Accuracy:  Acc@1 55.140 || Acc@5 80.850\n","==> 45.87 seconds to train this epoch\n","\n","\n","----- epoch: 57/100, lr: 0.0001 -----\n","Epoch: [57][  0/782]\tTime  0.153 ( 0.153)\tLoss 1.0331e+01 (1.0331e+01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [57][100/782]\tTime  0.060 ( 0.057)\tLoss 8.7474e+00 (6.0909e+00)\tAcc@1  98.44 ( 99.29)\tAcc@5 100.00 (100.00)\n","Epoch: [57][200/782]\tTime  0.056 ( 0.057)\tLoss 2.8930e+00 (6.0150e+00)\tAcc@1 100.00 ( 99.35)\tAcc@5 100.00 ( 99.99)\n","Epoch: [57][300/782]\tTime  0.054 ( 0.056)\tLoss 8.2186e+00 (6.0308e+00)\tAcc@1  98.44 ( 99.39)\tAcc@5 100.00 ( 99.99)\n","Epoch: [57][400/782]\tTime  0.053 ( 0.056)\tLoss 3.4743e+00 (6.2667e+00)\tAcc@1 100.00 ( 99.34)\tAcc@5 100.00 ( 99.99)\n","Epoch: [57][500/782]\tTime  0.055 ( 0.056)\tLoss 4.4001e+00 (6.2802e+00)\tAcc@1 100.00 ( 99.31)\tAcc@5 100.00 ( 99.99)\n","Epoch: [57][600/782]\tTime  0.054 ( 0.056)\tLoss 3.1565e+00 (6.3997e+00)\tAcc@1 100.00 ( 99.27)\tAcc@5 100.00 ( 99.99)\n","Epoch: [57][700/782]\tTime  0.053 ( 0.056)\tLoss 4.1205e+00 (6.4847e+00)\tAcc@1 100.00 ( 99.26)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 99.230 || Acc@5 99.992\n","==> Test Accuracy:  Acc@1 55.220 || Acc@5 80.750\n","==> 46.04 seconds to train this epoch\n","\n","\n","----- epoch: 58/100, lr: 0.0001 -----\n","Epoch: [58][  0/782]\tTime  0.152 ( 0.152)\tLoss 1.0401e+01 (1.0401e+01)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [58][100/782]\tTime  0.060 ( 0.057)\tLoss 8.0126e+00 (6.3707e+00)\tAcc@1  98.44 ( 99.18)\tAcc@5 100.00 (100.00)\n","Epoch: [58][200/782]\tTime  0.058 ( 0.056)\tLoss 5.6733e+00 (6.1209e+00)\tAcc@1 100.00 ( 99.28)\tAcc@5 100.00 (100.00)\n","Epoch: [58][300/782]\tTime  0.055 ( 0.056)\tLoss 3.9604e+00 (6.2300e+00)\tAcc@1 100.00 ( 99.23)\tAcc@5 100.00 (100.00)\n","Epoch: [58][400/782]\tTime  0.055 ( 0.056)\tLoss 6.7238e+00 (6.1653e+00)\tAcc@1 100.00 ( 99.23)\tAcc@5 100.00 (100.00)\n","Epoch: [58][500/782]\tTime  0.054 ( 0.056)\tLoss 5.8573e+00 (6.2212e+00)\tAcc@1 100.00 ( 99.21)\tAcc@5 100.00 (100.00)\n","Epoch: [58][600/782]\tTime  0.054 ( 0.056)\tLoss 7.6406e+00 (6.2627e+00)\tAcc@1 100.00 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [58][700/782]\tTime  0.053 ( 0.056)\tLoss 3.2201e+00 (6.2425e+00)\tAcc@1 100.00 ( 99.24)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.236 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.130 || Acc@5 80.790\n","==> 46.07 seconds to train this epoch\n","\n","\n","----- epoch: 59/100, lr: 0.0001 -----\n","Epoch: [59][  0/782]\tTime  0.153 ( 0.153)\tLoss 7.2653e+00 (7.2653e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [59][100/782]\tTime  0.055 ( 0.056)\tLoss 1.0644e+01 (5.8296e+00)\tAcc@1 100.00 ( 99.38)\tAcc@5 100.00 (100.00)\n","Epoch: [59][200/782]\tTime  0.059 ( 0.055)\tLoss 5.2516e+00 (5.9157e+00)\tAcc@1 100.00 ( 99.40)\tAcc@5 100.00 (100.00)\n","Epoch: [59][300/782]\tTime  0.054 ( 0.056)\tLoss 5.1088e+00 (5.9718e+00)\tAcc@1 100.00 ( 99.31)\tAcc@5 100.00 (100.00)\n","Epoch: [59][400/782]\tTime  0.055 ( 0.055)\tLoss 4.4967e+00 (6.0835e+00)\tAcc@1  98.44 ( 99.27)\tAcc@5 100.00 (100.00)\n","Epoch: [59][500/782]\tTime  0.056 ( 0.055)\tLoss 3.9557e+00 (6.1372e+00)\tAcc@1 100.00 ( 99.25)\tAcc@5 100.00 (100.00)\n","Epoch: [59][600/782]\tTime  0.060 ( 0.055)\tLoss 3.5776e+00 (6.1068e+00)\tAcc@1 100.00 ( 99.26)\tAcc@5 100.00 (100.00)\n","Epoch: [59][700/782]\tTime  0.054 ( 0.055)\tLoss 6.9771e+00 (6.0395e+00)\tAcc@1 100.00 ( 99.29)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.292 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.130 || Acc@5 80.780\n","==> 45.54 seconds to train this epoch\n","\n","\n","----- epoch: 60/100, lr: 1e-05 -----\n","Epoch: [60][  0/782]\tTime  0.159 ( 0.159)\tLoss 5.4755e+00 (5.4755e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [60][100/782]\tTime  0.054 ( 0.057)\tLoss 4.5412e+00 (5.8410e+00)\tAcc@1 100.00 ( 99.47)\tAcc@5 100.00 (100.00)\n","Epoch: [60][200/782]\tTime  0.054 ( 0.056)\tLoss 7.9648e+00 (5.7445e+00)\tAcc@1 100.00 ( 99.46)\tAcc@5 100.00 (100.00)\n","Epoch: [60][300/782]\tTime  0.058 ( 0.056)\tLoss 3.8874e+00 (5.7111e+00)\tAcc@1 100.00 ( 99.43)\tAcc@5 100.00 (100.00)\n","Epoch: [60][400/782]\tTime  0.059 ( 0.056)\tLoss 3.7455e+00 (5.6838e+00)\tAcc@1 100.00 ( 99.42)\tAcc@5 100.00 (100.00)\n","Epoch: [60][500/782]\tTime  0.055 ( 0.055)\tLoss 5.3076e+00 (5.6953e+00)\tAcc@1 100.00 ( 99.41)\tAcc@5 100.00 (100.00)\n","Epoch: [60][600/782]\tTime  0.054 ( 0.055)\tLoss 3.5955e+00 (5.6677e+00)\tAcc@1 100.00 ( 99.40)\tAcc@5 100.00 ( 99.99)\n","Epoch: [60][700/782]\tTime  0.054 ( 0.055)\tLoss 3.7701e+00 (5.6302e+00)\tAcc@1 100.00 ( 99.41)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.418 || Acc@5 99.996\n","==> Test Accuracy:  Acc@1 54.990 || Acc@5 80.990\n","==> 45.57 seconds to train this epoch\n","\n","\n","----- epoch: 61/100, lr: 1e-05 -----\n","Epoch: [61][  0/782]\tTime  0.153 ( 0.153)\tLoss 2.7043e+00 (2.7043e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [61][100/782]\tTime  0.059 ( 0.059)\tLoss 4.5581e+00 (5.1882e+00)\tAcc@1 100.00 ( 99.49)\tAcc@5 100.00 (100.00)\n","Epoch: [61][200/782]\tTime  0.053 ( 0.057)\tLoss 7.1415e+00 (5.2881e+00)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 (100.00)\n","Epoch: [61][300/782]\tTime  0.053 ( 0.057)\tLoss 3.8125e+00 (5.1679e+00)\tAcc@1 100.00 ( 99.60)\tAcc@5 100.00 (100.00)\n","Epoch: [61][400/782]\tTime  0.059 ( 0.056)\tLoss 7.6079e+00 (5.2158e+00)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 (100.00)\n","Epoch: [61][500/782]\tTime  0.055 ( 0.056)\tLoss 5.2194e+00 (5.2041e+00)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 (100.00)\n","Epoch: [61][600/782]\tTime  0.054 ( 0.056)\tLoss 5.3237e+00 (5.1700e+00)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 ( 99.99)\n","Epoch: [61][700/782]\tTime  0.054 ( 0.056)\tLoss 4.5516e+00 (5.1543e+00)\tAcc@1  98.44 ( 99.57)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 99.570 || Acc@5 99.992\n","==> Test Accuracy:  Acc@1 55.300 || Acc@5 80.850\n","==> 45.94 seconds to train this epoch\n","\n","\n","----- epoch: 62/100, lr: 1e-05 -----\n","Epoch: [62][  0/782]\tTime  0.145 ( 0.145)\tLoss 2.3401e+00 (2.3401e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [62][100/782]\tTime  0.059 ( 0.057)\tLoss 5.6913e+00 (4.8243e+00)\tAcc@1 100.00 ( 99.61)\tAcc@5 100.00 (100.00)\n","Epoch: [62][200/782]\tTime  0.054 ( 0.056)\tLoss 4.5107e+00 (5.2374e+00)\tAcc@1 100.00 ( 99.57)\tAcc@5 100.00 (100.00)\n","Epoch: [62][300/782]\tTime  0.055 ( 0.056)\tLoss 6.1555e+00 (5.2870e+00)\tAcc@1 100.00 ( 99.52)\tAcc@5 100.00 (100.00)\n","Epoch: [62][400/782]\tTime  0.054 ( 0.056)\tLoss 4.5332e+00 (5.2691e+00)\tAcc@1  98.44 ( 99.52)\tAcc@5 100.00 (100.00)\n","Epoch: [62][500/782]\tTime  0.054 ( 0.055)\tLoss 1.1655e+01 (5.2658e+00)\tAcc@1  95.31 ( 99.51)\tAcc@5 100.00 (100.00)\n","Epoch: [62][600/782]\tTime  0.058 ( 0.055)\tLoss 5.0802e+00 (5.2698e+00)\tAcc@1 100.00 ( 99.52)\tAcc@5 100.00 (100.00)\n","Epoch: [62][700/782]\tTime  0.054 ( 0.055)\tLoss 3.8847e+00 (5.2115e+00)\tAcc@1 100.00 ( 99.53)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.524 || Acc@5 99.998\n","==> Test Accuracy:  Acc@1 55.380 || Acc@5 81.010\n","==> 45.99 seconds to train this epoch\n","\n","\n","----- epoch: 63/100, lr: 1e-05 -----\n","Epoch: [63][  0/782]\tTime  0.152 ( 0.152)\tLoss 3.4389e+00 (3.4389e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [63][100/782]\tTime  0.053 ( 0.056)\tLoss 5.9538e+00 (4.8780e+00)\tAcc@1  98.44 ( 99.57)\tAcc@5 100.00 (100.00)\n","Epoch: [63][200/782]\tTime  0.055 ( 0.056)\tLoss 6.1951e+00 (5.0178e+00)\tAcc@1  98.44 ( 99.53)\tAcc@5 100.00 (100.00)\n","Epoch: [63][300/782]\tTime  0.059 ( 0.056)\tLoss 4.7263e+00 (4.9667e+00)\tAcc@1 100.00 ( 99.55)\tAcc@5 100.00 (100.00)\n","Epoch: [63][400/782]\tTime  0.054 ( 0.056)\tLoss 3.7451e+00 (4.8613e+00)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 (100.00)\n","Epoch: [63][500/782]\tTime  0.059 ( 0.056)\tLoss 4.2541e+00 (4.9021e+00)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 (100.00)\n","Epoch: [63][600/782]\tTime  0.059 ( 0.056)\tLoss 5.7790e+00 (4.9453e+00)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 (100.00)\n","Epoch: [63][700/782]\tTime  0.055 ( 0.056)\tLoss 3.7382e+00 (4.9579e+00)\tAcc@1 100.00 ( 99.56)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.534 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.610 || Acc@5 80.700\n","==> 46.31 seconds to train this epoch\n","\n","\n","----- epoch: 64/100, lr: 1e-05 -----\n","Epoch: [64][  0/782]\tTime  0.144 ( 0.144)\tLoss 5.0319e+00 (5.0319e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [64][100/782]\tTime  0.061 ( 0.055)\tLoss 3.7207e+00 (4.7781e+00)\tAcc@1 100.00 ( 99.55)\tAcc@5 100.00 (100.00)\n","Epoch: [64][200/782]\tTime  0.054 ( 0.055)\tLoss 6.9273e+00 (4.8639e+00)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 (100.00)\n","Epoch: [64][300/782]\tTime  0.054 ( 0.055)\tLoss 5.5419e+00 (4.8933e+00)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 (100.00)\n","Epoch: [64][400/782]\tTime  0.055 ( 0.055)\tLoss 5.5555e+00 (4.9404e+00)\tAcc@1  98.44 ( 99.56)\tAcc@5 100.00 (100.00)\n","Epoch: [64][500/782]\tTime  0.054 ( 0.055)\tLoss 6.4222e+00 (4.9004e+00)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 (100.00)\n","Epoch: [64][600/782]\tTime  0.054 ( 0.055)\tLoss 7.9884e+00 (4.9504e+00)\tAcc@1  98.44 ( 99.56)\tAcc@5 100.00 (100.00)\n","Epoch: [64][700/782]\tTime  0.057 ( 0.055)\tLoss 8.8095e+00 (4.9282e+00)\tAcc@1  98.44 ( 99.56)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.552 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.540 || Acc@5 80.970\n","==> 45.54 seconds to train this epoch\n","\n","\n","----- epoch: 65/100, lr: 1e-05 -----\n","Epoch: [65][  0/782]\tTime  0.149 ( 0.149)\tLoss 3.2757e+00 (3.2757e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [65][100/782]\tTime  0.055 ( 0.055)\tLoss 1.8304e+00 (4.8684e+00)\tAcc@1 100.00 ( 99.61)\tAcc@5 100.00 (100.00)\n","Epoch: [65][200/782]\tTime  0.053 ( 0.056)\tLoss 4.1255e+00 (4.8022e+00)\tAcc@1 100.00 ( 99.60)\tAcc@5 100.00 (100.00)\n","Epoch: [65][300/782]\tTime  0.054 ( 0.056)\tLoss 4.4896e+00 (4.7333e+00)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 (100.00)\n","Epoch: [65][400/782]\tTime  0.055 ( 0.056)\tLoss 3.5451e+00 (4.6987e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [65][500/782]\tTime  0.055 ( 0.056)\tLoss 6.2697e+00 (4.7011e+00)\tAcc@1  98.44 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [65][600/782]\tTime  0.055 ( 0.055)\tLoss 8.4579e+00 (4.7226e+00)\tAcc@1  98.44 ( 99.63)\tAcc@5 100.00 (100.00)\n","Epoch: [65][700/782]\tTime  0.059 ( 0.056)\tLoss 4.3195e+00 (4.7658e+00)\tAcc@1  98.44 ( 99.63)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.620 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.530 || Acc@5 80.910\n","==> 45.91 seconds to train this epoch\n","\n","\n","----- epoch: 66/100, lr: 1e-05 -----\n","Epoch: [66][  0/782]\tTime  0.142 ( 0.142)\tLoss 8.5125e+00 (8.5125e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [66][100/782]\tTime  0.056 ( 0.055)\tLoss 4.4368e+00 (4.8771e+00)\tAcc@1 100.00 ( 99.54)\tAcc@5 100.00 (100.00)\n","Epoch: [66][200/782]\tTime  0.054 ( 0.055)\tLoss 8.4263e+00 (4.8263e+00)\tAcc@1  98.44 ( 99.49)\tAcc@5 100.00 ( 99.99)\n","Epoch: [66][300/782]\tTime  0.060 ( 0.055)\tLoss 3.1655e+00 (4.8111e+00)\tAcc@1 100.00 ( 99.52)\tAcc@5 100.00 ( 99.99)\n","Epoch: [66][400/782]\tTime  0.054 ( 0.055)\tLoss 6.0891e+00 (4.8337e+00)\tAcc@1 100.00 ( 99.56)\tAcc@5 100.00 (100.00)\n","Epoch: [66][500/782]\tTime  0.054 ( 0.055)\tLoss 4.3825e+00 (4.7854e+00)\tAcc@1 100.00 ( 99.57)\tAcc@5 100.00 (100.00)\n","Epoch: [66][600/782]\tTime  0.053 ( 0.055)\tLoss 2.7278e+00 (4.7836e+00)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 (100.00)\n","Epoch: [66][700/782]\tTime  0.055 ( 0.055)\tLoss 4.6431e+00 (4.7559e+00)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.600 || Acc@5 99.998\n","==> Test Accuracy:  Acc@1 55.550 || Acc@5 80.960\n","==> 45.80 seconds to train this epoch\n","\n","\n","----- epoch: 67/100, lr: 1e-05 -----\n","Epoch: [67][  0/782]\tTime  0.152 ( 0.152)\tLoss 6.1450e+00 (6.1450e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [67][100/782]\tTime  0.053 ( 0.056)\tLoss 4.9386e+00 (4.8754e+00)\tAcc@1 100.00 ( 99.61)\tAcc@5 100.00 (100.00)\n","Epoch: [67][200/782]\tTime  0.055 ( 0.056)\tLoss 3.1713e+00 (4.9911e+00)\tAcc@1 100.00 ( 99.56)\tAcc@5 100.00 (100.00)\n","Epoch: [67][300/782]\tTime  0.055 ( 0.055)\tLoss 4.9065e+00 (4.8711e+00)\tAcc@1 100.00 ( 99.55)\tAcc@5 100.00 (100.00)\n","Epoch: [67][400/782]\tTime  0.054 ( 0.055)\tLoss 5.1884e+00 (4.8898e+00)\tAcc@1 100.00 ( 99.57)\tAcc@5 100.00 (100.00)\n","Epoch: [67][500/782]\tTime  0.054 ( 0.055)\tLoss 2.6847e+00 (4.7927e+00)\tAcc@1 100.00 ( 99.61)\tAcc@5 100.00 (100.00)\n","Epoch: [67][600/782]\tTime  0.055 ( 0.055)\tLoss 4.9905e+00 (4.7033e+00)\tAcc@1 100.00 ( 99.63)\tAcc@5 100.00 (100.00)\n","Epoch: [67][700/782]\tTime  0.055 ( 0.055)\tLoss 4.4296e+00 (4.7215e+00)\tAcc@1  98.44 ( 99.62)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.618 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.570 || Acc@5 81.020\n","==> 45.72 seconds to train this epoch\n","\n","\n","----- epoch: 68/100, lr: 1e-05 -----\n","Epoch: [68][  0/782]\tTime  0.157 ( 0.157)\tLoss 6.1263e+00 (6.1263e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [68][100/782]\tTime  0.054 ( 0.056)\tLoss 2.1875e+00 (4.5503e+00)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n","Epoch: [68][200/782]\tTime  0.054 ( 0.056)\tLoss 5.2497e+00 (4.6778e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [68][300/782]\tTime  0.055 ( 0.056)\tLoss 6.0431e+00 (4.7325e+00)\tAcc@1 100.00 ( 99.62)\tAcc@5 100.00 (100.00)\n","Epoch: [68][400/782]\tTime  0.055 ( 0.056)\tLoss 3.3938e+00 (4.6578e+00)\tAcc@1 100.00 ( 99.61)\tAcc@5 100.00 (100.00)\n","Epoch: [68][500/782]\tTime  0.054 ( 0.055)\tLoss 9.6750e+00 (4.6642e+00)\tAcc@1  98.44 ( 99.62)\tAcc@5 100.00 (100.00)\n","Epoch: [68][600/782]\tTime  0.054 ( 0.055)\tLoss 8.2456e+00 (4.6857e+00)\tAcc@1  95.31 ( 99.60)\tAcc@5 100.00 (100.00)\n","Epoch: [68][700/782]\tTime  0.054 ( 0.055)\tLoss 7.8099e+00 (4.6725e+00)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.572 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.510 || Acc@5 80.930\n","==> 45.70 seconds to train this epoch\n","\n","\n","----- epoch: 69/100, lr: 1e-05 -----\n","Epoch: [69][  0/782]\tTime  0.146 ( 0.146)\tLoss 4.2371e+00 (4.2371e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [69][100/782]\tTime  0.059 ( 0.057)\tLoss 3.8995e+00 (4.5240e+00)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 (100.00)\n","Epoch: [69][200/782]\tTime  0.053 ( 0.057)\tLoss 4.4273e+00 (4.5859e+00)\tAcc@1 100.00 ( 99.62)\tAcc@5 100.00 (100.00)\n","Epoch: [69][300/782]\tTime  0.053 ( 0.056)\tLoss 3.6373e+00 (4.4835e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [69][400/782]\tTime  0.054 ( 0.056)\tLoss 4.3708e+00 (4.4459e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [69][500/782]\tTime  0.054 ( 0.056)\tLoss 4.0427e+00 (4.5128e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [69][600/782]\tTime  0.054 ( 0.055)\tLoss 4.1531e+00 (4.5344e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [69][700/782]\tTime  0.054 ( 0.055)\tLoss 4.2327e+00 (4.5546e+00)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.672 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.750 || Acc@5 80.900\n","==> 45.78 seconds to train this epoch\n","\n","\n","----- epoch: 70/100, lr: 1e-05 -----\n","Epoch: [70][  0/782]\tTime  0.151 ( 0.151)\tLoss 6.1706e+00 (6.1706e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [70][100/782]\tTime  0.057 ( 0.058)\tLoss 5.2440e+00 (4.4269e+00)\tAcc@1 100.00 ( 99.61)\tAcc@5 100.00 (100.00)\n","Epoch: [70][200/782]\tTime  0.055 ( 0.057)\tLoss 5.0099e+00 (4.4218e+00)\tAcc@1  98.44 ( 99.60)\tAcc@5 100.00 (100.00)\n","Epoch: [70][300/782]\tTime  0.054 ( 0.056)\tLoss 5.2159e+00 (4.4712e+00)\tAcc@1 100.00 ( 99.62)\tAcc@5 100.00 (100.00)\n","Epoch: [70][400/782]\tTime  0.059 ( 0.056)\tLoss 3.1389e+00 (4.5323e+00)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 (100.00)\n","Epoch: [70][500/782]\tTime  0.056 ( 0.056)\tLoss 3.7550e+00 (4.5608e+00)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 (100.00)\n","Epoch: [70][600/782]\tTime  0.060 ( 0.056)\tLoss 4.4287e+00 (4.5542e+00)\tAcc@1  98.44 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [70][700/782]\tTime  0.054 ( 0.056)\tLoss 3.5229e+00 (4.5738e+00)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.642 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.450 || Acc@5 81.150\n","==> 46.20 seconds to train this epoch\n","\n","\n","----- epoch: 71/100, lr: 1e-05 -----\n","Epoch: [71][  0/782]\tTime  0.146 ( 0.146)\tLoss 6.9027e+00 (6.9027e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [71][100/782]\tTime  0.059 ( 0.055)\tLoss 6.7264e+00 (4.8207e+00)\tAcc@1  98.44 ( 99.55)\tAcc@5 100.00 (100.00)\n","Epoch: [71][200/782]\tTime  0.054 ( 0.056)\tLoss 6.8764e+00 (4.7854e+00)\tAcc@1 100.00 ( 99.60)\tAcc@5 100.00 (100.00)\n","Epoch: [71][300/782]\tTime  0.053 ( 0.055)\tLoss 3.9357e+00 (4.6465e+00)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n","Epoch: [71][400/782]\tTime  0.054 ( 0.055)\tLoss 4.5474e+00 (4.6489e+00)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n","Epoch: [71][500/782]\tTime  0.054 ( 0.055)\tLoss 5.3801e+00 (4.5605e+00)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n","Epoch: [71][600/782]\tTime  0.057 ( 0.055)\tLoss 2.7095e+00 (4.5081e+00)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n","Epoch: [71][700/782]\tTime  0.054 ( 0.055)\tLoss 2.9954e+00 (4.5220e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.648 || Acc@5 99.996\n","==> Test Accuracy:  Acc@1 55.640 || Acc@5 80.800\n","==> 45.80 seconds to train this epoch\n","\n","\n","----- epoch: 72/100, lr: 1e-05 -----\n","Epoch: [72][  0/782]\tTime  0.160 ( 0.160)\tLoss 3.6901e+00 (3.6901e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [72][100/782]\tTime  0.054 ( 0.058)\tLoss 3.7079e+00 (4.3770e+00)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 (100.00)\n","Epoch: [72][200/782]\tTime  0.054 ( 0.056)\tLoss 1.7429e+00 (4.3398e+00)\tAcc@1 100.00 ( 99.61)\tAcc@5 100.00 (100.00)\n","Epoch: [72][300/782]\tTime  0.054 ( 0.056)\tLoss 9.5934e+00 (4.4275e+00)\tAcc@1  98.44 ( 99.62)\tAcc@5 100.00 (100.00)\n","Epoch: [72][400/782]\tTime  0.054 ( 0.056)\tLoss 7.4122e+00 (4.4974e+00)\tAcc@1  98.44 ( 99.63)\tAcc@5 100.00 (100.00)\n","Epoch: [72][500/782]\tTime  0.055 ( 0.056)\tLoss 6.9963e+00 (4.4976e+00)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 (100.00)\n","Epoch: [72][600/782]\tTime  0.054 ( 0.055)\tLoss 2.0171e+00 (4.5148e+00)\tAcc@1 100.00 ( 99.63)\tAcc@5 100.00 (100.00)\n","Epoch: [72][700/782]\tTime  0.054 ( 0.056)\tLoss 6.3717e+00 (4.5079e+00)\tAcc@1  98.44 ( 99.64)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.650 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.820 || Acc@5 81.080\n","==> 46.02 seconds to train this epoch\n","\n","\n","----- epoch: 73/100, lr: 1e-05 -----\n","Epoch: [73][  0/782]\tTime  0.155 ( 0.155)\tLoss 3.1024e+00 (3.1024e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [73][100/782]\tTime  0.054 ( 0.056)\tLoss 3.6567e+00 (4.7704e+00)\tAcc@1 100.00 ( 99.55)\tAcc@5 100.00 (100.00)\n","Epoch: [73][200/782]\tTime  0.054 ( 0.056)\tLoss 8.9631e+00 (4.9079e+00)\tAcc@1  98.44 ( 99.52)\tAcc@5 100.00 (100.00)\n","Epoch: [73][300/782]\tTime  0.055 ( 0.056)\tLoss 3.6033e+00 (4.7396e+00)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 (100.00)\n","Epoch: [73][400/782]\tTime  0.056 ( 0.055)\tLoss 3.3107e+00 (4.6450e+00)\tAcc@1 100.00 ( 99.62)\tAcc@5 100.00 (100.00)\n","Epoch: [73][500/782]\tTime  0.059 ( 0.055)\tLoss 5.2788e+00 (4.5719e+00)\tAcc@1  98.44 ( 99.63)\tAcc@5 100.00 (100.00)\n","Epoch: [73][600/782]\tTime  0.053 ( 0.056)\tLoss 3.5755e+00 (4.5162e+00)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n","Epoch: [73][700/782]\tTime  0.054 ( 0.056)\tLoss 3.9915e+00 (4.4893e+00)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.662 || Acc@5 99.998\n","==> Test Accuracy:  Acc@1 55.920 || Acc@5 80.780\n","==> 45.97 seconds to train this epoch\n","\n","\n","----- epoch: 74/100, lr: 1e-05 -----\n","Epoch: [74][  0/782]\tTime  0.143 ( 0.143)\tLoss 3.4674e+00 (3.4674e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [74][100/782]\tTime  0.054 ( 0.058)\tLoss 3.8655e+00 (4.6257e+00)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 (100.00)\n","Epoch: [74][200/782]\tTime  0.053 ( 0.056)\tLoss 6.3348e+00 (4.5581e+00)\tAcc@1  98.44 ( 99.61)\tAcc@5 100.00 (100.00)\n","Epoch: [74][300/782]\tTime  0.054 ( 0.056)\tLoss 8.7724e+00 (4.5706e+00)\tAcc@1  98.44 ( 99.64)\tAcc@5 100.00 (100.00)\n","Epoch: [74][400/782]\tTime  0.059 ( 0.056)\tLoss 2.4753e+00 (4.5558e+00)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n","Epoch: [74][500/782]\tTime  0.059 ( 0.056)\tLoss 3.1625e+00 (4.5620e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [74][600/782]\tTime  0.054 ( 0.055)\tLoss 2.7781e+00 (4.6107e+00)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 (100.00)\n","Epoch: [74][700/782]\tTime  0.054 ( 0.055)\tLoss 7.6983e+00 (4.5964e+00)\tAcc@1  98.44 ( 99.65)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.654 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.530 || Acc@5 80.840\n","==> 45.89 seconds to train this epoch\n","\n","\n","----- epoch: 75/100, lr: 1e-05 -----\n","Epoch: [75][  0/782]\tTime  0.155 ( 0.155)\tLoss 5.0141e+00 (5.0141e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [75][100/782]\tTime  0.054 ( 0.056)\tLoss 4.9669e+00 (4.6436e+00)\tAcc@1 100.00 ( 99.52)\tAcc@5 100.00 (100.00)\n","Epoch: [75][200/782]\tTime  0.059 ( 0.057)\tLoss 2.7836e+00 (4.5944e+00)\tAcc@1 100.00 ( 99.57)\tAcc@5 100.00 (100.00)\n","Epoch: [75][300/782]\tTime  0.054 ( 0.056)\tLoss 1.4536e+00 (4.3762e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [75][400/782]\tTime  0.054 ( 0.056)\tLoss 4.0490e+00 (4.4159e+00)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n","Epoch: [75][500/782]\tTime  0.054 ( 0.055)\tLoss 5.2472e+00 (4.4259e+00)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n","Epoch: [75][600/782]\tTime  0.054 ( 0.055)\tLoss 1.0831e+01 (4.4368e+00)\tAcc@1  98.44 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [75][700/782]\tTime  0.054 ( 0.055)\tLoss 4.1192e+00 (4.4191e+00)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.676 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.410 || Acc@5 81.020\n","==> 45.84 seconds to train this epoch\n","\n","\n","----- epoch: 76/100, lr: 1e-05 -----\n","Epoch: [76][  0/782]\tTime  0.158 ( 0.158)\tLoss 5.3880e+00 (5.3880e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [76][100/782]\tTime  0.054 ( 0.057)\tLoss 4.4318e+00 (4.3344e+00)\tAcc@1  98.44 ( 99.63)\tAcc@5 100.00 (100.00)\n","Epoch: [76][200/782]\tTime  0.054 ( 0.056)\tLoss 2.9354e+00 (4.2274e+00)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n","Epoch: [76][300/782]\tTime  0.056 ( 0.056)\tLoss 4.9190e+00 (4.2563e+00)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n","Epoch: [76][400/782]\tTime  0.053 ( 0.056)\tLoss 2.8646e+00 (4.2631e+00)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n","Epoch: [76][500/782]\tTime  0.053 ( 0.056)\tLoss 2.6595e+00 (4.3448e+00)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n","Epoch: [76][600/782]\tTime  0.055 ( 0.056)\tLoss 1.4621e+00 (4.3866e+00)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n","Epoch: [76][700/782]\tTime  0.059 ( 0.056)\tLoss 5.6362e+00 (4.4443e+00)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.646 || Acc@5 99.998\n","==> Test Accuracy:  Acc@1 55.510 || Acc@5 81.090\n","==> 46.03 seconds to train this epoch\n","\n","\n","----- epoch: 77/100, lr: 1e-05 -----\n","Epoch: [77][  0/782]\tTime  0.150 ( 0.150)\tLoss 1.2244e+01 (1.2244e+01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [77][100/782]\tTime  0.054 ( 0.056)\tLoss 3.2879e+00 (4.6706e+00)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n","Epoch: [77][200/782]\tTime  0.053 ( 0.056)\tLoss 2.4884e+00 (4.5682e+00)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n","Epoch: [77][300/782]\tTime  0.056 ( 0.055)\tLoss 4.9630e+00 (4.5411e+00)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n","Epoch: [77][400/782]\tTime  0.053 ( 0.055)\tLoss 4.5634e+00 (4.5083e+00)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n","Epoch: [77][500/782]\tTime  0.054 ( 0.055)\tLoss 8.2942e+00 (4.4080e+00)\tAcc@1  98.44 ( 99.73)\tAcc@5 100.00 (100.00)\n","Epoch: [77][600/782]\tTime  0.054 ( 0.055)\tLoss 4.5289e+00 (4.4290e+00)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n","Epoch: [77][700/782]\tTime  0.059 ( 0.055)\tLoss 1.4379e+00 (4.3935e+00)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.720 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.700 || Acc@5 81.040\n","==> 45.69 seconds to train this epoch\n","\n","\n","----- epoch: 78/100, lr: 1e-05 -----\n","Epoch: [78][  0/782]\tTime  0.172 ( 0.172)\tLoss 3.8375e+00 (3.8375e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [78][100/782]\tTime  0.056 ( 0.056)\tLoss 1.6690e+00 (4.3981e+00)\tAcc@1 100.00 ( 99.47)\tAcc@5 100.00 (100.00)\n","Epoch: [78][200/782]\tTime  0.054 ( 0.055)\tLoss 6.3065e+00 (4.3248e+00)\tAcc@1  98.44 ( 99.56)\tAcc@5 100.00 (100.00)\n","Epoch: [78][300/782]\tTime  0.059 ( 0.055)\tLoss 4.5425e+00 (4.4418e+00)\tAcc@1 100.00 ( 99.57)\tAcc@5 100.00 (100.00)\n","Epoch: [78][400/782]\tTime  0.055 ( 0.055)\tLoss 4.6566e+00 (4.3347e+00)\tAcc@1  98.44 ( 99.64)\tAcc@5 100.00 (100.00)\n","Epoch: [78][500/782]\tTime  0.054 ( 0.055)\tLoss 3.8041e+00 (4.2738e+00)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n","Epoch: [78][600/782]\tTime  0.055 ( 0.055)\tLoss 2.4901e+00 (4.2650e+00)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n","Epoch: [78][700/782]\tTime  0.058 ( 0.055)\tLoss 3.0514e+00 (4.3088e+00)\tAcc@1  98.44 ( 99.67)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.660 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.560 || Acc@5 81.140\n","==> 45.71 seconds to train this epoch\n","\n","\n","----- epoch: 79/100, lr: 1e-05 -----\n","Epoch: [79][  0/782]\tTime  0.151 ( 0.151)\tLoss 5.7103e+00 (5.7103e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [79][100/782]\tTime  0.054 ( 0.056)\tLoss 2.5425e+00 (4.4074e+00)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 (100.00)\n","Epoch: [79][200/782]\tTime  0.053 ( 0.055)\tLoss 3.0491e+00 (4.3586e+00)\tAcc@1 100.00 ( 99.60)\tAcc@5 100.00 (100.00)\n","Epoch: [79][300/782]\tTime  0.054 ( 0.055)\tLoss 5.1899e+00 (4.3388e+00)\tAcc@1  96.88 ( 99.61)\tAcc@5 100.00 ( 99.99)\n","Epoch: [79][400/782]\tTime  0.054 ( 0.055)\tLoss 1.6065e+00 (4.2679e+00)\tAcc@1 100.00 ( 99.63)\tAcc@5 100.00 (100.00)\n","Epoch: [79][500/782]\tTime  0.054 ( 0.055)\tLoss 5.6461e+00 (4.3364e+00)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 (100.00)\n","Epoch: [79][600/782]\tTime  0.054 ( 0.055)\tLoss 3.4494e+00 (4.2856e+00)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n","Epoch: [79][700/782]\tTime  0.055 ( 0.055)\tLoss 3.4930e+00 (4.3054e+00)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.682 || Acc@5 99.998\n","==> Test Accuracy:  Acc@1 55.630 || Acc@5 81.100\n","==> 45.63 seconds to train this epoch\n","\n","\n","----- epoch: 80/100, lr: 1e-05 -----\n","Epoch: [80][  0/782]\tTime  0.146 ( 0.146)\tLoss 6.2758e+00 (6.2758e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [80][100/782]\tTime  0.059 ( 0.056)\tLoss 5.5292e+00 (4.4966e+00)\tAcc@1 100.00 ( 99.55)\tAcc@5 100.00 (100.00)\n","Epoch: [80][200/782]\tTime  0.055 ( 0.056)\tLoss 4.4017e+00 (4.2966e+00)\tAcc@1 100.00 ( 99.61)\tAcc@5 100.00 (100.00)\n","Epoch: [80][300/782]\tTime  0.059 ( 0.056)\tLoss 2.5450e+00 (4.3037e+00)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 (100.00)\n","Epoch: [80][400/782]\tTime  0.054 ( 0.056)\tLoss 7.0062e+00 (4.3256e+00)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n","Epoch: [80][500/782]\tTime  0.054 ( 0.056)\tLoss 6.2634e+00 (4.3213e+00)\tAcc@1  98.44 ( 99.68)\tAcc@5 100.00 (100.00)\n","Epoch: [80][600/782]\tTime  0.054 ( 0.056)\tLoss 2.0782e+00 (4.3332e+00)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n","Epoch: [80][700/782]\tTime  0.054 ( 0.056)\tLoss 6.5264e+00 (4.3474e+00)\tAcc@1  98.44 ( 99.67)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.672 || Acc@5 99.998\n","==> Test Accuracy:  Acc@1 55.660 || Acc@5 81.270\n","==> 45.92 seconds to train this epoch\n","\n","\n","----- epoch: 81/100, lr: 1e-05 -----\n","Epoch: [81][  0/782]\tTime  0.150 ( 0.150)\tLoss 1.0528e+01 (1.0528e+01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n","Epoch: [81][100/782]\tTime  0.054 ( 0.055)\tLoss 3.4708e+00 (4.5318e+00)\tAcc@1 100.00 ( 99.57)\tAcc@5 100.00 (100.00)\n","Epoch: [81][200/782]\tTime  0.060 ( 0.055)\tLoss 4.9774e+00 (4.3871e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [81][300/782]\tTime  0.055 ( 0.055)\tLoss 4.2965e+00 (4.3369e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [81][400/782]\tTime  0.054 ( 0.055)\tLoss 4.7754e+00 (4.3136e+00)\tAcc@1  98.44 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [81][500/782]\tTime  0.054 ( 0.055)\tLoss 5.3842e+00 (4.2905e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [81][600/782]\tTime  0.059 ( 0.055)\tLoss 3.9694e+00 (4.3022e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [81][700/782]\tTime  0.055 ( 0.055)\tLoss 4.4789e+00 (4.2845e+00)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.674 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.470 || Acc@5 80.870\n","==> 45.37 seconds to train this epoch\n","\n","\n","----- epoch: 82/100, lr: 1e-05 -----\n","Epoch: [82][  0/782]\tTime  0.159 ( 0.159)\tLoss 3.1310e+00 (3.1310e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [82][100/782]\tTime  0.054 ( 0.055)\tLoss 2.3252e+00 (4.3838e+00)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 ( 99.98)\n","Epoch: [82][200/782]\tTime  0.053 ( 0.055)\tLoss 2.1264e+00 (4.3057e+00)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 ( 99.99)\n","Epoch: [82][300/782]\tTime  0.054 ( 0.055)\tLoss 3.0537e+00 (4.3436e+00)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 ( 99.99)\n","Epoch: [82][400/782]\tTime  0.055 ( 0.055)\tLoss 5.1543e+00 (4.3148e+00)\tAcc@1  98.44 ( 99.69)\tAcc@5 100.00 (100.00)\n","Epoch: [82][500/782]\tTime  0.054 ( 0.055)\tLoss 1.8571e+00 (4.2905e+00)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n","Epoch: [82][600/782]\tTime  0.053 ( 0.055)\tLoss 2.6901e+00 (4.2716e+00)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n","Epoch: [82][700/782]\tTime  0.059 ( 0.055)\tLoss 3.0695e+00 (4.2682e+00)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.698 || Acc@5 99.998\n","==> Test Accuracy:  Acc@1 55.680 || Acc@5 80.910\n","==> 45.63 seconds to train this epoch\n","\n","\n","----- epoch: 83/100, lr: 1e-05 -----\n","Epoch: [83][  0/782]\tTime  0.142 ( 0.142)\tLoss 2.7896e+00 (2.7896e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [83][100/782]\tTime  0.054 ( 0.057)\tLoss 3.3229e+00 (3.9255e+00)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n","Epoch: [83][200/782]\tTime  0.054 ( 0.056)\tLoss 3.8918e+00 (4.0123e+00)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n","Epoch: [83][300/782]\tTime  0.059 ( 0.056)\tLoss 5.0381e+00 (4.0319e+00)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n","Epoch: [83][400/782]\tTime  0.056 ( 0.055)\tLoss 4.4233e+00 (4.1002e+00)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n","Epoch: [83][500/782]\tTime  0.054 ( 0.055)\tLoss 4.7609e+00 (4.0900e+00)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n","Epoch: [83][600/782]\tTime  0.054 ( 0.055)\tLoss 6.3287e+00 (4.0605e+00)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n","Epoch: [83][700/782]\tTime  0.055 ( 0.055)\tLoss 4.3850e+00 (4.0393e+00)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.708 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.460 || Acc@5 80.940\n","==> 45.72 seconds to train this epoch\n","\n","\n","----- epoch: 84/100, lr: 1e-05 -----\n","Epoch: [84][  0/782]\tTime  0.149 ( 0.149)\tLoss 3.7696e+00 (3.7696e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [84][100/782]\tTime  0.055 ( 0.056)\tLoss 2.5219e+00 (4.2225e+00)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 (100.00)\n","Epoch: [84][200/782]\tTime  0.056 ( 0.055)\tLoss 2.5739e+00 (4.2711e+00)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n","Epoch: [84][300/782]\tTime  0.060 ( 0.055)\tLoss 4.6661e+00 (4.3222e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [84][400/782]\tTime  0.054 ( 0.055)\tLoss 3.3436e+00 (4.2598e+00)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n","Epoch: [84][500/782]\tTime  0.053 ( 0.055)\tLoss 1.0186e+01 (4.2495e+00)\tAcc@1  98.44 ( 99.69)\tAcc@5 100.00 (100.00)\n","Epoch: [84][600/782]\tTime  0.054 ( 0.055)\tLoss 3.5054e+00 (4.2281e+00)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n","Epoch: [84][700/782]\tTime  0.056 ( 0.055)\tLoss 2.5336e+00 (4.2282e+00)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.688 || Acc@5 99.998\n","==> Test Accuracy:  Acc@1 55.670 || Acc@5 80.650\n","==> 45.80 seconds to train this epoch\n","\n","\n","----- epoch: 85/100, lr: 1e-05 -----\n","Epoch: [85][  0/782]\tTime  0.151 ( 0.151)\tLoss 4.7257e+00 (4.7257e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [85][100/782]\tTime  0.053 ( 0.056)\tLoss 3.6515e+00 (3.9271e+00)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n","Epoch: [85][200/782]\tTime  0.059 ( 0.055)\tLoss 3.0053e+00 (4.0488e+00)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n","Epoch: [85][300/782]\tTime  0.054 ( 0.056)\tLoss 3.5856e+00 (4.1097e+00)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n","Epoch: [85][400/782]\tTime  0.054 ( 0.055)\tLoss 4.4427e+00 (4.1152e+00)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n","Epoch: [85][500/782]\tTime  0.053 ( 0.055)\tLoss 2.2324e+00 (4.1211e+00)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n","Epoch: [85][600/782]\tTime  0.059 ( 0.055)\tLoss 1.7066e+00 (4.1473e+00)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n","Epoch: [85][700/782]\tTime  0.053 ( 0.055)\tLoss 4.6469e+00 (4.1992e+00)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.722 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.750 || Acc@5 80.800\n","==> 45.65 seconds to train this epoch\n","\n","\n","----- epoch: 86/100, lr: 1e-05 -----\n","Epoch: [86][  0/782]\tTime  0.150 ( 0.150)\tLoss 3.6750e+00 (3.6750e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [86][100/782]\tTime  0.054 ( 0.056)\tLoss 4.6610e+00 (4.0102e+00)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n","Epoch: [86][200/782]\tTime  0.054 ( 0.055)\tLoss 3.0065e+00 (4.2140e+00)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n","Epoch: [86][300/782]\tTime  0.054 ( 0.055)\tLoss 4.0715e+00 (4.0920e+00)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n","Epoch: [86][400/782]\tTime  0.056 ( 0.055)\tLoss 3.8842e+00 (4.1012e+00)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n","Epoch: [86][500/782]\tTime  0.055 ( 0.055)\tLoss 1.0085e+00 (4.0726e+00)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n","Epoch: [86][600/782]\tTime  0.054 ( 0.055)\tLoss 5.9760e+00 (4.0989e+00)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n","Epoch: [86][700/782]\tTime  0.058 ( 0.055)\tLoss 3.3292e+00 (4.1280e+00)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.738 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.430 || Acc@5 80.820\n","==> 45.24 seconds to train this epoch\n","\n","\n","----- epoch: 87/100, lr: 1e-05 -----\n","Epoch: [87][  0/782]\tTime  0.146 ( 0.146)\tLoss 6.2770e+00 (6.2770e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [87][100/782]\tTime  0.057 ( 0.055)\tLoss 1.2414e+00 (4.1190e+00)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n","Epoch: [87][200/782]\tTime  0.055 ( 0.056)\tLoss 3.5915e+00 (3.9513e+00)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n","Epoch: [87][300/782]\tTime  0.058 ( 0.056)\tLoss 5.4281e+00 (4.0093e+00)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n","Epoch: [87][400/782]\tTime  0.055 ( 0.055)\tLoss 5.3334e+00 (3.9787e+00)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n","Epoch: [87][500/782]\tTime  0.054 ( 0.055)\tLoss 2.5646e+00 (4.0129e+00)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n","Epoch: [87][600/782]\tTime  0.054 ( 0.055)\tLoss 1.3123e+01 (4.0044e+00)\tAcc@1  95.31 ( 99.76)\tAcc@5 100.00 (100.00)\n","Epoch: [87][700/782]\tTime  0.055 ( 0.055)\tLoss 3.7247e+00 (4.0551e+00)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.708 || Acc@5 99.998\n","==> Test Accuracy:  Acc@1 55.490 || Acc@5 80.640\n","==> 45.76 seconds to train this epoch\n","\n","\n","----- epoch: 88/100, lr: 1e-05 -----\n","Epoch: [88][  0/782]\tTime  0.150 ( 0.150)\tLoss 1.0251e+01 (1.0251e+01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [88][100/782]\tTime  0.054 ( 0.056)\tLoss 5.9476e+00 (4.3652e+00)\tAcc@1 100.00 ( 99.63)\tAcc@5 100.00 (100.00)\n","Epoch: [88][200/782]\tTime  0.054 ( 0.055)\tLoss 3.3392e+00 (4.1587e+00)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n","Epoch: [88][300/782]\tTime  0.054 ( 0.055)\tLoss 2.5778e+00 (4.2428e+00)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n","Epoch: [88][400/782]\tTime  0.054 ( 0.055)\tLoss 6.2970e+00 (4.1675e+00)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n","Epoch: [88][500/782]\tTime  0.055 ( 0.055)\tLoss 9.7422e-01 (4.1440e+00)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n","Epoch: [88][600/782]\tTime  0.054 ( 0.055)\tLoss 5.1136e+00 (4.1558e+00)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n","Epoch: [88][700/782]\tTime  0.054 ( 0.055)\tLoss 3.1148e+00 (4.1492e+00)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.700 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.530 || Acc@5 80.970\n","==> 45.65 seconds to train this epoch\n","\n","\n","----- epoch: 89/100, lr: 1e-05 -----\n","Epoch: [89][  0/782]\tTime  0.164 ( 0.164)\tLoss 3.9831e+00 (3.9831e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [89][100/782]\tTime  0.053 ( 0.057)\tLoss 2.8998e+00 (4.0620e+00)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n","Epoch: [89][200/782]\tTime  0.054 ( 0.056)\tLoss 6.7689e+00 (4.0729e+00)\tAcc@1  96.88 ( 99.72)\tAcc@5 100.00 (100.00)\n","Epoch: [89][300/782]\tTime  0.054 ( 0.055)\tLoss 2.3956e+00 (4.1414e+00)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n","Epoch: [89][400/782]\tTime  0.054 ( 0.055)\tLoss 2.9676e+00 (4.0562e+00)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n","Epoch: [89][500/782]\tTime  0.054 ( 0.055)\tLoss 2.2477e+00 (4.0598e+00)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n","Epoch: [89][600/782]\tTime  0.053 ( 0.055)\tLoss 1.2645e+00 (4.0417e+00)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n","Epoch: [89][700/782]\tTime  0.053 ( 0.055)\tLoss 3.8739e+00 (4.0708e+00)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.722 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.490 || Acc@5 80.860\n","==> 45.64 seconds to train this epoch\n","\n","\n","----- epoch: 90/100, lr: 1.0000000000000002e-06 -----\n","Epoch: [90][  0/782]\tTime  0.149 ( 0.149)\tLoss 5.5103e+00 (5.5103e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [90][100/782]\tTime  0.054 ( 0.056)\tLoss 4.8036e+00 (3.8890e+00)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n","Epoch: [90][200/782]\tTime  0.054 ( 0.056)\tLoss 3.9209e+00 (3.9806e+00)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n","Epoch: [90][300/782]\tTime  0.053 ( 0.055)\tLoss 2.7448e+00 (4.0958e+00)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 ( 99.99)\n","Epoch: [90][400/782]\tTime  0.055 ( 0.055)\tLoss 8.8364e+00 (4.0364e+00)\tAcc@1  96.88 ( 99.73)\tAcc@5 100.00 (100.00)\n","Epoch: [90][500/782]\tTime  0.059 ( 0.055)\tLoss 2.6468e+00 (4.0182e+00)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n","Epoch: [90][600/782]\tTime  0.061 ( 0.055)\tLoss 3.2779e+00 (4.0743e+00)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 ( 99.99)\n","Epoch: [90][700/782]\tTime  0.054 ( 0.055)\tLoss 3.8714e+00 (4.0917e+00)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.706 || Acc@5 99.994\n","==> Test Accuracy:  Acc@1 55.480 || Acc@5 80.900\n","==> 45.65 seconds to train this epoch\n","\n","\n","----- epoch: 91/100, lr: 1.0000000000000002e-06 -----\n","Epoch: [91][  0/782]\tTime  0.159 ( 0.159)\tLoss 2.8708e+00 (2.8708e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [91][100/782]\tTime  0.054 ( 0.056)\tLoss 3.1540e+00 (4.5727e+00)\tAcc@1  98.44 ( 99.49)\tAcc@5 100.00 (100.00)\n","Epoch: [91][200/782]\tTime  0.059 ( 0.056)\tLoss 1.4939e+00 (4.3693e+00)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 (100.00)\n","Epoch: [91][300/782]\tTime  0.054 ( 0.056)\tLoss 3.5405e+00 (4.2799e+00)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [91][400/782]\tTime  0.057 ( 0.055)\tLoss 2.3716e+00 (4.2147e+00)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n","Epoch: [91][500/782]\tTime  0.057 ( 0.056)\tLoss 7.6847e+00 (4.1579e+00)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n","Epoch: [91][600/782]\tTime  0.059 ( 0.056)\tLoss 3.2591e+00 (4.1070e+00)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n","Epoch: [91][700/782]\tTime  0.053 ( 0.056)\tLoss 5.8895e+00 (4.1032e+00)\tAcc@1  98.44 ( 99.69)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.694 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.520 || Acc@5 80.890\n","==> 45.78 seconds to train this epoch\n","\n","\n","----- epoch: 92/100, lr: 1.0000000000000002e-06 -----\n","Epoch: [92][  0/782]\tTime  0.140 ( 0.140)\tLoss 4.2648e+00 (4.2648e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [92][100/782]\tTime  0.053 ( 0.057)\tLoss 8.3017e+00 (4.1081e+00)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n","Epoch: [92][200/782]\tTime  0.055 ( 0.056)\tLoss 3.6384e+00 (3.9521e+00)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n","Epoch: [92][300/782]\tTime  0.054 ( 0.055)\tLoss 4.4440e+00 (4.0201e+00)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n","Epoch: [92][400/782]\tTime  0.054 ( 0.055)\tLoss 3.5391e+00 (4.0394e+00)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n","Epoch: [92][500/782]\tTime  0.059 ( 0.055)\tLoss 2.8449e+00 (4.0078e+00)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n","Epoch: [92][600/782]\tTime  0.054 ( 0.055)\tLoss 2.1872e+00 (3.9771e+00)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n","Epoch: [92][700/782]\tTime  0.053 ( 0.055)\tLoss 3.0656e+00 (3.9679e+00)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.738 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.390 || Acc@5 80.760\n","==> 45.63 seconds to train this epoch\n","\n","\n","----- epoch: 93/100, lr: 1.0000000000000002e-06 -----\n","Epoch: [93][  0/782]\tTime  0.155 ( 0.155)\tLoss 5.5549e+00 (5.5549e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [93][100/782]\tTime  0.054 ( 0.056)\tLoss 4.1960e+00 (3.7768e+00)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n","Epoch: [93][200/782]\tTime  0.059 ( 0.055)\tLoss 1.9715e+00 (3.8829e+00)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n","Epoch: [93][300/782]\tTime  0.059 ( 0.055)\tLoss 2.7891e+00 (3.9378e+00)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n","Epoch: [93][400/782]\tTime  0.060 ( 0.055)\tLoss 2.0330e+00 (3.9970e+00)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n","Epoch: [93][500/782]\tTime  0.060 ( 0.055)\tLoss 2.5437e+00 (3.9921e+00)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n","Epoch: [93][600/782]\tTime  0.060 ( 0.055)\tLoss 8.1090e+00 (3.9810e+00)\tAcc@1  98.44 ( 99.72)\tAcc@5 100.00 (100.00)\n","Epoch: [93][700/782]\tTime  0.055 ( 0.055)\tLoss 3.0080e+00 (3.9647e+00)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.736 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.250 || Acc@5 80.880\n","==> 45.58 seconds to train this epoch\n","\n","\n","----- epoch: 94/100, lr: 1.0000000000000002e-06 -----\n","Epoch: [94][  0/782]\tTime  0.158 ( 0.158)\tLoss 2.7666e+00 (2.7666e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [94][100/782]\tTime  0.053 ( 0.056)\tLoss 3.2324e+00 (3.9617e+00)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n","Epoch: [94][200/782]\tTime  0.054 ( 0.056)\tLoss 2.4119e+00 (3.8297e+00)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n","Epoch: [94][300/782]\tTime  0.054 ( 0.056)\tLoss 1.9060e+00 (3.9427e+00)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n","Epoch: [94][400/782]\tTime  0.053 ( 0.055)\tLoss 5.4837e+00 (3.8971e+00)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n","Epoch: [94][500/782]\tTime  0.053 ( 0.055)\tLoss 3.9916e+00 (3.9074e+00)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n","Epoch: [94][600/782]\tTime  0.054 ( 0.055)\tLoss 2.2461e+00 (3.9215e+00)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n","Epoch: [94][700/782]\tTime  0.055 ( 0.055)\tLoss 2.6943e+00 (3.9168e+00)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.762 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.310 || Acc@5 80.860\n","==> 45.71 seconds to train this epoch\n","\n","\n","----- epoch: 95/100, lr: 1.0000000000000002e-06 -----\n","Epoch: [95][  0/782]\tTime  0.155 ( 0.155)\tLoss 3.6919e+00 (3.6919e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [95][100/782]\tTime  0.056 ( 0.057)\tLoss 3.2725e+00 (3.8974e+00)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n","Epoch: [95][200/782]\tTime  0.054 ( 0.056)\tLoss 3.0117e+00 (3.8764e+00)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n","Epoch: [95][300/782]\tTime  0.059 ( 0.056)\tLoss 4.7114e+00 (3.9431e+00)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n","Epoch: [95][400/782]\tTime  0.055 ( 0.056)\tLoss 2.2372e+00 (4.0282e+00)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n","Epoch: [95][500/782]\tTime  0.054 ( 0.055)\tLoss 1.8003e+00 (4.0032e+00)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n","Epoch: [95][600/782]\tTime  0.054 ( 0.055)\tLoss 4.9261e+00 (3.9768e+00)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n","Epoch: [95][700/782]\tTime  0.054 ( 0.055)\tLoss 3.5335e+00 (3.9299e+00)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.760 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.640 || Acc@5 80.950\n","==> 45.79 seconds to train this epoch\n","\n","\n","----- epoch: 96/100, lr: 1.0000000000000002e-06 -----\n","Epoch: [96][  0/782]\tTime  0.153 ( 0.153)\tLoss 3.5851e+00 (3.5851e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [96][100/782]\tTime  0.055 ( 0.056)\tLoss 3.1449e+00 (3.7788e+00)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 (100.00)\n","Epoch: [96][200/782]\tTime  0.054 ( 0.055)\tLoss 1.9210e+00 (3.7495e+00)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n","Epoch: [96][300/782]\tTime  0.057 ( 0.055)\tLoss 2.7862e+00 (3.8321e+00)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n","Epoch: [96][400/782]\tTime  0.055 ( 0.055)\tLoss 1.7220e+00 (3.8596e+00)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n","Epoch: [96][500/782]\tTime  0.054 ( 0.055)\tLoss 3.9235e+00 (3.9055e+00)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n","Epoch: [96][600/782]\tTime  0.053 ( 0.055)\tLoss 3.5083e+00 (3.9450e+00)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n","Epoch: [96][700/782]\tTime  0.054 ( 0.055)\tLoss 3.5251e+00 (3.9496e+00)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.728 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.290 || Acc@5 81.030\n","==> 45.63 seconds to train this epoch\n","\n","\n","----- epoch: 97/100, lr: 1.0000000000000002e-06 -----\n","Epoch: [97][  0/782]\tTime  0.140 ( 0.140)\tLoss 4.7288e+00 (4.7288e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [97][100/782]\tTime  0.055 ( 0.057)\tLoss 2.3225e+00 (3.7807e+00)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n","Epoch: [97][200/782]\tTime  0.054 ( 0.055)\tLoss 2.5420e+00 (3.7400e+00)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n","Epoch: [97][300/782]\tTime  0.054 ( 0.055)\tLoss 3.2563e+00 (3.8419e+00)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n","Epoch: [97][400/782]\tTime  0.058 ( 0.055)\tLoss 3.0118e+00 (3.9299e+00)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n","Epoch: [97][500/782]\tTime  0.059 ( 0.055)\tLoss 2.7891e+00 (3.9452e+00)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n","Epoch: [97][600/782]\tTime  0.054 ( 0.055)\tLoss 4.3062e+00 (3.9485e+00)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n","Epoch: [97][700/782]\tTime  0.053 ( 0.055)\tLoss 8.1612e+00 (3.9314e+00)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.784 || Acc@5 99.998\n","==> Test Accuracy:  Acc@1 55.440 || Acc@5 81.160\n","==> 45.49 seconds to train this epoch\n","\n","\n","----- epoch: 98/100, lr: 1.0000000000000002e-06 -----\n","Epoch: [98][  0/782]\tTime  0.155 ( 0.155)\tLoss 2.9275e+00 (2.9275e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [98][100/782]\tTime  0.054 ( 0.056)\tLoss 3.2045e+00 (3.8816e+00)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n","Epoch: [98][200/782]\tTime  0.059 ( 0.055)\tLoss 3.4527e+00 (3.8932e+00)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n","Epoch: [98][300/782]\tTime  0.055 ( 0.056)\tLoss 2.4700e+00 (3.8898e+00)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n","Epoch: [98][400/782]\tTime  0.054 ( 0.056)\tLoss 2.4786e+00 (3.9070e+00)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n","Epoch: [98][500/782]\tTime  0.059 ( 0.055)\tLoss 4.1082e+00 (3.9141e+00)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n","Epoch: [98][600/782]\tTime  0.059 ( 0.055)\tLoss 5.6754e+00 (3.9688e+00)\tAcc@1  98.44 ( 99.75)\tAcc@5 100.00 (100.00)\n","Epoch: [98][700/782]\tTime  0.054 ( 0.055)\tLoss 4.4736e+00 (3.9585e+00)\tAcc@1  98.44 ( 99.75)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.746 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.460 || Acc@5 80.800\n","==> 45.66 seconds to train this epoch\n","\n","\n","----- epoch: 99/100, lr: 1.0000000000000002e-06 -----\n","Epoch: [99][  0/782]\tTime  0.159 ( 0.159)\tLoss 5.8609e+00 (5.8609e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [99][100/782]\tTime  0.054 ( 0.056)\tLoss 3.5830e+00 (4.0756e+00)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n","Epoch: [99][200/782]\tTime  0.053 ( 0.055)\tLoss 4.1205e+00 (4.0386e+00)\tAcc@1  98.44 ( 99.69)\tAcc@5 100.00 (100.00)\n","Epoch: [99][300/782]\tTime  0.056 ( 0.055)\tLoss 4.8864e+00 (3.9216e+00)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n","Epoch: [99][400/782]\tTime  0.053 ( 0.055)\tLoss 5.3117e+00 (3.9129e+00)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n","Epoch: [99][500/782]\tTime  0.059 ( 0.055)\tLoss 4.1520e+00 (3.9379e+00)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n","Epoch: [99][600/782]\tTime  0.059 ( 0.055)\tLoss 1.0432e+01 (3.9590e+00)\tAcc@1  98.44 ( 99.72)\tAcc@5 100.00 (100.00)\n","Epoch: [99][700/782]\tTime  0.054 ( 0.055)\tLoss 3.1816e+00 (3.9477e+00)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.730 || Acc@5 100.000\n","==> Test Accuracy:  Acc@1 55.420 || Acc@5 80.900\n","==> 45.78 seconds to train this epoch\n","\n","Best Top-1 Accuracy: 56.31\n"]}]}]}