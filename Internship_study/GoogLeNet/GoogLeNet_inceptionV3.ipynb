{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GoogLeNet_inceptionV3.ipynb","provenance":[{"file_id":"1k1AvOzCJO3qtDvlMGN_N7jHonTEA_KFQ","timestamp":1631627421244}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPJgG0Mt8/TJ+6Ug+NXwdXE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0f42f1ff2e4e4e2c8a9a3c0203da5459":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_282f7a6444af449ea49ff6419da9b1da","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_85ce7305176b418eb768b7de2137bb44","IPY_MODEL_049df0b173a84cf796c6356d8b0946e3","IPY_MODEL_56b0fe0f24424d989149f223ab35e0ba"]}},"282f7a6444af449ea49ff6419da9b1da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"85ce7305176b418eb768b7de2137bb44":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_39273c848d3844818562553bd5878f94","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_83af46fe381f45e4ab4e3b75111fc3ac"}},"049df0b173a84cf796c6356d8b0946e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d010701e11d94acb8146bafefe78580a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":169001437,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":169001437,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0590e0aa8de5409590435fe897983f20"}},"56b0fe0f24424d989149f223ab35e0ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c2f73b840f824b7e940083a267bb272f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 169001984/? [00:03&lt;00:00, 48101606.02it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8746744c74ca44a18aeec108a857712b"}},"39273c848d3844818562553bd5878f94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"83af46fe381f45e4ab4e3b75111fc3ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d010701e11d94acb8146bafefe78580a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0590e0aa8de5409590435fe897983f20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c2f73b840f824b7e940083a267bb272f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8746744c74ca44a18aeec108a857712b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"mbcuodGG1Rgg"},"source":["##**Import all neceassary packages**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XB-tD0SQ2qJr","executionInfo":{"status":"ok","timestamp":1631613289839,"user_tz":-540,"elapsed":19148,"user":{"displayName":"ᄋᄋᄌ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07872107978641370856"}},"outputId":"038455a9-e38b-4deb-b496-2ac629cc8bfe"},"source":["import numpy as np\n","import time\n","import copy\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torch.backends.cudnn as cudnn\n","from torch.optim.lr_scheduler import MultiStepLR, StepLR\n","\n","from torchvision import datasets, transforms\n","\n","from tqdm.notebook import tqdm as tqdm\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"t7dn0AtK1Wi1"},"source":["##**Model - Define GoogLeNet Model**"]},{"cell_type":"markdown","metadata":{"id":"5IKXNtXt1sBT"},"source":["### conv_block, gridReduction, Inception x3, x5, x2, auxiliary classifier"]},{"cell_type":"code","metadata":{"id":"3iEU5aYI1qxK"},"source":["class conv_block(nn.Module):\n","    def __init__(self, in_channels, out_channels, **kwargs):\n","        super(conv_block, self).__init__()\n","\n","        self.conv_layer = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, **kwargs),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","        )\n","    \n","    def forward(self, x):\n","        return self.conv_layer(x)\n","\n","class GridReduction(nn.Module):\n","    def __init__(self, in_fts, out_fts):\n","        super(GridReduction, self).__init__()\n","        self.branch1 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts, kernel_size=(3, 3), stride=(2, 2))\n","        )\n","\n","        self.branch2 = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2))\n","        )\n","\n","    def forward(self, input_img):\n","        o1 = self.branch1(input_img)\n","        o2 = self.branch2(input_img)\n","        x = torch.cat([o1, o2], dim=1)\n","        return x\n","\n","class Inceptionx3(nn.Module):\n","    def __init__(self, in_fts, out_fts):\n","        super(Inceptionx3, self).__init__()\n","        self.branch1 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[0], kernel_size=(1, 1), stride=(1, 1)),\n","            nn.Conv2d(in_channels=out_fts[0], out_channels=out_fts[0], kernel_size=(3, 3), stride=(1, 1), padding=1),\n","            nn.Conv2d(in_channels=out_fts[0], out_channels=out_fts[0], kernel_size=(3, 3), stride=(1, 1), padding=1)\n","        )\n","        self.branch2 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[1], kernel_size=(1, 1), stride=(1, 1)),\n","            nn.Conv2d(in_channels=out_fts[1], out_channels=out_fts[1], kernel_size=(3, 3), stride=(1, 1), padding=1),\n","        )\n","        self.branch3 = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=(3, 3), stride=(1, 1), padding=1),\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[2], kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        self.branch4 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[3], kernel_size=(1, 1), stride=(1, 1))\n","        )\n","\n","    def forward(self, input_img):\n","        o1 = self.branch1(input_img)\n","        o2 = self.branch2(input_img)\n","        o3 = self.branch3(input_img)\n","        o4 = self.branch4(input_img)\n","        x = torch.cat([o1, o2, o3, o4], dim=1)\n","        return x\n","\n","class Inceptionx5(nn.Module):\n","    def __init__(self, in_fts, out_fts, n=7):\n","        super(Inceptionx5, self).__init__()\n","        self.branch1 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[0], kernel_size=(1, 1), stride=(1, 1)),\n","            nn.Conv2d(in_channels=out_fts[0], out_channels=out_fts[0], kernel_size=(1, n), stride=(1, 1),\n","                      padding=(0, n // 2)),\n","            nn.Conv2d(in_channels=out_fts[0], out_channels=out_fts[0], kernel_size=(n, 1), stride=(1, 1),\n","                      padding=(n // 2, 0)),\n","            nn.Conv2d(in_channels=out_fts[0], out_channels=out_fts[0], kernel_size=(1, n), stride=(1, 1),\n","                      padding=(0, n // 2)),\n","            nn.Conv2d(in_channels=out_fts[0], out_channels=out_fts[0], kernel_size=(n, 1), stride=(1, 1),\n","                      padding=(n // 2, 0)),\n","        )\n","        self.branch2 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[1], kernel_size=(1, 1), stride=(1, 1)),\n","            nn.Conv2d(in_channels=out_fts[1], out_channels=out_fts[1], kernel_size=(1, n), stride=(1, 1),\n","                      padding=(0, n // 2)),\n","            nn.Conv2d(in_channels=out_fts[1], out_channels=out_fts[1], kernel_size=(n, 1), stride=(1, 1),\n","                      padding=(n // 2, 0)),\n","        )\n","        self.branch3 = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=(3, 3), stride=(1, 1), padding=1),\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[2], kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        self.branch4 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[3], kernel_size=(1, 1), stride=(1, 1))\n","        )\n","\n","    def forward(self, input_img):\n","        o1 = self.branch1(input_img)\n","        o2 = self.branch2(input_img)\n","        o3 = self.branch3(input_img)\n","        o4 = self.branch4(input_img)\n","        x = torch.cat([o1, o2, o3, o4], dim=1)\n","        return x\n","\n","class Inceptionx2(nn.Module):\n","    def __init__(self, in_fts, out_fts):\n","        super(Inceptionx2, self).__init__()\n","        self.branch1 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[0] // 4, kernel_size=(1, 1)),\n","            nn.Conv2d(in_channels=out_fts[0] // 4, out_channels=out_fts[0] // 4, kernel_size=(3, 3), stride=(1, 1),\n","                      padding=1)\n","        )\n","        self.subbranch1_1 = nn.Sequential(\n","            nn.Conv2d(in_channels=out_fts[0] // 4, out_channels=out_fts[0], kernel_size=(1, 3), stride=(1, 1),\n","                      padding=(0, 3 // 2))\n","        )\n","        self.subbranch1_2 = nn.Sequential(\n","            nn.Conv2d(in_channels=out_fts[0] // 4, out_channels=out_fts[1], kernel_size=(3, 1), stride=(1, 1),\n","                      padding=(3 // 2, 0))\n","        )\n","        self.branch2 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[2] // 4, kernel_size=(1, 1))\n","        )\n","        self.subbranch2_1 = nn.Sequential(\n","            nn.Conv2d(in_channels=out_fts[2] // 4, out_channels=out_fts[2], kernel_size=(1, 3), stride=(1, 1),\n","                      padding=(0, 3 // 2))\n","        )\n","        self.subbranch2_2 = nn.Sequential(\n","            nn.Conv2d(in_channels=out_fts[2] // 4, out_channels=out_fts[3], kernel_size=(3, 1), stride=(1, 1),\n","                      padding=(3 // 2, 0))\n","        )\n","        self.branch3 = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=1),\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[4], kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        self.branch4 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_fts, out_channels=out_fts[5], kernel_size=(1, 1), stride=(1, 1))\n","        )\n","\n","    def forward(self, input_img):\n","        o1 = self.branch1(input_img)\n","        o11 = self.subbranch1_1(o1)\n","        o12 = self.subbranch1_2(o1)\n","        o2 = self.branch2(input_img)\n","        o21 = self.subbranch2_1(o2)\n","        o22 = self.subbranch2_2(o2)\n","        o3 = self.branch3(input_img)\n","        o4 = self.branch4(input_img)\n","        x = torch.cat([o11, o12, o21, o22, o3, o4], dim=1)\n","        return x\n","\n","# auxiliary classifier의 loss는 0.3이 곱해지고, 최종 loss에 추가합니다. 정규화 효과가 있습니다. \n","class InceptionAux(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super(InceptionAux, self).__init__()\n","\n","        self.conv = nn.Sequential(\n","            nn.AdaptiveAvgPool2d(output_size=5),\n","            conv_block(in_channels, 128, kernel_size=1),\n","        )\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(5*5*128, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.7),\n","            nn.BatchNorm1d(num_features=1024),\n","            nn.Linear(1024, num_classes),\n","        )\n","\n","    def forward(self,x):\n","        x = self.conv(x)\n","        x = x.view(x.shape[0], -1)\n","        x = self.fc(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MhEYI32X11rW"},"source":["### Declare Inception V3 model"]},{"cell_type":"code","metadata":{"id":"8NDl4D5s1agB"},"source":["class GoogLeNet_v3(nn.Module):\n","    def __init__(self, aux_logits=True, num_classes=10, init_weights=True):\n","        super(GoogLeNet_v2, self).__init__()\n","        assert aux_logits == True or aux_logits == False\n","        self.aux_logits = aux_logits\n","\n","        # conv_block takes in_channels, out_channels, kernel_size, stride, padding\n","        # Inception block takes out1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool\n","\n","        # 3 X 299 X 299\n","        self.conv1 = conv_block(3, 32, kernel_size=3, stride=2)\n","        self.conv2 = conv_block(32, 32, kernel_size=3, stride=1)\n","        self.conv3 = conv_block(32, 64, kernel_size=3, stride=1, padding=1)\n","        # 64 X 147 X 147\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n","        # 64 X 73 X 73\n","        self.conv4 = conv_block(64, 80, kernel_size=3, stride=1)\n","        self.conv5 = conv_block(80, 192, kernel_size=3, stride=2)\n","        self.conv6 = conv_block(192, 288, kernel_size=3, stride=1, padding=1)\n","        # 288 X 35 X 35\n","        list_incept = [Inceptionx3(in_fts=288, out_fts=[96, 96, 96, 96]),\n","                       Inceptionx3(in_fts=4 * 96, out_fts=[96, 96, 96, 96]),\n","                       Inceptionx3(in_fts=4 * 96, out_fts=[96, 96, 96, 96])]\n","\n","        self.inceptx3 = nn.Sequential(*list_incept)\n","        # 384 X 17 X 17\n","        self.grid_redn_1 = GridReduction(in_fts=4 * 96, out_fts=384)\n","        # 768 X 17 X 17\n","        if self.aux_logits:\n","            self.aux_classifier = InceptionAux(768, num_classes)\n","        else:\n","            self.aux_classifier = None\n","        # 768 X 17 X 17\n","        list_incept = [Inceptionx5(in_fts=768, out_fts=[160, 160, 160, 160]),\n","                       Inceptionx5(in_fts=4 * 160, out_fts=[160, 160, 160, 160]),\n","                       Inceptionx5(in_fts=4 * 160, out_fts=[160, 160, 160, 160]),\n","                       Inceptionx5(in_fts=4 * 160, out_fts=[160, 160, 160, 160]),\n","                       Inceptionx5(in_fts=4 * 160, out_fts=[160, 160, 160, 160])]\n","\n","        self.inceptx5 = nn.Sequential(*list_incept)\n","        # 640 X 8 X 8\n","        self.grid_redn_2 = GridReduction(in_fts=4 * 160, out_fts=640)\n","        # 1280 X 8 X 8\n","        list_incept = [Inceptionx2(in_fts=1280, out_fts=[256, 256, 192, 192, 64, 64]),\n","                       Inceptionx2(in_fts=1024, out_fts=[384, 384, 384, 384, 256, 256])]\n","\n","        self.inceptx2 = nn.Sequential(*list_incept)\n","        # 2048 X 8 X 8\n","        self.avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n","        # 2048 X 1 X 1\n","        self.fc = nn.Linear(2048, num_classes)\n","\n","    def forward(self, input_img):\n","        N = input_img.shape[0]\n","        x = self.conv1(input_img)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.maxpool(x)\n","        x = self.conv4(x)\n","        x = self.conv5(x)\n","        x = self.conv6(x)\n","        x = self.inceptx3(x)\n","        x = self.grid_redn_1(x)\n","        aux_out = self.aux_classifier(x)\n","        x = self.inceptx5(x)\n","        x = self.grid_redn_2(x)\n","        x = self.inceptx2(x)\n","        x = self.avgpool(x)\n","        x = x.reshape(N, -1)\n","        x = self.fc(x)\n","        if self.aux_logits and self.training:\n","            return x, aux_out\n","        else:\n","            return x "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LsOcL8g11Z5Y"},"source":["##**Utils**"]},{"cell_type":"code","metadata":{"id":"7LpvhzjP1mGa"},"source":["class AverageMeter(object):\n","    r\"\"\"Computes and stores the average and current value\n","    \"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt # 출력하는 소수의 자릿수\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def print(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print('\\t'.join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n","    \"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        # _, pred = output.topk(maxk, 1, True, True)\n","        # pred = pred.t()\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n","        _, idx = output.sort(descending=True)\n","        pred = idx[:,:maxk]\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g058eZ-Z1tOh"},"source":["##**Cutout: Main Code for Applying Cutout data augmentation**"]},{"cell_type":"code","metadata":{"id":"WU7zK9wi1mlr"},"source":["class Cutout(object):\n","    \"\"\"Randomly mask out one or more patches from an image.\n","\n","    Args:\n","        n_holes (int): Number of patches to cut out of each image.\n","        length (int): The length (in pixels) of each square patch.\n","    \"\"\"\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        \"\"\"\n","        Args:\n","            img (Tensor): Tensor image of size (C, H, W).\n","        Returns:\n","            Tensor: Image with n_holes of dimension length x length cut out of it.\n","        \"\"\"\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","\n","        return img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4vbg5_d92J7r"},"source":["##**Parameter Settings**"]},{"cell_type":"code","metadata":{"id":"e7SdlZce2KlG"},"source":["dataset = 'cifar100' # cifar10 or cifar100\n","model = 'GoogLeNetV3' # resnet18, resnet50, resnet101, GoogLeNetV1\n","batch_size = 64  # Input batch size for training (default: 128)\n","epochs = 100 # Number of epochs to train (default: 200)\n","learning_rate = 1e-3 # Learning rate\n","data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n","sanity_check = False\n","path2weights = './drive/MyDrive/DeepLearning_competition/Internship/Week_2/GoogLeNet_V3.pth'    # route for model saving\n","\n","cutout = True # Apply Cutout?\n","n_holes = 1 # Number of holes to cut out from image\n","length = 16 # Length of the holes\n","\n","seed = 0 # Random seed (default: 0)\n","print_freq = 100\n","cuda = torch.cuda.is_available()\n","cudnn.benchmark = True  # Should make training should go faster for large models\n","\n","torch.manual_seed(seed)\n","if cuda:\n","    torch.cuda.manual_seed(seed)\n","\n","test_id = dataset + '_' + model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xxsNHUuR2OLD"},"source":["##**Load and preprocess data**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":103,"referenced_widgets":["0f42f1ff2e4e4e2c8a9a3c0203da5459","282f7a6444af449ea49ff6419da9b1da","85ce7305176b418eb768b7de2137bb44","049df0b173a84cf796c6356d8b0946e3","56b0fe0f24424d989149f223ab35e0ba","39273c848d3844818562553bd5878f94","83af46fe381f45e4ab4e3b75111fc3ac","d010701e11d94acb8146bafefe78580a","0590e0aa8de5409590435fe897983f20","c2f73b840f824b7e940083a267bb272f","8746744c74ca44a18aeec108a857712b"]},"id":"G0xxABoH2Odv","executionInfo":{"status":"ok","timestamp":1631621022414,"user_tz":-540,"elapsed":7953,"user":{"displayName":"ᄋᄋᄌ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07872107978641370856"}},"outputId":"82d474fa-4af2-4aa5-bff2-7ec42fba438c"},"source":["# Image Preprocessing\n","normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n","                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n","\n","# train\n","train_transform = transforms.Compose([])\n","\n","train_transform.transforms.append(transforms.Resize((299, 299)))\n","if data_augmentation:\n","    train_transform.transforms.append(transforms.RandomCrop(299, 299))\n","    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n","train_transform.transforms.append(transforms.ToTensor())\n","train_transform.transforms.append(normalize)\n","\n","if cutout:\n","    train_transform.transforms.append(Cutout(n_holes=n_holes, length=length))\n","\n","# test\n","test_transform = transforms.Compose([\n","    transforms.Resize((299, 299)),\n","    transforms.ToTensor(),\n","    normalize])\n","\n","if dataset == 'cifar10':\n","    num_classes = 10\n","    train_dataset = datasets.CIFAR10(root='data/',\n","                                     train=True,\n","                                     transform=train_transform,\n","                                     download=True)\n","\n","    test_dataset = datasets.CIFAR10(root='data/',\n","                                    train=False,\n","                                    transform=test_transform,\n","                                    download=True)\n","elif dataset == 'cifar100':\n","    num_classes = 100\n","    train_dataset = datasets.CIFAR100(root='data/',\n","                                      train=True,\n","                                      transform=train_transform,\n","                                      download=True)\n","\n","    test_dataset = datasets.CIFAR100(root='data/',\n","                                     train=False,\n","                                     transform=test_transform,\n","                                     download=True)\n","\n","\n","# Data Loader (Input Pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           pin_memory=True,\n","                                           num_workers=2)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          pin_memory=True,\n","                                          num_workers=2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f42f1ff2e4e4e2c8a9a3c0203da5459","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/169001437 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting data/cifar-100-python.tar.gz to data/\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","metadata":{"id":"BUHCSAbQ5HMo"},"source":["##**Main Training**"]},{"cell_type":"code","metadata":{"id":"6cyFfBNQ5NY9"},"source":["def train(train_loader, epoch, model, optimizer, criterion):\n","    batch_time = AverageMeter('Time', ':6.3f') # 소수 출력 형식지정\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(len(train_loader), batch_time, losses,\n","                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n","    # switch to train mode\n","    model.train()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    running_loss = 0.0\n","    len_data = len(train_loader.dataset)\n","    end = time.time()\n","    for i, (input, target) in enumerate(train_loader):\n","        # measure data loading time\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        # compute output\n","        output = model(input) # output = (x, aux_out)\n","\n","        loss_b = loss_batch(criterion, output, target, optimizer)\n","        running_loss += loss_b\n","        \n","        if sanity_check is True:\n","            break\n","\n","        # measure accuracy and record loss, accuracy \n","        acc1, acc5 = accuracy(output[0], target, topk=(1, 5))\n","        losses.update(loss_b, input.size(0))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            progress.print(i)\n","    \n","    loss = running_loss / len_data\n","\n","    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","def test(test_loader,epoch, model):\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","\n","    # switch to test mode\n","    model.eval()\n","    for i,(input,target) in enumerate(test_loader):\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        output = model(input)\n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UB6yWMLewVlK"},"source":["### Label smoothing"]},{"cell_type":"code","metadata":{"id":"ADhLQISOwVC8"},"source":["class LabelSmoothing(nn.Module):\n","    def __init__(self, num_classes=1000, smoothing=0.1):\n","        super(LabelSmoothing, self).__init__()\n","        self.smoothing = smoothing\n","        self.k = num_classes\n","\n","    def forward(self, target, pred):\n","        \"\"\"\n","        pred (FloatTensor): [batch_size,n_classes]\n","        target (LongTensor): [batch_size]\n","        Ex- for batch_size=2\n","        target = tensor([[1],\n","                         [2]])\n","        pred = tensor([[0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n","                      [0.0200, 0.0200, 0.0200, 0.0200, 0.0200]])\n","        output:-\n","        tensor([[0.0200, 0.9200, 0.0200, 0.0200, 0.0200],\n","                [0.0200, 0.0200, 0.9200, 0.0200, 0.0200]])\n","        \"\"\"\n","        batch_size = target.shape[0]\n","        confidence = torch.as_tensor(batch_size * [(1.0 - smoothing)]).unsqueeze(1)\n","        q = torch.zeros_like(pred).fill_((self.smoothing / self.k)).scatter_(dim=1, index=target.unsqueeze(1),\n","                                                                             src=confidence, reduce='add')\n","\n","        return q\n","\n","class Loss_Inception_v3(nn.Module):\n","    def __init__(self, K, smoothing):\n","        super(Loss_Inception_v3, self).__init__()\n","        self.lsr = LabelSmoothing(K, smoothing)\n","\n","    def forward(self, y, p):\n","        '''\n","        Params\n","        y: true label value --> batch_size\n","        p: predicted by model --> batch_size, num_classes\n","        Return:\n","        Loss values using LabelSmoothing CrossEntropy\n","        '''\n","        q_dist = self.lsr(y, p)\n","        p_k_x = torch.log(torch.softmax(p, dim=1))\n","        l = 0\n","        for i in range(p.shape[0]):\n","            l += torch.sum(p_k_x[i] * q_dist[i])\n","\n","        return l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B0R3_dP_zwVT"},"source":["def get_lr(opt):\n","    for param_group in opt.param_groups:\n","        return param_group['lr']\n","\n","def loss_batch(loss_func, outputs, target, opt=None):\n","    if np.shape(outputs)[0] == 2:\n","        output, aux_out = outputs\n","\n","        output_loss = loss_func(output, target)\n","        aux_out_loss = loss_func(aux_out, target)\n","\n","        loss = output_loss + 0.3*aux_out_loss\n","\n","    else:\n","        loss = loss_func(outputs, target)\n","\n","    if opt is not None:\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","    \n","    return loss.item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"634QzH7t5cW2"},"source":["model = GoogLeNet_v3(num_classes=num_classes).cuda()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = StepLR(optimizer, step_size=8, gamma=0.96)\n","\n","criterion = torch.nn.CrossEntropyLoss(reduction='sum').cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FMJr89WBqqX","outputId":"52aa6d96-2e75-41b3-ce53-0e6419828b44"},"source":["best_acc = 0\n","for epoch in range(epochs):\n","    current_lr = get_lr(optimizer)\n","    print(\"\\n----- epoch: {}/{}, lr: {} -----\".format(\n","        epoch+1, epochs, optimizer.param_groups[0][\"lr\"]))\n","\n","    # train for one epoch\n","    model.aux_logits = True\n","    start_time = time.time()\n","    train(train_loader, epoch, model, optimizer, criterion)\n","\n","    # auxiliary classifier is not used when testing.\n","    model.aux_logits = False\n","    test_acc = test(test_loader,epoch,model)\n","\n","    elapsed_time = time.time() - start_time\n","    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n","    # learning rate scheduling\n","    scheduler.step()\n","    \n","    # Save model for best accuracy\n","    if best_acc < test_acc:\n","        best_acc = test_acc\n","        torch.save(model.state_dict(), path2weights)\n","\n","torch.save(model.state_dict(), path2weights)\n","print(f\"Best Top-1 Accuracy: {best_acc}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","----- epoch: 0/100, lr: 0.001 -----\n","Epoch: [0][  0/782]\tTime  1.843 ( 1.843)\tLoss 3.8375e+02 (3.8375e+02)\tAcc@1   4.69 (  4.69)\tAcc@5   6.25 (  6.25)\n","Epoch: [0][100/782]\tTime  0.443 ( 0.453)\tLoss 3.3549e+12 (1.6918e+13)\tAcc@1   1.56 (  1.18)\tAcc@5   1.56 (  5.31)\n","Epoch: [0][200/782]\tTime  0.453 ( 0.451)\tLoss 1.2315e+20 (2.0173e+20)\tAcc@1   0.00 (  1.19)\tAcc@5   6.25 (  5.32)\n","Epoch: [0][300/782]\tTime  0.462 ( 0.453)\tLoss 2.4936e+17 (2.0816e+20)\tAcc@1   1.56 (  1.07)\tAcc@5   6.25 (  5.01)\n","Epoch: [0][400/782]\tTime  0.466 ( 0.456)\tLoss 6.0850e+16 (1.5628e+20)\tAcc@1   1.56 (  1.07)\tAcc@5   3.12 (  4.96)\n","Epoch: [0][500/782]\tTime  0.471 ( 0.458)\tLoss 3.3259e+16 (1.2509e+20)\tAcc@1   0.00 (  1.05)\tAcc@5   6.25 (  5.00)\n","Epoch: [0][600/782]\tTime  0.471 ( 0.460)\tLoss 1.7347e+16 (1.0428e+20)\tAcc@1   3.12 (  0.99)\tAcc@5   3.12 (  4.90)\n","Epoch: [0][700/782]\tTime  0.471 ( 0.462)\tLoss 1.4277e+16 (8.9410e+19)\tAcc@1   0.00 (  0.99)\tAcc@5   4.69 (  4.97)\n","==> Train Accuracy: Acc@1 0.976 || Acc@5 5.022\n","==> Test Accuracy:  Acc@1 0.860 || Acc@5 4.620\n","==> 384.25 seconds to train this epoch\n","\n","\n","----- epoch: 1/100, lr: 0.001 -----\n","Epoch: [1][  0/782]\tTime  0.782 ( 0.782)\tLoss 1.6464e+16 (1.6464e+16)\tAcc@1   1.56 (  1.56)\tAcc@5   9.38 (  9.38)\n","Epoch: [1][100/782]\tTime  0.470 ( 0.474)\tLoss 2.5688e+16 (1.5994e+16)\tAcc@1   0.00 (  0.82)\tAcc@5   3.12 (  4.73)\n","Epoch: [1][200/782]\tTime  0.474 ( 0.473)\tLoss 1.9712e+16 (1.6704e+16)\tAcc@1   0.00 (  0.86)\tAcc@5   3.12 (  5.05)\n","Epoch: [1][300/782]\tTime  0.472 ( 0.472)\tLoss 5.3135e+15 (1.4547e+16)\tAcc@1   1.56 (  0.89)\tAcc@5   6.25 (  5.10)\n","Epoch: [1][400/782]\tTime  0.468 ( 0.472)\tLoss 9.8219e+15 (1.3241e+16)\tAcc@1   0.00 (  0.90)\tAcc@5   3.12 (  5.00)\n","Epoch: [1][500/782]\tTime  0.474 ( 0.472)\tLoss 5.9627e+15 (1.2467e+16)\tAcc@1   0.00 (  0.95)\tAcc@5   3.12 (  5.17)\n","Epoch: [1][600/782]\tTime  0.472 ( 0.472)\tLoss 6.6066e+15 (1.1853e+16)\tAcc@1   1.56 (  0.93)\tAcc@5   4.69 (  5.13)\n","Epoch: [1][700/782]\tTime  0.469 ( 0.472)\tLoss 7.3566e+15 (1.1156e+16)\tAcc@1   0.00 (  0.95)\tAcc@5   9.38 (  5.11)\n","==> Train Accuracy: Acc@1 0.952 || Acc@5 5.110\n","==> Test Accuracy:  Acc@1 0.580 || Acc@5 5.170\n","==> 390.47 seconds to train this epoch\n","\n","\n","----- epoch: 2/100, lr: 0.001 -----\n","Epoch: [2][  0/782]\tTime  0.775 ( 0.775)\tLoss 4.7146e+15 (4.7146e+15)\tAcc@1   0.00 (  0.00)\tAcc@5   3.12 (  3.12)\n","Epoch: [2][100/782]\tTime  0.471 ( 0.474)\tLoss 1.6625e+16 (7.1932e+15)\tAcc@1   0.00 (  1.07)\tAcc@5   4.69 (  5.18)\n","Epoch: [2][200/782]\tTime  0.471 ( 0.473)\tLoss 4.4291e+15 (6.9108e+15)\tAcc@1   1.56 (  1.09)\tAcc@5   7.81 (  5.33)\n","Epoch: [2][300/782]\tTime  0.471 ( 0.472)\tLoss 3.8887e+15 (6.8391e+15)\tAcc@1   1.56 (  1.04)\tAcc@5   4.69 (  5.24)\n","Epoch: [2][400/782]\tTime  0.471 ( 0.472)\tLoss 4.3025e+15 (6.1900e+15)\tAcc@1   1.56 (  0.97)\tAcc@5   6.25 (  5.07)\n","Epoch: [2][500/782]\tTime  0.473 ( 0.472)\tLoss 4.6361e+15 (5.8610e+15)\tAcc@1   0.00 (  0.95)\tAcc@5   1.56 (  5.03)\n","Epoch: [2][600/782]\tTime  0.468 ( 0.472)\tLoss 2.5410e+15 (5.4218e+15)\tAcc@1   0.00 (  0.96)\tAcc@5  10.94 (  5.12)\n","Epoch: [2][700/782]\tTime  0.469 ( 0.472)\tLoss 5.1888e+15 (5.1349e+15)\tAcc@1   0.00 (  0.95)\tAcc@5   4.69 (  5.07)\n","==> Train Accuracy: Acc@1 0.968 || Acc@5 5.098\n","==> Test Accuracy:  Acc@1 1.000 || Acc@5 5.390\n","==> 390.63 seconds to train this epoch\n","\n","\n","----- epoch: 3/100, lr: 0.001 -----\n","Epoch: [3][  0/782]\tTime  0.775 ( 0.775)\tLoss 3.1046e+15 (3.1046e+15)\tAcc@1   0.00 (  0.00)\tAcc@5   3.12 (  3.12)\n","Epoch: [3][100/782]\tTime  0.470 ( 0.474)\tLoss 3.3056e+15 (5.7040e+15)\tAcc@1   0.00 (  0.79)\tAcc@5   7.81 (  4.78)\n","Epoch: [3][200/782]\tTime  0.470 ( 0.473)\tLoss 3.6514e+15 (5.2473e+15)\tAcc@1   1.56 (  0.93)\tAcc@5   1.56 (  4.94)\n","Epoch: [3][300/782]\tTime  0.469 ( 0.472)\tLoss 4.2573e+15 (5.6331e+15)\tAcc@1   0.00 (  0.97)\tAcc@5   3.12 (  4.92)\n","Epoch: [3][400/782]\tTime  0.470 ( 0.472)\tLoss 1.5039e+15 (4.9876e+15)\tAcc@1   0.00 (  0.96)\tAcc@5   3.12 (  4.92)\n","Epoch: [3][500/782]\tTime  0.472 ( 0.472)\tLoss 2.5187e+16 (4.5291e+15)\tAcc@1   1.56 (  0.97)\tAcc@5   4.69 (  4.88)\n","Epoch: [3][600/782]\tTime  0.468 ( 0.471)\tLoss 1.7694e+15 (4.2624e+15)\tAcc@1   3.12 (  0.97)\tAcc@5   7.81 (  4.96)\n","Epoch: [3][700/782]\tTime  0.468 ( 0.471)\tLoss 1.2287e+15 (3.8761e+15)\tAcc@1   3.12 (  0.97)\tAcc@5   7.81 (  4.98)\n","==> Train Accuracy: Acc@1 0.950 || Acc@5 4.984\n","==> Test Accuracy:  Acc@1 1.150 || Acc@5 4.300\n","==> 390.31 seconds to train this epoch\n","\n","\n","----- epoch: 4/100, lr: 0.001 -----\n","Epoch: [4][  0/782]\tTime  0.784 ( 0.784)\tLoss 1.1446e+15 (1.1446e+15)\tAcc@1   3.12 (  3.12)\tAcc@5   6.25 (  6.25)\n","Epoch: [4][100/782]\tTime  0.472 ( 0.474)\tLoss 1.4408e+15 (1.3920e+15)\tAcc@1   0.00 (  0.99)\tAcc@5   7.81 (  4.86)\n"]}]}]}